{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c rdkit rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_logger import configure, log_value\n",
    "import tensorboard\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "#import utils import Logger\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part to use my own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transforms_=None):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.files = sorted(glob.glob('%s/*.*' % folder_path))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "img_shape = (3, 100, 100)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "n_epochs=5000 #number of epochs of training\n",
    "batch_size=400 #size of the batches\n",
    "lr=0.0002 #adam: learning rate\n",
    "b1=0.5  #\"adam: decay of first order momentum of gradient\")\n",
    "b2=0.999 #adam: decay of first order momentum of gradient\")\n",
    "n_cpu=8\n",
    "latent_dim=100\n",
    "img_size=200\n",
    "channels=3\n",
    "n_critic=5\n",
    "clip_value=0.01\n",
    "sample_interval=1000\n",
    "img_shape = (channels, img_size, img_size)\n",
    "crop_size = 400\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = \"./zinc100k500px\"\n",
    "transforms_ = [ transforms.Resize(img_size),\n",
    "                transforms.CenterCrop(img_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(folder_path, transforms_=transforms_),\n",
    "                        batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_shape = (3, 100, 100)\n",
    "\n",
    "#folder_path = \"./molecules100\"\n",
    "#transforms_ = [ transforms.Resize(100),\n",
    "#                transforms.CenterCrop(100),\n",
    "#                transforms.ToTensor(),\n",
    "#                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "#dataloader = DataLoader(ImageDataset(folder_path, transforms_=transforms_),\n",
    "#                        batch_size=100, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(100, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: Determine optimal learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual training now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b2, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1455, -1.3897,  0.5656,  ..., -0.1336, -0.3261, -0.2717],\n",
      "        [ 0.3769, -1.7770, -1.7421,  ...,  0.8083,  1.5583,  0.1583],\n",
      "        [ 0.3128,  0.6326, -0.6259,  ...,  0.2174,  1.5046,  0.7104],\n",
      "        ...,\n",
      "        [-0.7455,  0.2533,  0.4738,  ...,  2.8316, -1.6945,  0.2717],\n",
      "        [ 0.3215,  1.1270,  1.6873,  ...,  1.4072, -0.1512,  0.7300],\n",
      "        [-0.5515,  1.2271,  1.1987,  ..., -0.7063,  0.1423, -1.6368]],\n",
      "       device='cuda:0')\n",
      "100\n",
      "torch.Size([400, 3, 200, 200])\n",
      "tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "# Sample noise as generator input\n",
    "\n",
    "imgs\n",
    "z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "print(z)\n",
    "print(latent_dim)\n",
    "print(imgs.shape)\n",
    "print(imgs)\n",
    "\n",
    "# Generate a batch of images\n",
    "fake_imgs = generator(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batches_done' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d13fa1fc5f99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatches_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batches_done' is not defined"
     ]
    }
   ],
   "source": [
    "batches_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 0/250] [D loss: 36.971878] [G loss: -1377.578979] [5batch time: -0.000001]\n",
      "[Epoch 0/1] [Batch 5/250] [D loss: 25.295403] [G loss: -1309.954346] [5batch time: 11.239845]\n",
      "[Epoch 0/1] [Batch 10/250] [D loss: 16.670288] [G loss: -1236.936890] [5batch time: 1.651815]\n",
      "[Epoch 0/1] [Batch 15/250] [D loss: 4.637108] [G loss: -1153.895386] [5batch time: 1.628217]\n",
      "[Epoch 0/1] [Batch 20/250] [D loss: -3.039436] [G loss: -1068.142212] [5batch time: 1.603856]\n",
      "[Epoch 0/1] [Batch 25/250] [D loss: -2.178219] [G loss: -985.437866] [5batch time: 1.603096]\n",
      "[Epoch 0/1] [Batch 30/250] [D loss: -5.159782] [G loss: -894.653503] [5batch time: 1.565035]\n",
      "[Epoch 0/1] [Batch 35/250] [D loss: -10.541723] [G loss: -798.574646] [5batch time: 1.568519]\n",
      "[Epoch 0/1] [Batch 40/250] [D loss: -11.379900] [G loss: -703.054504] [5batch time: 1.572233]\n",
      "[Epoch 0/1] [Batch 45/250] [D loss: -15.985483] [G loss: -602.522034] [5batch time: 1.580967]\n",
      "[Epoch 0/1] [Batch 50/250] [D loss: -17.476208] [G loss: -504.797729] [5batch time: 1.573425]\n",
      "[Epoch 0/1] [Batch 55/250] [D loss: -17.895506] [G loss: -408.500977] [5batch time: 1.590179]\n",
      "[Epoch 0/1] [Batch 60/250] [D loss: -11.936330] [G loss: -318.927490] [5batch time: 1.613126]\n",
      "[Epoch 0/1] [Batch 65/250] [D loss: -11.259507] [G loss: -225.939056] [5batch time: 1.624038]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-64:\n",
      "Process Process-63:\n",
      "Process Process-60:\n",
      "Process Process-61:\n",
      "Process Process-59:\n",
      "Process Process-62:\n",
      "Process Process-57:\n",
      "Process Process-58:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-2-3e5f53181d14>\", line 17, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"<ipython-input-2-3e5f53181d14>\", line 17, in __getitem__\n",
      "    img = self.transform(img)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-2-3e5f53181d14>\", line 17, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"<ipython-input-2-3e5f53181d14>\", line 17, in __getitem__\n",
      "    img = self.transform(img)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"<ipython-input-2-3e5f53181d14>\", line 17, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/Image.py\", line 1747, in resize\n",
      "    self.load()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/Image.py\", line 1747, in resize\n",
      "    self.load()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 78, in to_tensor\n",
      "    img = img.view(pic.size[1], pic.size[0], nchannel)\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/Image.py\", line 1747, in resize\n",
      "    self.load()\n",
      "  File \"/home/jgmeyer2/anaconda3/envs/vangan/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-97b061a392ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Configure input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mreal_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#  Train Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# old logger\n",
    "from utils import Logger\n",
    "#configure(\"runs/test2\",flush_secs=5)\n",
    "#logger = Logger(model_name='wgangp1t1', data_name='200px')\n",
    "#num_batches = len(dataloader)\n",
    "n_epochs=1\n",
    "batches_done = 0\n",
    "### new logger\n",
    "\n",
    "\n",
    "#batch_size=100\n",
    "#print(latent_dim)\n",
    "for epoch in range(n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "        ## monitor time\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z)\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        optimizer_G.zero_grad()\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % n_critic == 0:\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [5batch time: %f]\"\n",
    "                % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), batchtime)\n",
    "            )\n",
    "\n",
    "            #logger.log(d_loss, g_loss, epoch, batches_done, num_batches)\n",
    "            if batches_done % sample_interval/10 ==0:\n",
    "                log_value('g_loss', g_loss, batches_done)\n",
    "                log_value('d_loss', d_loss, batches_done)\n",
    "            \n",
    "            if batches_done % sample_interval == 0:\n",
    "                save_image(fake_imgs.data[:25], \"molpics500px/%d_c.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            batchtime= end - start\n",
    "            start = time.time()\n",
    "            batches_done += n_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tensorboard\n",
    "!python -m tensorboard.main --logdir runs\n",
    "#tensorboard --help\n",
    "#tensorboard --logdir=runs\n",
    "\n",
    "#logger.d_loss.data.cpu().numpy()\n",
    "#logger.display_status(epoch, n_epochs, batches_done, num_batches, d_loss, g_loss, d_pred_real, d_pred_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved models @\n",
      "669\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"/home/jgmeyer2/vangan/gans/models\",exist_ok=True)\n",
    "PATH = \"/home/jgmeyer2/vangan/gans/models/\"\n",
    "modelid=\"200px_668epoch\"\n",
    "\n",
    "\n",
    "state_g = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': generator.state_dict(),\n",
    "    'optimizer': optimizer_G.state_dict()\n",
    "    }\n",
    "torch.save(state_g, PATH+\"g\"+modelid+\".model\")\n",
    "\n",
    "state_d = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': discriminator.state_dict(),\n",
    "    'optimizer': optimizer_D.state_dict()\n",
    "    }\n",
    "torch.save(state_d, PATH+\"d\"+modelid+\".model\")\n",
    "print(\"saved models @\")\n",
    "print(epoch)\n",
    "\n",
    "\n",
    "#def save_model(net, optim, ckpt_fname):\n",
    "#    state_dict = net.module.state_dict()\n",
    "#    for key in state_dict.keys():\n",
    "#        state_dict[key] = state_dict[key].cpu()\n",
    "#        torch.save({\n",
    "#            'epoch': epoch,                                                                                                                                                                                     \n",
    "#            'state_dict': state_dict,                                                                                                                                                                                \n",
    "#            'optimizer': optim},                                                                                                                                                                                     \n",
    "#            ckpt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Generator:\n\tsize mismatch for model.11.weight: copying a param of torch.Size([120000, 1024]) from checkpoint, where the shape is torch.Size([30000, 1024]) in current model.\n\tsize mismatch for model.11.bias: copying a param of torch.Size([120000]) from checkpoint, where the shape is torch.Size([30000]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-d375cccd5f81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_g\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_g\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vangan/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tsize mismatch for model.11.weight: copying a param of torch.Size([120000, 1024]) from checkpoint, where the shape is torch.Size([30000, 1024]) in current model.\n\tsize mismatch for model.11.bias: copying a param of torch.Size([120000]) from checkpoint, where the shape is torch.Size([30000]) in current model."
     ]
    }
   ],
   "source": [
    "state_g = torch.load(\"/home/jgmeyer2/vangan/gans/models/g5k.modelg5k.model\")\n",
    "state_d = torch.load(\"/home/jgmeyer2/vangan/gans/models/g5k.modeld5k.model\")\n",
    "\n",
    "\n",
    "generator.load_state_dict(state_g['state_dict'])\n",
    "optimizer_G.load_state_dict(state_g['optimizer'])\n",
    "\n",
    "discriminator.load_state_dict(state_d['state_dict'])\n",
    "optimizer_D.load_state_dict(state_d['optimizer'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vangan",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
