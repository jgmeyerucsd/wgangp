{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgmeyer2/anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - rdkit\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    libboost: 1.65.1-habcd387_4               \n",
      "    py-boost: 1.65.1-py36hf484d3e_4           \n",
      "    rdkit:    2018.03.4.0-py36h71b666b_1 rdkit\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c rdkit rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images from SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['downloaded_zinc_n2/IACA.txt', 'downloaded_zinc_n2/JACB.txt', 'downloaded_zinc_n2/KACB.txt', 'downloaded_zinc_n2/JAAA.txt', 'downloaded_zinc_n2/KAAA.txt', 'downloaded_zinc_n2/IABB.txt', 'downloaded_zinc_n2/IABA.txt', 'downloaded_zinc_n2/KAEB.txt', 'downloaded_zinc_n2/IAAD.txt', 'downloaded_zinc_n2/JABA.txt', 'downloaded_zinc_n2/KAAB.txt', 'downloaded_zinc_n2/IACD.txt', 'downloaded_zinc_n2/JAEB.txt', 'downloaded_zinc_n2/JABD.txt', 'downloaded_zinc_n2/KAEA.txt', 'downloaded_zinc_n2/KAAD.txt', 'downloaded_zinc_n2/JACA.txt', 'downloaded_zinc_n2/IAAB.txt', 'downloaded_zinc_n2/JAEA.txt', 'downloaded_zinc_n2/JABB.txt', 'downloaded_zinc_n2/IABD.txt', 'downloaded_zinc_n2/KABA.txt', 'downloaded_zinc_n2/JAAB.txt', 'downloaded_zinc_n2/IAAA.txt', 'downloaded_zinc_n2/JACD.txt', 'downloaded_zinc_n2/KABB.txt', 'downloaded_zinc_n2/IAED.txt', 'downloaded_zinc_n2/JAAD.txt', 'downloaded_zinc_n2/IACB.txt', 'downloaded_zinc_n2/JAED.txt', 'downloaded_zinc_n2/IAEA.txt', 'downloaded_zinc_n2/KACA.txt', 'downloaded_zinc_n2/IAEB.txt']\n",
      "downloaded_zinc_n2/IACA.txt\n"
     ]
    }
   ],
   "source": [
    "#print(os.listdir())\n",
    "tables_list=glob.glob(\"downloaded_zinc_n2/*.txt\")\n",
    "print(tables_list)\n",
    "print(tables_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the tables found above, take the first column containing smiles text, and append to master list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded_zinc_n2/IACA.txt\n",
      "downloaded_zinc_n2/JACB.txt\n",
      "downloaded_zinc_n2/KACB.txt\n",
      "downloaded_zinc_n2/JAAA.txt\n",
      "downloaded_zinc_n2/KAAA.txt\n",
      "downloaded_zinc_n2/IABB.txt\n",
      "downloaded_zinc_n2/IABA.txt\n",
      "downloaded_zinc_n2/KAEB.txt\n",
      "downloaded_zinc_n2/IAAD.txt\n",
      "downloaded_zinc_n2/JABA.txt\n",
      "downloaded_zinc_n2/KAAB.txt\n",
      "downloaded_zinc_n2/IACD.txt\n",
      "downloaded_zinc_n2/JAEB.txt\n",
      "downloaded_zinc_n2/JABD.txt\n",
      "downloaded_zinc_n2/KAEA.txt\n",
      "downloaded_zinc_n2/KAAD.txt\n",
      "downloaded_zinc_n2/JACA.txt\n",
      "downloaded_zinc_n2/IAAB.txt\n",
      "downloaded_zinc_n2/JAEA.txt\n",
      "downloaded_zinc_n2/JABB.txt\n",
      "downloaded_zinc_n2/IABD.txt\n",
      "downloaded_zinc_n2/KABA.txt\n",
      "downloaded_zinc_n2/JAAB.txt\n",
      "downloaded_zinc_n2/IAAA.txt\n",
      "downloaded_zinc_n2/JACD.txt\n",
      "downloaded_zinc_n2/KABB.txt\n",
      "downloaded_zinc_n2/IAED.txt\n",
      "downloaded_zinc_n2/JAAD.txt\n",
      "downloaded_zinc_n2/IACB.txt\n",
      "downloaded_zinc_n2/JAED.txt\n",
      "downloaded_zinc_n2/IAEA.txt\n",
      "downloaded_zinc_n2/KACA.txt\n",
      "downloaded_zinc_n2/IAEB.txt\n",
      "57885\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "smileslist = []\n",
    "        \n",
    "for table in tables_list:\n",
    "    with open(table) as inf:\n",
    "        reader = csv.reader(inf, delimiter=\"\\t\")\n",
    "        smiles = list(zip(*reader))[0]\n",
    "        smileslist.extend(list(smiles)[1:])\n",
    "        print(table)\n",
    "    \n",
    "print(len(smileslist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### cut the first line from the list which is the header\n",
    "smiles= smileslist[1:len(smileslist)]\n",
    "#print(len(smileslist))\n",
    "#print(len(smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "i=1\n",
    "for x in smiles:\n",
    "    x_mol = Chem.MolFromSmiles(str(x))\n",
    "    Draw.MolToFile(x_mol, fileName=\"./molecules100/\"+str(i)+\"a.png\", size=(100, 100), kekulize=True, wedgeBonds=True, imageType=\"png\")\n",
    "    i+=1\n",
    "    #urllib.request.urlretrieve(url_pre+str(x)+url_post, out_pre+str(x)+out_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part to use my own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transforms_=None):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.files = sorted(glob.glob('%s/*.*' % folder_path))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "img_shape = (3, 100, 100)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=200 #number of epochs of training\n",
    "batch_size=64 #size of the batches\n",
    "lr=0.0002 #adam: learning rate\n",
    "b1=0.5  #\"adam: decay of first order momentum of gradient\")\n",
    "b2=0.999 #adam: decay of first order momentum of gradient\")\n",
    "n_cpu=8\n",
    "latent_dim=50\n",
    "img_size=100\n",
    "channels=3\n",
    "n_critic=5\n",
    "clip_value=0.01\n",
    "sample_interval=815\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = \"./molecules100\"\n",
    "transforms_ = [ transforms.Resize(50),\n",
    "                transforms.CenterCrop(50),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(folder_path, transforms_=transforms_),\n",
    "                        batch_size=100, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(100, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine optimal learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual training now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/815] [D loss: -5.789902] [G loss: -23.082102]\n",
      "[Epoch 0/200] [Batch 5/815] [D loss: -3.468456] [G loss: -49.181351]\n",
      "[Epoch 0/200] [Batch 10/815] [D loss: -3.809268] [G loss: -37.151054]\n",
      "[Epoch 0/200] [Batch 15/815] [D loss: -3.958514] [G loss: -44.932156]\n",
      "[Epoch 0/200] [Batch 20/815] [D loss: -4.714270] [G loss: -30.208340]\n",
      "[Epoch 0/200] [Batch 25/815] [D loss: -5.454857] [G loss: -22.341024]\n",
      "[Epoch 0/200] [Batch 30/815] [D loss: -4.707932] [G loss: -34.585598]\n",
      "[Epoch 0/200] [Batch 35/815] [D loss: -5.001633] [G loss: -23.999882]\n",
      "[Epoch 0/200] [Batch 40/815] [D loss: -4.780243] [G loss: -37.460815]\n",
      "[Epoch 0/200] [Batch 45/815] [D loss: -4.962447] [G loss: -31.616678]\n",
      "[Epoch 0/200] [Batch 50/815] [D loss: -5.444920] [G loss: -22.370380]\n",
      "[Epoch 0/200] [Batch 55/815] [D loss: -5.580760] [G loss: -20.079750]\n",
      "[Epoch 0/200] [Batch 60/815] [D loss: -4.717446] [G loss: -28.510597]\n",
      "[Epoch 0/200] [Batch 65/815] [D loss: -5.193073] [G loss: -21.988544]\n",
      "[Epoch 0/200] [Batch 70/815] [D loss: -5.362594] [G loss: -32.831017]\n",
      "[Epoch 0/200] [Batch 75/815] [D loss: -5.226788] [G loss: -20.982208]\n",
      "[Epoch 0/200] [Batch 80/815] [D loss: -4.318919] [G loss: -41.031868]\n",
      "[Epoch 0/200] [Batch 85/815] [D loss: -4.463343] [G loss: -21.060698]\n",
      "[Epoch 0/200] [Batch 90/815] [D loss: -5.805273] [G loss: -20.363890]\n",
      "[Epoch 0/200] [Batch 95/815] [D loss: -5.197951] [G loss: -23.734484]\n",
      "[Epoch 0/200] [Batch 100/815] [D loss: -5.136851] [G loss: -22.787546]\n",
      "[Epoch 0/200] [Batch 105/815] [D loss: -4.669248] [G loss: -33.745777]\n",
      "[Epoch 0/200] [Batch 110/815] [D loss: -4.658298] [G loss: -30.967155]\n",
      "[Epoch 0/200] [Batch 115/815] [D loss: -4.808947] [G loss: -20.749784]\n",
      "[Epoch 0/200] [Batch 120/815] [D loss: -5.510952] [G loss: -14.747877]\n",
      "[Epoch 0/200] [Batch 125/815] [D loss: -4.430208] [G loss: -30.713627]\n",
      "[Epoch 0/200] [Batch 130/815] [D loss: -4.684008] [G loss: -26.052023]\n",
      "[Epoch 0/200] [Batch 135/815] [D loss: -5.286479] [G loss: -27.800280]\n",
      "[Epoch 0/200] [Batch 140/815] [D loss: -5.506504] [G loss: -18.493568]\n",
      "[Epoch 0/200] [Batch 145/815] [D loss: -4.235806] [G loss: -37.627987]\n",
      "[Epoch 0/200] [Batch 150/815] [D loss: -5.235448] [G loss: -15.764031]\n",
      "[Epoch 0/200] [Batch 155/815] [D loss: -4.215278] [G loss: -23.018826]\n",
      "[Epoch 0/200] [Batch 160/815] [D loss: -4.857401] [G loss: -28.853319]\n",
      "[Epoch 0/200] [Batch 165/815] [D loss: -5.437984] [G loss: -18.527531]\n",
      "[Epoch 0/200] [Batch 170/815] [D loss: -5.686274] [G loss: -23.743155]\n",
      "[Epoch 0/200] [Batch 175/815] [D loss: -5.173175] [G loss: -26.108784]\n",
      "[Epoch 0/200] [Batch 180/815] [D loss: -5.745827] [G loss: -19.062874]\n",
      "[Epoch 0/200] [Batch 185/815] [D loss: -5.458760] [G loss: -26.483009]\n",
      "[Epoch 0/200] [Batch 190/815] [D loss: -4.416446] [G loss: -30.344076]\n",
      "[Epoch 0/200] [Batch 195/815] [D loss: -5.218090] [G loss: -18.164379]\n",
      "[Epoch 0/200] [Batch 200/815] [D loss: -4.200155] [G loss: -30.747812]\n",
      "[Epoch 0/200] [Batch 205/815] [D loss: -4.765704] [G loss: -23.636736]\n",
      "[Epoch 0/200] [Batch 210/815] [D loss: -2.736182] [G loss: -72.070869]\n",
      "[Epoch 0/200] [Batch 215/815] [D loss: -3.717592] [G loss: -39.054142]\n",
      "[Epoch 0/200] [Batch 220/815] [D loss: -4.002648] [G loss: -29.861193]\n",
      "[Epoch 0/200] [Batch 225/815] [D loss: -4.006552] [G loss: -24.498600]\n",
      "[Epoch 0/200] [Batch 230/815] [D loss: -4.197127] [G loss: -26.205061]\n",
      "[Epoch 0/200] [Batch 235/815] [D loss: -4.512481] [G loss: -19.085350]\n",
      "[Epoch 0/200] [Batch 240/815] [D loss: -4.813874] [G loss: -24.970741]\n",
      "[Epoch 0/200] [Batch 245/815] [D loss: -6.187544] [G loss: -16.050806]\n",
      "[Epoch 0/200] [Batch 250/815] [D loss: -4.136545] [G loss: -30.696585]\n",
      "[Epoch 0/200] [Batch 255/815] [D loss: -4.566382] [G loss: -25.869577]\n",
      "[Epoch 0/200] [Batch 260/815] [D loss: -4.496997] [G loss: -30.919182]\n",
      "[Epoch 0/200] [Batch 265/815] [D loss: -5.156920] [G loss: -15.534960]\n",
      "[Epoch 0/200] [Batch 270/815] [D loss: -3.817172] [G loss: -34.303883]\n",
      "[Epoch 0/200] [Batch 275/815] [D loss: -5.162308] [G loss: -17.717981]\n",
      "[Epoch 0/200] [Batch 280/815] [D loss: -5.479832] [G loss: -19.168360]\n",
      "[Epoch 0/200] [Batch 285/815] [D loss: -5.347565] [G loss: -17.333944]\n",
      "[Epoch 0/200] [Batch 290/815] [D loss: -4.411450] [G loss: -35.662357]\n",
      "[Epoch 0/200] [Batch 295/815] [D loss: -4.419868] [G loss: -21.593510]\n",
      "[Epoch 0/200] [Batch 300/815] [D loss: -4.632934] [G loss: -23.911476]\n",
      "[Epoch 0/200] [Batch 305/815] [D loss: -5.052498] [G loss: -28.827457]\n",
      "[Epoch 0/200] [Batch 310/815] [D loss: -5.741143] [G loss: -17.541803]\n",
      "[Epoch 0/200] [Batch 315/815] [D loss: -4.661846] [G loss: -22.654846]\n",
      "[Epoch 0/200] [Batch 320/815] [D loss: -5.525190] [G loss: -25.885788]\n",
      "[Epoch 0/200] [Batch 325/815] [D loss: -4.973268] [G loss: -20.235781]\n",
      "[Epoch 0/200] [Batch 330/815] [D loss: -4.318448] [G loss: -23.401464]\n",
      "[Epoch 0/200] [Batch 335/815] [D loss: -4.759959] [G loss: -16.613516]\n",
      "[Epoch 0/200] [Batch 340/815] [D loss: -4.982494] [G loss: -33.248768]\n",
      "[Epoch 0/200] [Batch 345/815] [D loss: -4.702565] [G loss: -24.266161]\n",
      "[Epoch 0/200] [Batch 350/815] [D loss: -4.873278] [G loss: -18.072065]\n",
      "[Epoch 0/200] [Batch 355/815] [D loss: -4.725994] [G loss: -15.482733]\n",
      "[Epoch 0/200] [Batch 360/815] [D loss: -5.732291] [G loss: -19.895060]\n",
      "[Epoch 0/200] [Batch 365/815] [D loss: -3.827100] [G loss: -25.663202]\n",
      "[Epoch 0/200] [Batch 370/815] [D loss: -3.649389] [G loss: -35.774654]\n",
      "[Epoch 0/200] [Batch 375/815] [D loss: -5.419552] [G loss: -23.344679]\n",
      "[Epoch 0/200] [Batch 380/815] [D loss: -4.983795] [G loss: -18.059267]\n",
      "[Epoch 0/200] [Batch 385/815] [D loss: -5.030692] [G loss: -22.356176]\n",
      "[Epoch 0/200] [Batch 390/815] [D loss: -4.860710] [G loss: -16.788229]\n",
      "[Epoch 0/200] [Batch 395/815] [D loss: -4.519457] [G loss: -33.268517]\n",
      "[Epoch 0/200] [Batch 400/815] [D loss: -5.025428] [G loss: -19.946236]\n",
      "[Epoch 0/200] [Batch 405/815] [D loss: -5.307043] [G loss: -18.855419]\n",
      "[Epoch 0/200] [Batch 410/815] [D loss: -5.002519] [G loss: -20.222528]\n",
      "[Epoch 0/200] [Batch 415/815] [D loss: -5.063886] [G loss: -15.011074]\n",
      "[Epoch 0/200] [Batch 420/815] [D loss: -4.661124] [G loss: -18.169807]\n",
      "[Epoch 0/200] [Batch 425/815] [D loss: -5.683430] [G loss: -22.926872]\n",
      "[Epoch 0/200] [Batch 430/815] [D loss: -5.236063] [G loss: -13.171109]\n",
      "[Epoch 0/200] [Batch 435/815] [D loss: -3.837020] [G loss: -55.109531]\n",
      "[Epoch 0/200] [Batch 440/815] [D loss: -4.202778] [G loss: -27.539680]\n",
      "[Epoch 0/200] [Batch 445/815] [D loss: -4.689767] [G loss: -25.344141]\n",
      "[Epoch 0/200] [Batch 450/815] [D loss: -4.711977] [G loss: -22.596270]\n",
      "[Epoch 0/200] [Batch 455/815] [D loss: -5.332263] [G loss: -26.849495]\n",
      "[Epoch 0/200] [Batch 460/815] [D loss: -4.784588] [G loss: -14.252987]\n",
      "[Epoch 0/200] [Batch 465/815] [D loss: -4.909382] [G loss: -16.954739]\n",
      "[Epoch 0/200] [Batch 470/815] [D loss: -5.380106] [G loss: -17.115208]\n",
      "[Epoch 0/200] [Batch 475/815] [D loss: -5.256672] [G loss: -16.026718]\n",
      "[Epoch 0/200] [Batch 480/815] [D loss: -6.353734] [G loss: -13.569283]\n",
      "[Epoch 0/200] [Batch 485/815] [D loss: -5.612922] [G loss: -12.966734]\n",
      "[Epoch 0/200] [Batch 490/815] [D loss: -4.315917] [G loss: -23.798374]\n",
      "[Epoch 0/200] [Batch 495/815] [D loss: -5.075220] [G loss: -16.580198]\n",
      "[Epoch 0/200] [Batch 500/815] [D loss: -3.855816] [G loss: -24.981636]\n",
      "[Epoch 0/200] [Batch 505/815] [D loss: -4.909873] [G loss: -27.620251]\n",
      "[Epoch 0/200] [Batch 510/815] [D loss: -5.530427] [G loss: -17.246159]\n",
      "[Epoch 0/200] [Batch 515/815] [D loss: -3.941923] [G loss: -29.352629]\n",
      "[Epoch 0/200] [Batch 520/815] [D loss: -7.284312] [G loss: -14.622154]\n",
      "[Epoch 0/200] [Batch 525/815] [D loss: -4.657218] [G loss: -15.563014]\n",
      "[Epoch 0/200] [Batch 530/815] [D loss: -4.262259] [G loss: -37.103607]\n",
      "[Epoch 0/200] [Batch 535/815] [D loss: -5.398922] [G loss: -23.033339]\n",
      "[Epoch 0/200] [Batch 540/815] [D loss: -4.652328] [G loss: -35.014507]\n",
      "[Epoch 0/200] [Batch 545/815] [D loss: -4.495337] [G loss: -22.689682]\n",
      "[Epoch 0/200] [Batch 550/815] [D loss: -4.770143] [G loss: -21.746923]\n",
      "[Epoch 0/200] [Batch 555/815] [D loss: -4.730873] [G loss: -18.224028]\n",
      "[Epoch 0/200] [Batch 560/815] [D loss: -5.539720] [G loss: -23.181232]\n",
      "[Epoch 0/200] [Batch 565/815] [D loss: -5.280065] [G loss: -13.762102]\n",
      "[Epoch 0/200] [Batch 570/815] [D loss: -5.928789] [G loss: -11.159441]\n",
      "[Epoch 0/200] [Batch 575/815] [D loss: -6.309260] [G loss: -17.106524]\n",
      "[Epoch 0/200] [Batch 580/815] [D loss: -4.447762] [G loss: -23.933882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 585/815] [D loss: -5.223890] [G loss: -18.083355]\n",
      "[Epoch 0/200] [Batch 590/815] [D loss: -5.354591] [G loss: -13.752713]\n",
      "[Epoch 0/200] [Batch 595/815] [D loss: -4.550429] [G loss: -25.927073]\n",
      "[Epoch 0/200] [Batch 600/815] [D loss: -5.660472] [G loss: -18.913204]\n",
      "[Epoch 0/200] [Batch 605/815] [D loss: -5.237696] [G loss: -16.364305]\n",
      "[Epoch 0/200] [Batch 610/815] [D loss: -4.806082] [G loss: -26.446293]\n",
      "[Epoch 0/200] [Batch 615/815] [D loss: -5.402307] [G loss: -16.312006]\n",
      "[Epoch 0/200] [Batch 620/815] [D loss: -3.989680] [G loss: -34.518536]\n",
      "[Epoch 0/200] [Batch 625/815] [D loss: -4.385514] [G loss: -19.857111]\n",
      "[Epoch 0/200] [Batch 630/815] [D loss: -4.287412] [G loss: -19.260242]\n",
      "[Epoch 0/200] [Batch 635/815] [D loss: -5.114437] [G loss: -12.806242]\n",
      "[Epoch 0/200] [Batch 640/815] [D loss: -4.560164] [G loss: -23.153900]\n",
      "[Epoch 0/200] [Batch 645/815] [D loss: -4.728593] [G loss: -15.868505]\n",
      "[Epoch 0/200] [Batch 650/815] [D loss: -3.840821] [G loss: -36.611881]\n",
      "[Epoch 0/200] [Batch 655/815] [D loss: -4.450554] [G loss: -23.635305]\n",
      "[Epoch 0/200] [Batch 660/815] [D loss: -4.607244] [G loss: -25.295179]\n",
      "[Epoch 0/200] [Batch 665/815] [D loss: -5.178690] [G loss: -12.739577]\n",
      "[Epoch 0/200] [Batch 670/815] [D loss: -5.542563] [G loss: -13.428800]\n",
      "[Epoch 0/200] [Batch 675/815] [D loss: -4.811647] [G loss: -21.705347]\n",
      "[Epoch 0/200] [Batch 680/815] [D loss: -3.066541] [G loss: -50.227898]\n",
      "[Epoch 0/200] [Batch 685/815] [D loss: -4.833810] [G loss: -25.006769]\n",
      "[Epoch 0/200] [Batch 690/815] [D loss: -5.210601] [G loss: -17.105137]\n",
      "[Epoch 0/200] [Batch 695/815] [D loss: -4.193156] [G loss: -30.738199]\n",
      "[Epoch 0/200] [Batch 700/815] [D loss: -4.157995] [G loss: -22.464218]\n",
      "[Epoch 0/200] [Batch 705/815] [D loss: -4.059781] [G loss: -19.169409]\n",
      "[Epoch 0/200] [Batch 710/815] [D loss: -4.693160] [G loss: -15.680135]\n",
      "[Epoch 0/200] [Batch 715/815] [D loss: -5.023427] [G loss: -17.951429]\n",
      "[Epoch 0/200] [Batch 720/815] [D loss: -5.728689] [G loss: -11.152206]\n",
      "[Epoch 0/200] [Batch 725/815] [D loss: -4.488704] [G loss: -27.849638]\n",
      "[Epoch 0/200] [Batch 730/815] [D loss: -4.765826] [G loss: -14.910403]\n",
      "[Epoch 0/200] [Batch 735/815] [D loss: -5.118702] [G loss: -15.631501]\n",
      "[Epoch 0/200] [Batch 740/815] [D loss: -5.363442] [G loss: -24.041508]\n",
      "[Epoch 0/200] [Batch 745/815] [D loss: -4.123810] [G loss: -33.777058]\n",
      "[Epoch 0/200] [Batch 750/815] [D loss: -4.834599] [G loss: -17.156279]\n",
      "[Epoch 0/200] [Batch 755/815] [D loss: -5.426867] [G loss: -23.515755]\n",
      "[Epoch 0/200] [Batch 760/815] [D loss: -5.375447] [G loss: -16.923008]\n",
      "[Epoch 0/200] [Batch 765/815] [D loss: -5.498750] [G loss: -25.009626]\n",
      "[Epoch 0/200] [Batch 770/815] [D loss: -4.626082] [G loss: -18.382851]\n",
      "[Epoch 0/200] [Batch 775/815] [D loss: -5.590087] [G loss: -11.559779]\n",
      "[Epoch 0/200] [Batch 780/815] [D loss: -4.790544] [G loss: -24.124001]\n",
      "[Epoch 0/200] [Batch 785/815] [D loss: -4.429392] [G loss: -22.589233]\n",
      "[Epoch 0/200] [Batch 790/815] [D loss: -5.591379] [G loss: -20.200516]\n",
      "[Epoch 0/200] [Batch 795/815] [D loss: -5.057656] [G loss: -22.553297]\n",
      "[Epoch 0/200] [Batch 800/815] [D loss: -3.456428] [G loss: -55.124100]\n",
      "[Epoch 0/200] [Batch 805/815] [D loss: -4.103758] [G loss: -33.375275]\n",
      "[Epoch 0/200] [Batch 810/815] [D loss: -4.932018] [G loss: -22.660913]\n",
      "[Epoch 1/200] [Batch 0/815] [D loss: -3.865967] [G loss: -18.615566]\n",
      "[Epoch 1/200] [Batch 5/815] [D loss: -5.113828] [G loss: -24.387079]\n",
      "[Epoch 1/200] [Batch 10/815] [D loss: -5.338067] [G loss: -11.581840]\n",
      "[Epoch 1/200] [Batch 15/815] [D loss: -5.105056] [G loss: -19.743212]\n",
      "[Epoch 1/200] [Batch 20/815] [D loss: -5.256080] [G loss: -21.624289]\n",
      "[Epoch 1/200] [Batch 25/815] [D loss: -4.992072] [G loss: -12.884727]\n",
      "[Epoch 1/200] [Batch 30/815] [D loss: -4.517561] [G loss: -24.658216]\n",
      "[Epoch 1/200] [Batch 35/815] [D loss: -4.755833] [G loss: -26.953331]\n",
      "[Epoch 1/200] [Batch 40/815] [D loss: -4.183337] [G loss: -31.113544]\n",
      "[Epoch 1/200] [Batch 45/815] [D loss: -5.918453] [G loss: -18.561033]\n",
      "[Epoch 1/200] [Batch 50/815] [D loss: -5.320318] [G loss: -14.532351]\n",
      "[Epoch 1/200] [Batch 55/815] [D loss: -4.911420] [G loss: -16.690403]\n",
      "[Epoch 1/200] [Batch 60/815] [D loss: -4.983936] [G loss: -14.881088]\n",
      "[Epoch 1/200] [Batch 65/815] [D loss: -4.966567] [G loss: -15.070027]\n",
      "[Epoch 1/200] [Batch 70/815] [D loss: -4.912225] [G loss: -19.824165]\n",
      "[Epoch 1/200] [Batch 75/815] [D loss: -5.270544] [G loss: -18.394625]\n",
      "[Epoch 1/200] [Batch 80/815] [D loss: -5.002394] [G loss: -15.945872]\n",
      "[Epoch 1/200] [Batch 85/815] [D loss: -4.861547] [G loss: -25.022577]\n",
      "[Epoch 1/200] [Batch 90/815] [D loss: -5.620239] [G loss: -14.916203]\n",
      "[Epoch 1/200] [Batch 95/815] [D loss: -4.450566] [G loss: -21.325819]\n",
      "[Epoch 1/200] [Batch 100/815] [D loss: -6.261943] [G loss: -11.257425]\n",
      "[Epoch 1/200] [Batch 105/815] [D loss: -5.651057] [G loss: -12.382100]\n",
      "[Epoch 1/200] [Batch 110/815] [D loss: -3.916087] [G loss: -28.978640]\n",
      "[Epoch 1/200] [Batch 115/815] [D loss: -4.401995] [G loss: -37.651218]\n",
      "[Epoch 1/200] [Batch 120/815] [D loss: -3.383513] [G loss: -27.186411]\n",
      "[Epoch 1/200] [Batch 125/815] [D loss: -4.920931] [G loss: -16.422573]\n",
      "[Epoch 1/200] [Batch 130/815] [D loss: -5.297135] [G loss: -16.906626]\n",
      "[Epoch 1/200] [Batch 135/815] [D loss: -5.380016] [G loss: -12.778483]\n",
      "[Epoch 1/200] [Batch 140/815] [D loss: -5.892330] [G loss: -17.195698]\n",
      "[Epoch 1/200] [Batch 145/815] [D loss: -5.879386] [G loss: -11.246353]\n",
      "[Epoch 1/200] [Batch 150/815] [D loss: -5.903688] [G loss: -25.523878]\n",
      "[Epoch 1/200] [Batch 155/815] [D loss: -4.637193] [G loss: -18.300753]\n",
      "[Epoch 1/200] [Batch 160/815] [D loss: -5.240608] [G loss: -21.428024]\n",
      "[Epoch 1/200] [Batch 165/815] [D loss: -4.647944] [G loss: -25.873070]\n",
      "[Epoch 1/200] [Batch 170/815] [D loss: -4.537811] [G loss: -17.364893]\n",
      "[Epoch 1/200] [Batch 175/815] [D loss: -4.458133] [G loss: -25.504629]\n",
      "[Epoch 1/200] [Batch 180/815] [D loss: -4.948091] [G loss: -16.803324]\n",
      "[Epoch 1/200] [Batch 185/815] [D loss: -4.901279] [G loss: -21.989946]\n",
      "[Epoch 1/200] [Batch 190/815] [D loss: -5.215471] [G loss: -12.963119]\n",
      "[Epoch 1/200] [Batch 195/815] [D loss: -5.797494] [G loss: -12.864077]\n",
      "[Epoch 1/200] [Batch 200/815] [D loss: -5.117195] [G loss: -26.477669]\n",
      "[Epoch 1/200] [Batch 205/815] [D loss: -5.245786] [G loss: -30.380890]\n",
      "[Epoch 1/200] [Batch 210/815] [D loss: -4.532877] [G loss: -19.868553]\n",
      "[Epoch 1/200] [Batch 215/815] [D loss: -4.843380] [G loss: -18.800013]\n",
      "[Epoch 1/200] [Batch 220/815] [D loss: -4.821313] [G loss: -16.661438]\n",
      "[Epoch 1/200] [Batch 225/815] [D loss: -5.513245] [G loss: -13.273705]\n",
      "[Epoch 1/200] [Batch 230/815] [D loss: -2.931926] [G loss: -29.443884]\n",
      "[Epoch 1/200] [Batch 235/815] [D loss: -5.721915] [G loss: -26.308578]\n",
      "[Epoch 1/200] [Batch 240/815] [D loss: -3.847384] [G loss: -31.173506]\n",
      "[Epoch 1/200] [Batch 245/815] [D loss: -4.725893] [G loss: -21.695934]\n",
      "[Epoch 1/200] [Batch 250/815] [D loss: -4.910640] [G loss: -26.650347]\n",
      "[Epoch 1/200] [Batch 255/815] [D loss: -4.322873] [G loss: -16.381592]\n",
      "[Epoch 1/200] [Batch 260/815] [D loss: -4.951533] [G loss: -14.458035]\n",
      "[Epoch 1/200] [Batch 265/815] [D loss: -4.858346] [G loss: -17.024038]\n",
      "[Epoch 1/200] [Batch 270/815] [D loss: -4.626129] [G loss: -26.836506]\n",
      "[Epoch 1/200] [Batch 275/815] [D loss: -4.568321] [G loss: -20.039799]\n",
      "[Epoch 1/200] [Batch 280/815] [D loss: -4.999041] [G loss: -21.477455]\n",
      "[Epoch 1/200] [Batch 285/815] [D loss: -5.033270] [G loss: -15.613342]\n",
      "[Epoch 1/200] [Batch 290/815] [D loss: -4.939378] [G loss: -21.023998]\n",
      "[Epoch 1/200] [Batch 295/815] [D loss: -5.059023] [G loss: -11.917134]\n",
      "[Epoch 1/200] [Batch 300/815] [D loss: -4.762506] [G loss: -18.178808]\n",
      "[Epoch 1/200] [Batch 305/815] [D loss: -6.016550] [G loss: -23.240953]\n",
      "[Epoch 1/200] [Batch 310/815] [D loss: -4.854240] [G loss: -28.599148]\n",
      "[Epoch 1/200] [Batch 315/815] [D loss: -5.415350] [G loss: -12.790190]\n",
      "[Epoch 1/200] [Batch 320/815] [D loss: -5.726073] [G loss: -19.776669]\n",
      "[Epoch 1/200] [Batch 325/815] [D loss: -5.112860] [G loss: -19.514263]\n",
      "[Epoch 1/200] [Batch 330/815] [D loss: -5.016507] [G loss: -28.994101]\n",
      "[Epoch 1/200] [Batch 335/815] [D loss: -5.015594] [G loss: -18.898968]\n",
      "[Epoch 1/200] [Batch 340/815] [D loss: -5.032576] [G loss: -14.292298]\n",
      "[Epoch 1/200] [Batch 345/815] [D loss: -5.754622] [G loss: -13.301929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 350/815] [D loss: -4.492887] [G loss: -25.279736]\n",
      "[Epoch 1/200] [Batch 355/815] [D loss: -3.738382] [G loss: -24.328417]\n",
      "[Epoch 1/200] [Batch 360/815] [D loss: -4.610808] [G loss: -20.882832]\n",
      "[Epoch 1/200] [Batch 365/815] [D loss: -3.713732] [G loss: -31.430363]\n",
      "[Epoch 1/200] [Batch 370/815] [D loss: -5.524736] [G loss: -23.077261]\n",
      "[Epoch 1/200] [Batch 375/815] [D loss: -4.979402] [G loss: -23.893024]\n",
      "[Epoch 1/200] [Batch 380/815] [D loss: -4.843578] [G loss: -32.957684]\n",
      "[Epoch 1/200] [Batch 385/815] [D loss: -4.058051] [G loss: -23.604017]\n",
      "[Epoch 1/200] [Batch 390/815] [D loss: -5.049287] [G loss: -21.154758]\n",
      "[Epoch 1/200] [Batch 395/815] [D loss: -4.873770] [G loss: -23.605249]\n",
      "[Epoch 1/200] [Batch 400/815] [D loss: -5.215153] [G loss: -20.794115]\n",
      "[Epoch 1/200] [Batch 405/815] [D loss: -5.262623] [G loss: -28.631025]\n",
      "[Epoch 1/200] [Batch 410/815] [D loss: -4.094130] [G loss: -30.661709]\n",
      "[Epoch 1/200] [Batch 415/815] [D loss: -4.576552] [G loss: -20.956545]\n",
      "[Epoch 1/200] [Batch 420/815] [D loss: -4.436557] [G loss: -21.489433]\n",
      "[Epoch 1/200] [Batch 425/815] [D loss: -4.209382] [G loss: -24.323727]\n",
      "[Epoch 1/200] [Batch 430/815] [D loss: -4.559494] [G loss: -17.314215]\n",
      "[Epoch 1/200] [Batch 435/815] [D loss: -4.484885] [G loss: -21.736277]\n",
      "[Epoch 1/200] [Batch 440/815] [D loss: -3.583168] [G loss: -28.404982]\n",
      "[Epoch 1/200] [Batch 445/815] [D loss: -4.855669] [G loss: -18.875814]\n",
      "[Epoch 1/200] [Batch 450/815] [D loss: -5.252978] [G loss: -21.816528]\n",
      "[Epoch 1/200] [Batch 455/815] [D loss: -5.295720] [G loss: -18.792133]\n",
      "[Epoch 1/200] [Batch 460/815] [D loss: -5.180569] [G loss: -14.995948]\n",
      "[Epoch 1/200] [Batch 465/815] [D loss: -6.668704] [G loss: -21.207609]\n",
      "[Epoch 1/200] [Batch 470/815] [D loss: -5.095017] [G loss: -23.178244]\n",
      "[Epoch 1/200] [Batch 475/815] [D loss: -4.997540] [G loss: -15.917420]\n",
      "[Epoch 1/200] [Batch 480/815] [D loss: -4.600059] [G loss: -19.482740]\n",
      "[Epoch 1/200] [Batch 485/815] [D loss: -4.923754] [G loss: -21.749800]\n",
      "[Epoch 1/200] [Batch 490/815] [D loss: -5.716918] [G loss: -15.613118]\n",
      "[Epoch 1/200] [Batch 495/815] [D loss: -5.020704] [G loss: -22.459782]\n",
      "[Epoch 1/200] [Batch 500/815] [D loss: -6.395166] [G loss: -13.454464]\n",
      "[Epoch 1/200] [Batch 505/815] [D loss: -5.451865] [G loss: -18.356831]\n",
      "[Epoch 1/200] [Batch 510/815] [D loss: -4.533919] [G loss: -26.645836]\n",
      "[Epoch 1/200] [Batch 515/815] [D loss: -5.598341] [G loss: -12.139184]\n",
      "[Epoch 1/200] [Batch 520/815] [D loss: -5.247192] [G loss: -19.245657]\n",
      "[Epoch 1/200] [Batch 525/815] [D loss: -4.964479] [G loss: -20.630156]\n",
      "[Epoch 1/200] [Batch 530/815] [D loss: -5.478474] [G loss: -18.829336]\n",
      "[Epoch 1/200] [Batch 535/815] [D loss: -6.165002] [G loss: -15.916479]\n",
      "[Epoch 1/200] [Batch 540/815] [D loss: -5.405371] [G loss: -22.366943]\n",
      "[Epoch 1/200] [Batch 545/815] [D loss: -4.468438] [G loss: -20.013069]\n",
      "[Epoch 1/200] [Batch 550/815] [D loss: -5.158496] [G loss: -21.439081]\n",
      "[Epoch 1/200] [Batch 555/815] [D loss: -4.325899] [G loss: -22.360104]\n",
      "[Epoch 1/200] [Batch 560/815] [D loss: -5.794886] [G loss: -11.356988]\n",
      "[Epoch 1/200] [Batch 565/815] [D loss: -5.747841] [G loss: -24.082333]\n",
      "[Epoch 1/200] [Batch 570/815] [D loss: -4.623341] [G loss: -21.837778]\n",
      "[Epoch 1/200] [Batch 575/815] [D loss: -5.097611] [G loss: -15.998919]\n",
      "[Epoch 1/200] [Batch 580/815] [D loss: -5.326678] [G loss: -14.355719]\n",
      "[Epoch 1/200] [Batch 585/815] [D loss: -4.616440] [G loss: -22.895882]\n",
      "[Epoch 1/200] [Batch 590/815] [D loss: -5.957572] [G loss: -16.369972]\n",
      "[Epoch 1/200] [Batch 595/815] [D loss: -4.840202] [G loss: -20.352453]\n",
      "[Epoch 1/200] [Batch 600/815] [D loss: -4.706768] [G loss: -20.320700]\n",
      "[Epoch 1/200] [Batch 605/815] [D loss: -5.253302] [G loss: -18.487688]\n",
      "[Epoch 1/200] [Batch 610/815] [D loss: -4.830038] [G loss: -15.322654]\n",
      "[Epoch 1/200] [Batch 615/815] [D loss: -4.970633] [G loss: -12.199089]\n",
      "[Epoch 1/200] [Batch 620/815] [D loss: -4.879668] [G loss: -13.448246]\n",
      "[Epoch 1/200] [Batch 625/815] [D loss: -5.164126] [G loss: -14.328173]\n",
      "[Epoch 1/200] [Batch 630/815] [D loss: -5.394897] [G loss: -17.275415]\n",
      "[Epoch 1/200] [Batch 635/815] [D loss: -5.381131] [G loss: -23.365175]\n",
      "[Epoch 1/200] [Batch 640/815] [D loss: -4.297956] [G loss: -20.509403]\n",
      "[Epoch 1/200] [Batch 645/815] [D loss: -5.015457] [G loss: -17.917557]\n",
      "[Epoch 1/200] [Batch 650/815] [D loss: -4.996025] [G loss: -15.991014]\n",
      "[Epoch 1/200] [Batch 655/815] [D loss: -4.906427] [G loss: -24.290613]\n",
      "[Epoch 1/200] [Batch 660/815] [D loss: -4.438354] [G loss: -21.039413]\n",
      "[Epoch 1/200] [Batch 665/815] [D loss: -4.810174] [G loss: -17.012423]\n",
      "[Epoch 1/200] [Batch 670/815] [D loss: -4.907768] [G loss: -12.055843]\n",
      "[Epoch 1/200] [Batch 675/815] [D loss: -4.670294] [G loss: -23.022722]\n",
      "[Epoch 1/200] [Batch 680/815] [D loss: -4.449151] [G loss: -18.290003]\n",
      "[Epoch 1/200] [Batch 685/815] [D loss: -4.663168] [G loss: -19.223242]\n",
      "[Epoch 1/200] [Batch 690/815] [D loss: -6.139312] [G loss: -17.912073]\n",
      "[Epoch 1/200] [Batch 695/815] [D loss: -4.409910] [G loss: -29.672487]\n",
      "[Epoch 1/200] [Batch 700/815] [D loss: -4.630983] [G loss: -20.227827]\n",
      "[Epoch 1/200] [Batch 705/815] [D loss: -4.187895] [G loss: -20.681763]\n",
      "[Epoch 1/200] [Batch 710/815] [D loss: -5.789604] [G loss: -25.837942]\n",
      "[Epoch 1/200] [Batch 715/815] [D loss: -4.387786] [G loss: -17.048140]\n",
      "[Epoch 1/200] [Batch 720/815] [D loss: -4.837005] [G loss: -20.381809]\n",
      "[Epoch 1/200] [Batch 725/815] [D loss: -5.139999] [G loss: -19.827532]\n",
      "[Epoch 1/200] [Batch 730/815] [D loss: -4.930604] [G loss: -15.219784]\n",
      "[Epoch 1/200] [Batch 735/815] [D loss: -4.897173] [G loss: -21.947746]\n",
      "[Epoch 1/200] [Batch 740/815] [D loss: -4.616815] [G loss: -27.373732]\n",
      "[Epoch 1/200] [Batch 745/815] [D loss: -5.892716] [G loss: -18.765497]\n",
      "[Epoch 1/200] [Batch 750/815] [D loss: -5.406330] [G loss: -12.015547]\n",
      "[Epoch 1/200] [Batch 755/815] [D loss: -4.359706] [G loss: -20.313633]\n",
      "[Epoch 1/200] [Batch 760/815] [D loss: -5.951695] [G loss: -15.228763]\n",
      "[Epoch 1/200] [Batch 765/815] [D loss: -5.542428] [G loss: -13.724516]\n",
      "[Epoch 1/200] [Batch 770/815] [D loss: -5.462303] [G loss: -18.018671]\n",
      "[Epoch 1/200] [Batch 775/815] [D loss: -6.082968] [G loss: -13.990435]\n",
      "[Epoch 1/200] [Batch 780/815] [D loss: -4.524323] [G loss: -31.514774]\n",
      "[Epoch 1/200] [Batch 785/815] [D loss: -4.773908] [G loss: -25.450729]\n",
      "[Epoch 1/200] [Batch 790/815] [D loss: -5.242125] [G loss: -13.577132]\n",
      "[Epoch 1/200] [Batch 795/815] [D loss: -6.069758] [G loss: -14.056124]\n",
      "[Epoch 1/200] [Batch 800/815] [D loss: -6.329001] [G loss: -18.538601]\n",
      "[Epoch 1/200] [Batch 805/815] [D loss: -5.074363] [G loss: -15.036119]\n",
      "[Epoch 1/200] [Batch 810/815] [D loss: -5.802953] [G loss: -10.640851]\n",
      "[Epoch 2/200] [Batch 0/815] [D loss: -4.067115] [G loss: -29.857540]\n",
      "[Epoch 2/200] [Batch 5/815] [D loss: -5.834367] [G loss: -14.711926]\n",
      "[Epoch 2/200] [Batch 10/815] [D loss: -4.979338] [G loss: -18.972252]\n",
      "[Epoch 2/200] [Batch 15/815] [D loss: -4.891310] [G loss: -21.638393]\n",
      "[Epoch 2/200] [Batch 20/815] [D loss: -6.311396] [G loss: -19.737394]\n",
      "[Epoch 2/200] [Batch 25/815] [D loss: -5.004520] [G loss: -17.154043]\n",
      "[Epoch 2/200] [Batch 30/815] [D loss: -6.054058] [G loss: -12.570875]\n",
      "[Epoch 2/200] [Batch 35/815] [D loss: -5.429493] [G loss: -20.971151]\n",
      "[Epoch 2/200] [Batch 40/815] [D loss: -5.104002] [G loss: -20.182882]\n",
      "[Epoch 2/200] [Batch 45/815] [D loss: -4.577800] [G loss: -21.979517]\n",
      "[Epoch 2/200] [Batch 50/815] [D loss: -5.004782] [G loss: -20.807390]\n",
      "[Epoch 2/200] [Batch 55/815] [D loss: -4.646417] [G loss: -29.749983]\n",
      "[Epoch 2/200] [Batch 60/815] [D loss: -4.828644] [G loss: -21.046705]\n",
      "[Epoch 2/200] [Batch 65/815] [D loss: -5.001768] [G loss: -21.765615]\n",
      "[Epoch 2/200] [Batch 70/815] [D loss: -5.133850] [G loss: -24.762827]\n",
      "[Epoch 2/200] [Batch 75/815] [D loss: -5.257042] [G loss: -12.653008]\n",
      "[Epoch 2/200] [Batch 80/815] [D loss: -4.514153] [G loss: -23.634905]\n",
      "[Epoch 2/200] [Batch 85/815] [D loss: -4.872787] [G loss: -32.464615]\n",
      "[Epoch 2/200] [Batch 90/815] [D loss: -4.571609] [G loss: -20.770594]\n",
      "[Epoch 2/200] [Batch 95/815] [D loss: -5.317195] [G loss: -17.170877]\n",
      "[Epoch 2/200] [Batch 100/815] [D loss: -5.071270] [G loss: -19.554232]\n",
      "[Epoch 2/200] [Batch 105/815] [D loss: -4.168095] [G loss: -31.861357]\n",
      "[Epoch 2/200] [Batch 110/815] [D loss: -4.859572] [G loss: -16.317347]\n",
      "[Epoch 2/200] [Batch 115/815] [D loss: -4.895686] [G loss: -19.969154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 120/815] [D loss: -6.181818] [G loss: -15.993863]\n",
      "[Epoch 2/200] [Batch 125/815] [D loss: -5.168097] [G loss: -16.417250]\n",
      "[Epoch 2/200] [Batch 130/815] [D loss: -5.836532] [G loss: -14.296454]\n",
      "[Epoch 2/200] [Batch 135/815] [D loss: -6.008942] [G loss: -14.191665]\n",
      "[Epoch 2/200] [Batch 140/815] [D loss: -5.841182] [G loss: -23.600376]\n",
      "[Epoch 2/200] [Batch 145/815] [D loss: -5.564143] [G loss: -16.364117]\n",
      "[Epoch 2/200] [Batch 150/815] [D loss: -5.586823] [G loss: -15.999202]\n",
      "[Epoch 2/200] [Batch 155/815] [D loss: -5.794216] [G loss: -16.602539]\n",
      "[Epoch 2/200] [Batch 160/815] [D loss: -5.515720] [G loss: -21.756300]\n",
      "[Epoch 2/200] [Batch 165/815] [D loss: -5.373440] [G loss: -16.167997]\n",
      "[Epoch 2/200] [Batch 170/815] [D loss: -4.347470] [G loss: -28.155409]\n",
      "[Epoch 2/200] [Batch 175/815] [D loss: -4.487490] [G loss: -23.627829]\n",
      "[Epoch 2/200] [Batch 180/815] [D loss: -4.811705] [G loss: -17.013186]\n",
      "[Epoch 2/200] [Batch 185/815] [D loss: -4.126747] [G loss: -20.725803]\n",
      "[Epoch 2/200] [Batch 190/815] [D loss: -5.121532] [G loss: -12.878632]\n",
      "[Epoch 2/200] [Batch 195/815] [D loss: -5.278383] [G loss: -13.237640]\n",
      "[Epoch 2/200] [Batch 200/815] [D loss: -4.692262] [G loss: -23.158257]\n",
      "[Epoch 2/200] [Batch 205/815] [D loss: -4.891035] [G loss: -19.873182]\n",
      "[Epoch 2/200] [Batch 210/815] [D loss: -4.408969] [G loss: -18.720634]\n",
      "[Epoch 2/200] [Batch 215/815] [D loss: -5.732307] [G loss: -13.882730]\n",
      "[Epoch 2/200] [Batch 220/815] [D loss: -6.084086] [G loss: -15.021932]\n",
      "[Epoch 2/200] [Batch 225/815] [D loss: -4.508781] [G loss: -25.867262]\n",
      "[Epoch 2/200] [Batch 230/815] [D loss: -5.882576] [G loss: -17.810602]\n",
      "[Epoch 2/200] [Batch 235/815] [D loss: -5.944210] [G loss: -14.784968]\n",
      "[Epoch 2/200] [Batch 240/815] [D loss: -4.383766] [G loss: -33.863693]\n",
      "[Epoch 2/200] [Batch 245/815] [D loss: -4.554692] [G loss: -18.591658]\n",
      "[Epoch 2/200] [Batch 250/815] [D loss: -3.979610] [G loss: -23.698952]\n",
      "[Epoch 2/200] [Batch 255/815] [D loss: -3.950027] [G loss: -27.867218]\n",
      "[Epoch 2/200] [Batch 260/815] [D loss: -5.348950] [G loss: -15.024700]\n",
      "[Epoch 2/200] [Batch 265/815] [D loss: -4.564908] [G loss: -33.528084]\n",
      "[Epoch 2/200] [Batch 270/815] [D loss: -4.624855] [G loss: -15.060556]\n",
      "[Epoch 2/200] [Batch 275/815] [D loss: -4.963970] [G loss: -17.536901]\n",
      "[Epoch 2/200] [Batch 280/815] [D loss: -4.975499] [G loss: -14.727370]\n",
      "[Epoch 2/200] [Batch 285/815] [D loss: -5.333070] [G loss: -19.572321]\n",
      "[Epoch 2/200] [Batch 290/815] [D loss: -5.692348] [G loss: -12.852027]\n",
      "[Epoch 2/200] [Batch 295/815] [D loss: -5.332252] [G loss: -16.510468]\n",
      "[Epoch 2/200] [Batch 300/815] [D loss: -5.145410] [G loss: -28.242332]\n",
      "[Epoch 2/200] [Batch 305/815] [D loss: -4.528372] [G loss: -15.637069]\n",
      "[Epoch 2/200] [Batch 310/815] [D loss: -4.387585] [G loss: -28.459955]\n",
      "[Epoch 2/200] [Batch 315/815] [D loss: -4.612982] [G loss: -17.309980]\n",
      "[Epoch 2/200] [Batch 320/815] [D loss: -5.311367] [G loss: -16.902107]\n",
      "[Epoch 2/200] [Batch 325/815] [D loss: -5.087907] [G loss: -22.241953]\n",
      "[Epoch 2/200] [Batch 330/815] [D loss: -4.768529] [G loss: -24.156717]\n",
      "[Epoch 2/200] [Batch 335/815] [D loss: -5.232010] [G loss: -15.165183]\n",
      "[Epoch 2/200] [Batch 340/815] [D loss: -5.098446] [G loss: -28.422726]\n",
      "[Epoch 2/200] [Batch 345/815] [D loss: -4.747994] [G loss: -16.993774]\n",
      "[Epoch 2/200] [Batch 350/815] [D loss: -5.288803] [G loss: -13.611651]\n",
      "[Epoch 2/200] [Batch 355/815] [D loss: -4.049009] [G loss: -28.849901]\n",
      "[Epoch 2/200] [Batch 360/815] [D loss: -4.647217] [G loss: -20.547512]\n",
      "[Epoch 2/200] [Batch 365/815] [D loss: -3.901269] [G loss: -29.144785]\n",
      "[Epoch 2/200] [Batch 370/815] [D loss: -4.214622] [G loss: -20.631821]\n",
      "[Epoch 2/200] [Batch 375/815] [D loss: -5.671758] [G loss: -15.875168]\n",
      "[Epoch 2/200] [Batch 380/815] [D loss: -5.519028] [G loss: -25.762552]\n",
      "[Epoch 2/200] [Batch 385/815] [D loss: -3.600930] [G loss: -34.459095]\n",
      "[Epoch 2/200] [Batch 390/815] [D loss: -5.219543] [G loss: -21.946396]\n",
      "[Epoch 2/200] [Batch 395/815] [D loss: -5.203483] [G loss: -16.308592]\n",
      "[Epoch 2/200] [Batch 400/815] [D loss: -4.361074] [G loss: -24.487949]\n",
      "[Epoch 2/200] [Batch 405/815] [D loss: -4.443531] [G loss: -24.450212]\n",
      "[Epoch 2/200] [Batch 410/815] [D loss: -5.907683] [G loss: -11.448743]\n",
      "[Epoch 2/200] [Batch 415/815] [D loss: -6.067270] [G loss: -15.253050]\n",
      "[Epoch 2/200] [Batch 420/815] [D loss: -5.076154] [G loss: -14.156971]\n",
      "[Epoch 2/200] [Batch 425/815] [D loss: -4.459994] [G loss: -27.128283]\n",
      "[Epoch 2/200] [Batch 430/815] [D loss: -5.429698] [G loss: -12.926636]\n",
      "[Epoch 2/200] [Batch 435/815] [D loss: -5.115199] [G loss: -30.232031]\n",
      "[Epoch 2/200] [Batch 440/815] [D loss: -5.033537] [G loss: -21.417778]\n",
      "[Epoch 2/200] [Batch 445/815] [D loss: -4.852787] [G loss: -18.077366]\n",
      "[Epoch 2/200] [Batch 450/815] [D loss: -5.613256] [G loss: -15.630297]\n",
      "[Epoch 2/200] [Batch 455/815] [D loss: -5.681916] [G loss: -13.873719]\n",
      "[Epoch 2/200] [Batch 460/815] [D loss: -4.896015] [G loss: -20.931942]\n",
      "[Epoch 2/200] [Batch 465/815] [D loss: -5.324094] [G loss: -20.163395]\n",
      "[Epoch 2/200] [Batch 470/815] [D loss: -5.242244] [G loss: -20.617706]\n",
      "[Epoch 2/200] [Batch 475/815] [D loss: -4.326427] [G loss: -27.092381]\n",
      "[Epoch 2/200] [Batch 480/815] [D loss: -4.037024] [G loss: -26.395451]\n",
      "[Epoch 2/200] [Batch 485/815] [D loss: -5.441955] [G loss: -16.157372]\n",
      "[Epoch 2/200] [Batch 490/815] [D loss: -5.097210] [G loss: -22.406599]\n",
      "[Epoch 2/200] [Batch 495/815] [D loss: -6.290820] [G loss: -10.494520]\n",
      "[Epoch 2/200] [Batch 500/815] [D loss: -5.466547] [G loss: -16.332392]\n",
      "[Epoch 2/200] [Batch 505/815] [D loss: -4.715304] [G loss: -22.403578]\n",
      "[Epoch 2/200] [Batch 510/815] [D loss: -5.852089] [G loss: -10.477156]\n",
      "[Epoch 2/200] [Batch 515/815] [D loss: -5.305091] [G loss: -20.642277]\n",
      "[Epoch 2/200] [Batch 520/815] [D loss: -4.972090] [G loss: -21.187817]\n",
      "[Epoch 2/200] [Batch 525/815] [D loss: -4.605316] [G loss: -18.562260]\n",
      "[Epoch 2/200] [Batch 530/815] [D loss: -5.510943] [G loss: -14.627131]\n",
      "[Epoch 2/200] [Batch 535/815] [D loss: -4.981882] [G loss: -16.108673]\n",
      "[Epoch 2/200] [Batch 540/815] [D loss: -5.535305] [G loss: -15.814385]\n",
      "[Epoch 2/200] [Batch 545/815] [D loss: -5.927821] [G loss: -14.621395]\n",
      "[Epoch 2/200] [Batch 550/815] [D loss: -5.128125] [G loss: -17.884291]\n",
      "[Epoch 2/200] [Batch 555/815] [D loss: -6.028979] [G loss: -11.293628]\n",
      "[Epoch 2/200] [Batch 560/815] [D loss: -6.186668] [G loss: -10.027744]\n",
      "[Epoch 2/200] [Batch 565/815] [D loss: -5.440104] [G loss: -18.971523]\n",
      "[Epoch 2/200] [Batch 570/815] [D loss: -5.034203] [G loss: -20.624336]\n",
      "[Epoch 2/200] [Batch 575/815] [D loss: -5.156083] [G loss: -20.809023]\n",
      "[Epoch 2/200] [Batch 580/815] [D loss: -5.813771] [G loss: -14.249592]\n",
      "[Epoch 2/200] [Batch 585/815] [D loss: -4.505357] [G loss: -30.026979]\n",
      "[Epoch 2/200] [Batch 590/815] [D loss: -5.800034] [G loss: -14.024471]\n",
      "[Epoch 2/200] [Batch 595/815] [D loss: -5.887118] [G loss: -12.024055]\n",
      "[Epoch 2/200] [Batch 600/815] [D loss: -5.131197] [G loss: -17.594120]\n",
      "[Epoch 2/200] [Batch 605/815] [D loss: -5.006014] [G loss: -25.258879]\n",
      "[Epoch 2/200] [Batch 610/815] [D loss: -5.266504] [G loss: -13.099309]\n",
      "[Epoch 2/200] [Batch 615/815] [D loss: -5.830927] [G loss: -14.016951]\n",
      "[Epoch 2/200] [Batch 620/815] [D loss: -4.152973] [G loss: -27.319183]\n",
      "[Epoch 2/200] [Batch 625/815] [D loss: -3.337408] [G loss: -24.466230]\n",
      "[Epoch 2/200] [Batch 630/815] [D loss: -4.945176] [G loss: -21.596577]\n",
      "[Epoch 2/200] [Batch 635/815] [D loss: -4.106515] [G loss: -23.571629]\n",
      "[Epoch 2/200] [Batch 640/815] [D loss: -5.084117] [G loss: -15.120658]\n",
      "[Epoch 2/200] [Batch 645/815] [D loss: -5.354478] [G loss: -15.136327]\n",
      "[Epoch 2/200] [Batch 650/815] [D loss: -4.671926] [G loss: -28.647848]\n",
      "[Epoch 2/200] [Batch 655/815] [D loss: -5.180652] [G loss: -24.198481]\n",
      "[Epoch 2/200] [Batch 660/815] [D loss: -5.534578] [G loss: -17.947311]\n",
      "[Epoch 2/200] [Batch 665/815] [D loss: -5.294322] [G loss: -14.728699]\n",
      "[Epoch 2/200] [Batch 670/815] [D loss: -5.463800] [G loss: -17.979490]\n",
      "[Epoch 2/200] [Batch 675/815] [D loss: -4.787869] [G loss: -33.353302]\n",
      "[Epoch 2/200] [Batch 680/815] [D loss: -5.285355] [G loss: -15.868060]\n",
      "[Epoch 2/200] [Batch 685/815] [D loss: -5.176401] [G loss: -23.208391]\n",
      "[Epoch 2/200] [Batch 690/815] [D loss: -5.457919] [G loss: -15.344571]\n",
      "[Epoch 2/200] [Batch 695/815] [D loss: -4.542223] [G loss: -25.495897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 700/815] [D loss: -4.263895] [G loss: -34.927174]\n",
      "[Epoch 2/200] [Batch 705/815] [D loss: -4.491981] [G loss: -27.283791]\n",
      "[Epoch 2/200] [Batch 710/815] [D loss: -4.582393] [G loss: -27.769751]\n",
      "[Epoch 2/200] [Batch 715/815] [D loss: -4.691870] [G loss: -18.148865]\n",
      "[Epoch 2/200] [Batch 720/815] [D loss: -4.580259] [G loss: -20.294664]\n",
      "[Epoch 2/200] [Batch 725/815] [D loss: -5.083668] [G loss: -17.739964]\n",
      "[Epoch 2/200] [Batch 730/815] [D loss: -6.142824] [G loss: -19.871464]\n",
      "[Epoch 2/200] [Batch 735/815] [D loss: -4.642027] [G loss: -28.547817]\n",
      "[Epoch 2/200] [Batch 740/815] [D loss: -5.725635] [G loss: -18.805687]\n",
      "[Epoch 2/200] [Batch 745/815] [D loss: -4.696927] [G loss: -19.385223]\n",
      "[Epoch 2/200] [Batch 750/815] [D loss: -4.713256] [G loss: -16.629835]\n",
      "[Epoch 2/200] [Batch 755/815] [D loss: -5.537938] [G loss: -16.493715]\n",
      "[Epoch 2/200] [Batch 760/815] [D loss: -5.291945] [G loss: -20.046896]\n",
      "[Epoch 2/200] [Batch 765/815] [D loss: -4.684738] [G loss: -15.802648]\n",
      "[Epoch 2/200] [Batch 770/815] [D loss: -5.708119] [G loss: -14.897426]\n",
      "[Epoch 2/200] [Batch 775/815] [D loss: -5.386373] [G loss: -27.117355]\n",
      "[Epoch 2/200] [Batch 780/815] [D loss: -4.521589] [G loss: -22.261953]\n",
      "[Epoch 2/200] [Batch 785/815] [D loss: -5.969360] [G loss: -13.092169]\n",
      "[Epoch 2/200] [Batch 790/815] [D loss: -5.281132] [G loss: -23.997578]\n",
      "[Epoch 2/200] [Batch 795/815] [D loss: -4.550096] [G loss: -37.061962]\n",
      "[Epoch 2/200] [Batch 800/815] [D loss: -5.987785] [G loss: -16.528929]\n",
      "[Epoch 2/200] [Batch 805/815] [D loss: -4.782086] [G loss: -13.426970]\n",
      "[Epoch 2/200] [Batch 810/815] [D loss: -5.023678] [G loss: -18.038128]\n",
      "[Epoch 3/200] [Batch 0/815] [D loss: -5.759396] [G loss: -16.503952]\n",
      "[Epoch 3/200] [Batch 5/815] [D loss: -5.803003] [G loss: -18.014351]\n",
      "[Epoch 3/200] [Batch 10/815] [D loss: -5.707626] [G loss: -21.554760]\n",
      "[Epoch 3/200] [Batch 15/815] [D loss: -4.342808] [G loss: -26.271858]\n",
      "[Epoch 3/200] [Batch 20/815] [D loss: -4.394170] [G loss: -28.916050]\n",
      "[Epoch 3/200] [Batch 25/815] [D loss: -5.116109] [G loss: -18.283306]\n",
      "[Epoch 3/200] [Batch 30/815] [D loss: -5.167128] [G loss: -15.341646]\n",
      "[Epoch 3/200] [Batch 35/815] [D loss: -6.747784] [G loss: -15.158239]\n",
      "[Epoch 3/200] [Batch 40/815] [D loss: -4.371647] [G loss: -27.097496]\n",
      "[Epoch 3/200] [Batch 45/815] [D loss: -5.638209] [G loss: -13.436368]\n",
      "[Epoch 3/200] [Batch 50/815] [D loss: -6.051904] [G loss: -18.086981]\n",
      "[Epoch 3/200] [Batch 55/815] [D loss: -4.810982] [G loss: -21.790119]\n",
      "[Epoch 3/200] [Batch 60/815] [D loss: -4.981133] [G loss: -12.984371]\n",
      "[Epoch 3/200] [Batch 65/815] [D loss: -5.290508] [G loss: -11.296997]\n",
      "[Epoch 3/200] [Batch 70/815] [D loss: -4.581553] [G loss: -21.402990]\n",
      "[Epoch 3/200] [Batch 75/815] [D loss: -4.101101] [G loss: -31.930975]\n",
      "[Epoch 3/200] [Batch 80/815] [D loss: -4.991963] [G loss: -28.653585]\n",
      "[Epoch 3/200] [Batch 85/815] [D loss: -4.866984] [G loss: -20.983982]\n",
      "[Epoch 3/200] [Batch 90/815] [D loss: -4.782223] [G loss: -19.329054]\n",
      "[Epoch 3/200] [Batch 95/815] [D loss: -5.709538] [G loss: -15.139355]\n",
      "[Epoch 3/200] [Batch 100/815] [D loss: -4.861046] [G loss: -24.412174]\n",
      "[Epoch 3/200] [Batch 105/815] [D loss: -4.994867] [G loss: -17.495924]\n",
      "[Epoch 3/200] [Batch 110/815] [D loss: -3.532931] [G loss: -43.439507]\n",
      "[Epoch 3/200] [Batch 115/815] [D loss: -4.938004] [G loss: -13.808868]\n",
      "[Epoch 3/200] [Batch 120/815] [D loss: -4.966541] [G loss: -19.906796]\n",
      "[Epoch 3/200] [Batch 125/815] [D loss: -4.237395] [G loss: -23.227743]\n",
      "[Epoch 3/200] [Batch 130/815] [D loss: -4.976737] [G loss: -16.733484]\n",
      "[Epoch 3/200] [Batch 135/815] [D loss: -5.121509] [G loss: -20.130466]\n",
      "[Epoch 3/200] [Batch 140/815] [D loss: -5.242950] [G loss: -17.310575]\n",
      "[Epoch 3/200] [Batch 145/815] [D loss: -5.184094] [G loss: -15.622394]\n",
      "[Epoch 3/200] [Batch 150/815] [D loss: -5.756759] [G loss: -19.783543]\n",
      "[Epoch 3/200] [Batch 155/815] [D loss: -6.085485] [G loss: -10.020451]\n",
      "[Epoch 3/200] [Batch 160/815] [D loss: -5.253306] [G loss: -15.727393]\n",
      "[Epoch 3/200] [Batch 165/815] [D loss: -5.934420] [G loss: -12.136339]\n",
      "[Epoch 3/200] [Batch 170/815] [D loss: -6.034131] [G loss: -10.923255]\n",
      "[Epoch 3/200] [Batch 175/815] [D loss: -5.331866] [G loss: -20.594851]\n",
      "[Epoch 3/200] [Batch 180/815] [D loss: -5.592595] [G loss: -24.243483]\n",
      "[Epoch 3/200] [Batch 185/815] [D loss: -4.963853] [G loss: -15.243895]\n",
      "[Epoch 3/200] [Batch 190/815] [D loss: -5.367979] [G loss: -14.492847]\n",
      "[Epoch 3/200] [Batch 195/815] [D loss: -5.958586] [G loss: -13.580564]\n",
      "[Epoch 3/200] [Batch 200/815] [D loss: -5.157805] [G loss: -17.090528]\n",
      "[Epoch 3/200] [Batch 205/815] [D loss: -5.479163] [G loss: -14.376798]\n",
      "[Epoch 3/200] [Batch 210/815] [D loss: -4.099710] [G loss: -29.854548]\n",
      "[Epoch 3/200] [Batch 215/815] [D loss: -6.009082] [G loss: -10.645684]\n",
      "[Epoch 3/200] [Batch 220/815] [D loss: -4.416932] [G loss: -26.686508]\n",
      "[Epoch 3/200] [Batch 225/815] [D loss: -5.473651] [G loss: -16.544622]\n",
      "[Epoch 3/200] [Batch 230/815] [D loss: -5.054868] [G loss: -21.740158]\n",
      "[Epoch 3/200] [Batch 235/815] [D loss: -4.748030] [G loss: -17.597706]\n",
      "[Epoch 3/200] [Batch 240/815] [D loss: -5.085189] [G loss: -19.006704]\n",
      "[Epoch 3/200] [Batch 245/815] [D loss: -5.444585] [G loss: -20.151489]\n",
      "[Epoch 3/200] [Batch 250/815] [D loss: -5.967750] [G loss: -15.055382]\n",
      "[Epoch 3/200] [Batch 255/815] [D loss: -4.567307] [G loss: -23.448469]\n",
      "[Epoch 3/200] [Batch 260/815] [D loss: -4.934754] [G loss: -22.975782]\n",
      "[Epoch 3/200] [Batch 265/815] [D loss: -6.348094] [G loss: -12.467322]\n",
      "[Epoch 3/200] [Batch 270/815] [D loss: -5.543461] [G loss: -25.717651]\n",
      "[Epoch 3/200] [Batch 275/815] [D loss: -6.271219] [G loss: -12.917695]\n",
      "[Epoch 3/200] [Batch 280/815] [D loss: -4.375265] [G loss: -32.247147]\n",
      "[Epoch 3/200] [Batch 285/815] [D loss: -4.738567] [G loss: -21.703547]\n",
      "[Epoch 3/200] [Batch 290/815] [D loss: -4.307925] [G loss: -17.677948]\n",
      "[Epoch 3/200] [Batch 295/815] [D loss: -4.589262] [G loss: -24.729292]\n",
      "[Epoch 3/200] [Batch 300/815] [D loss: -4.192696] [G loss: -13.680539]\n",
      "[Epoch 3/200] [Batch 305/815] [D loss: -4.682608] [G loss: -21.907822]\n",
      "[Epoch 3/200] [Batch 310/815] [D loss: -3.824808] [G loss: -42.585220]\n",
      "[Epoch 3/200] [Batch 315/815] [D loss: -4.174169] [G loss: -24.739380]\n",
      "[Epoch 3/200] [Batch 320/815] [D loss: -4.781156] [G loss: -17.580343]\n",
      "[Epoch 3/200] [Batch 325/815] [D loss: -4.755484] [G loss: -25.218506]\n",
      "[Epoch 3/200] [Batch 330/815] [D loss: -4.621738] [G loss: -18.593321]\n",
      "[Epoch 3/200] [Batch 335/815] [D loss: -5.037477] [G loss: -13.744679]\n",
      "[Epoch 3/200] [Batch 340/815] [D loss: -4.925281] [G loss: -25.878298]\n",
      "[Epoch 3/200] [Batch 345/815] [D loss: -6.115072] [G loss: -13.160229]\n",
      "[Epoch 3/200] [Batch 350/815] [D loss: -5.942221] [G loss: -11.829496]\n",
      "[Epoch 3/200] [Batch 355/815] [D loss: -4.142795] [G loss: -29.143896]\n",
      "[Epoch 3/200] [Batch 360/815] [D loss: -4.639221] [G loss: -15.850984]\n",
      "[Epoch 3/200] [Batch 365/815] [D loss: -5.278159] [G loss: -18.757063]\n",
      "[Epoch 3/200] [Batch 370/815] [D loss: -5.145137] [G loss: -16.589243]\n",
      "[Epoch 3/200] [Batch 375/815] [D loss: -4.597382] [G loss: -20.794119]\n",
      "[Epoch 3/200] [Batch 380/815] [D loss: -5.029140] [G loss: -17.827383]\n",
      "[Epoch 3/200] [Batch 385/815] [D loss: -6.326614] [G loss: -17.002533]\n",
      "[Epoch 3/200] [Batch 390/815] [D loss: -4.852138] [G loss: -19.840588]\n",
      "[Epoch 3/200] [Batch 395/815] [D loss: -4.882041] [G loss: -20.184557]\n",
      "[Epoch 3/200] [Batch 400/815] [D loss: -5.366657] [G loss: -16.393658]\n",
      "[Epoch 3/200] [Batch 405/815] [D loss: -5.473260] [G loss: -13.541833]\n",
      "[Epoch 3/200] [Batch 410/815] [D loss: -5.267368] [G loss: -20.639893]\n",
      "[Epoch 3/200] [Batch 415/815] [D loss: -5.930133] [G loss: -16.517429]\n",
      "[Epoch 3/200] [Batch 420/815] [D loss: -4.371258] [G loss: -27.280907]\n",
      "[Epoch 3/200] [Batch 425/815] [D loss: -5.297199] [G loss: -17.850691]\n",
      "[Epoch 3/200] [Batch 430/815] [D loss: -5.022337] [G loss: -17.987537]\n",
      "[Epoch 3/200] [Batch 435/815] [D loss: -5.578136] [G loss: -15.573663]\n",
      "[Epoch 3/200] [Batch 440/815] [D loss: -5.530843] [G loss: -22.574175]\n",
      "[Epoch 3/200] [Batch 445/815] [D loss: -5.638308] [G loss: -21.159740]\n",
      "[Epoch 3/200] [Batch 450/815] [D loss: -4.036637] [G loss: -21.181765]\n",
      "[Epoch 3/200] [Batch 455/815] [D loss: -5.290472] [G loss: -11.118940]\n",
      "[Epoch 3/200] [Batch 460/815] [D loss: -5.414767] [G loss: -16.049616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 465/815] [D loss: -5.891487] [G loss: -16.168116]\n",
      "[Epoch 3/200] [Batch 470/815] [D loss: -4.989245] [G loss: -25.888084]\n",
      "[Epoch 3/200] [Batch 475/815] [D loss: -5.195458] [G loss: -16.671949]\n",
      "[Epoch 3/200] [Batch 480/815] [D loss: -5.679863] [G loss: -11.663747]\n",
      "[Epoch 3/200] [Batch 485/815] [D loss: -2.896311] [G loss: -42.494400]\n",
      "[Epoch 3/200] [Batch 490/815] [D loss: -4.739523] [G loss: -21.671652]\n",
      "[Epoch 3/200] [Batch 495/815] [D loss: -4.545610] [G loss: -14.850622]\n",
      "[Epoch 3/200] [Batch 500/815] [D loss: -5.440955] [G loss: -14.777917]\n",
      "[Epoch 3/200] [Batch 505/815] [D loss: -5.126044] [G loss: -17.441076]\n",
      "[Epoch 3/200] [Batch 510/815] [D loss: -4.767344] [G loss: -18.486341]\n",
      "[Epoch 3/200] [Batch 515/815] [D loss: -5.485389] [G loss: -11.495197]\n",
      "[Epoch 3/200] [Batch 520/815] [D loss: -5.887033] [G loss: -14.600313]\n",
      "[Epoch 3/200] [Batch 525/815] [D loss: -5.495420] [G loss: -14.544327]\n",
      "[Epoch 3/200] [Batch 530/815] [D loss: -5.392673] [G loss: -14.749199]\n",
      "[Epoch 3/200] [Batch 535/815] [D loss: -4.762485] [G loss: -21.897585]\n",
      "[Epoch 3/200] [Batch 540/815] [D loss: -4.930775] [G loss: -16.235811]\n",
      "[Epoch 3/200] [Batch 545/815] [D loss: -4.521867] [G loss: -21.857029]\n",
      "[Epoch 3/200] [Batch 550/815] [D loss: -5.329509] [G loss: -11.912760]\n",
      "[Epoch 3/200] [Batch 555/815] [D loss: -6.190452] [G loss: -19.081882]\n",
      "[Epoch 3/200] [Batch 560/815] [D loss: -6.027600] [G loss: -13.794304]\n",
      "[Epoch 3/200] [Batch 565/815] [D loss: -4.532767] [G loss: -18.637428]\n",
      "[Epoch 3/200] [Batch 570/815] [D loss: -4.430712] [G loss: -19.785652]\n",
      "[Epoch 3/200] [Batch 575/815] [D loss: -4.957397] [G loss: -15.357910]\n",
      "[Epoch 3/200] [Batch 580/815] [D loss: -4.288006] [G loss: -30.451891]\n",
      "[Epoch 3/200] [Batch 585/815] [D loss: -4.278495] [G loss: -14.233089]\n",
      "[Epoch 3/200] [Batch 590/815] [D loss: -5.408337] [G loss: -14.713115]\n",
      "[Epoch 3/200] [Batch 595/815] [D loss: -5.538214] [G loss: -13.312484]\n",
      "[Epoch 3/200] [Batch 600/815] [D loss: -6.131479] [G loss: -11.954586]\n",
      "[Epoch 3/200] [Batch 605/815] [D loss: -5.996188] [G loss: -17.218060]\n",
      "[Epoch 3/200] [Batch 610/815] [D loss: -4.602870] [G loss: -28.687063]\n",
      "[Epoch 3/200] [Batch 615/815] [D loss: -5.067657] [G loss: -18.132372]\n",
      "[Epoch 3/200] [Batch 620/815] [D loss: -6.055553] [G loss: -12.608696]\n",
      "[Epoch 3/200] [Batch 625/815] [D loss: -5.941412] [G loss: -23.210642]\n",
      "[Epoch 3/200] [Batch 630/815] [D loss: -5.521127] [G loss: -20.193756]\n",
      "[Epoch 3/200] [Batch 635/815] [D loss: -6.163991] [G loss: -12.824826]\n",
      "[Epoch 3/200] [Batch 640/815] [D loss: -4.784030] [G loss: -19.866432]\n",
      "[Epoch 3/200] [Batch 645/815] [D loss: -5.681075] [G loss: -17.935324]\n",
      "[Epoch 3/200] [Batch 650/815] [D loss: -5.045602] [G loss: -21.502653]\n",
      "[Epoch 3/200] [Batch 655/815] [D loss: -5.013814] [G loss: -19.626564]\n",
      "[Epoch 3/200] [Batch 660/815] [D loss: -5.535272] [G loss: -14.780698]\n",
      "[Epoch 3/200] [Batch 665/815] [D loss: -5.301475] [G loss: -27.205515]\n",
      "[Epoch 3/200] [Batch 670/815] [D loss: -4.311099] [G loss: -23.324097]\n",
      "[Epoch 3/200] [Batch 675/815] [D loss: -5.339468] [G loss: -14.795820]\n",
      "[Epoch 3/200] [Batch 680/815] [D loss: -4.998888] [G loss: -21.188618]\n",
      "[Epoch 3/200] [Batch 685/815] [D loss: -5.740685] [G loss: -17.393076]\n",
      "[Epoch 3/200] [Batch 690/815] [D loss: -5.312374] [G loss: -18.169300]\n",
      "[Epoch 3/200] [Batch 695/815] [D loss: -5.606279] [G loss: -17.733664]\n",
      "[Epoch 3/200] [Batch 700/815] [D loss: -4.851202] [G loss: -22.398054]\n",
      "[Epoch 3/200] [Batch 705/815] [D loss: -5.236920] [G loss: -24.484144]\n",
      "[Epoch 3/200] [Batch 710/815] [D loss: -5.388270] [G loss: -16.105001]\n",
      "[Epoch 3/200] [Batch 715/815] [D loss: -5.486526] [G loss: -14.338616]\n",
      "[Epoch 3/200] [Batch 720/815] [D loss: -5.317464] [G loss: -13.952959]\n",
      "[Epoch 3/200] [Batch 725/815] [D loss: -4.499160] [G loss: -24.421005]\n",
      "[Epoch 3/200] [Batch 730/815] [D loss: -5.438272] [G loss: -17.706440]\n",
      "[Epoch 3/200] [Batch 735/815] [D loss: -4.823550] [G loss: -17.191442]\n",
      "[Epoch 3/200] [Batch 740/815] [D loss: -5.093879] [G loss: -20.676735]\n",
      "[Epoch 3/200] [Batch 745/815] [D loss: -4.993513] [G loss: -17.683565]\n",
      "[Epoch 3/200] [Batch 750/815] [D loss: -4.415021] [G loss: -23.618879]\n",
      "[Epoch 3/200] [Batch 755/815] [D loss: -5.696565] [G loss: -16.127151]\n",
      "[Epoch 3/200] [Batch 760/815] [D loss: -5.768745] [G loss: -14.735052]\n",
      "[Epoch 3/200] [Batch 765/815] [D loss: -6.177928] [G loss: -13.917711]\n",
      "[Epoch 3/200] [Batch 770/815] [D loss: -5.742613] [G loss: -18.336658]\n",
      "[Epoch 3/200] [Batch 775/815] [D loss: -4.485511] [G loss: -22.363905]\n",
      "[Epoch 3/200] [Batch 780/815] [D loss: -4.151133] [G loss: -29.394444]\n",
      "[Epoch 3/200] [Batch 785/815] [D loss: -5.556604] [G loss: -17.370317]\n",
      "[Epoch 3/200] [Batch 790/815] [D loss: -5.300673] [G loss: -17.651537]\n",
      "[Epoch 3/200] [Batch 795/815] [D loss: -5.759966] [G loss: -11.917141]\n",
      "[Epoch 3/200] [Batch 800/815] [D loss: -5.892950] [G loss: -19.735510]\n",
      "[Epoch 3/200] [Batch 805/815] [D loss: -5.251274] [G loss: -16.822767]\n",
      "[Epoch 3/200] [Batch 810/815] [D loss: -5.476715] [G loss: -13.379194]\n",
      "[Epoch 4/200] [Batch 0/815] [D loss: -4.694383] [G loss: -30.621582]\n",
      "[Epoch 4/200] [Batch 5/815] [D loss: -3.698364] [G loss: -34.200054]\n",
      "[Epoch 4/200] [Batch 10/815] [D loss: -4.936934] [G loss: -20.950283]\n",
      "[Epoch 4/200] [Batch 15/815] [D loss: -5.519032] [G loss: -15.967155]\n",
      "[Epoch 4/200] [Batch 20/815] [D loss: -4.948731] [G loss: -15.447572]\n",
      "[Epoch 4/200] [Batch 25/815] [D loss: -4.898084] [G loss: -15.662689]\n",
      "[Epoch 4/200] [Batch 30/815] [D loss: -5.706632] [G loss: -14.444934]\n",
      "[Epoch 4/200] [Batch 35/815] [D loss: -5.730066] [G loss: -25.131378]\n",
      "[Epoch 4/200] [Batch 40/815] [D loss: -5.538411] [G loss: -14.723015]\n",
      "[Epoch 4/200] [Batch 45/815] [D loss: -5.579945] [G loss: -16.174446]\n",
      "[Epoch 4/200] [Batch 50/815] [D loss: -5.861061] [G loss: -22.729500]\n",
      "[Epoch 4/200] [Batch 55/815] [D loss: -5.486375] [G loss: -18.230860]\n",
      "[Epoch 4/200] [Batch 60/815] [D loss: -5.453326] [G loss: -13.696644]\n",
      "[Epoch 4/200] [Batch 65/815] [D loss: -3.688805] [G loss: -22.562874]\n",
      "[Epoch 4/200] [Batch 70/815] [D loss: -5.871277] [G loss: -15.753219]\n",
      "[Epoch 4/200] [Batch 75/815] [D loss: -5.558127] [G loss: -25.499340]\n",
      "[Epoch 4/200] [Batch 80/815] [D loss: -4.871638] [G loss: -17.668869]\n",
      "[Epoch 4/200] [Batch 85/815] [D loss: -5.009696] [G loss: -28.240978]\n",
      "[Epoch 4/200] [Batch 90/815] [D loss: -5.070218] [G loss: -18.410547]\n",
      "[Epoch 4/200] [Batch 95/815] [D loss: -5.186875] [G loss: -13.548691]\n",
      "[Epoch 4/200] [Batch 100/815] [D loss: -4.802940] [G loss: -23.990200]\n",
      "[Epoch 4/200] [Batch 105/815] [D loss: -6.226645] [G loss: -11.706644]\n",
      "[Epoch 4/200] [Batch 110/815] [D loss: -5.141562] [G loss: -22.913881]\n",
      "[Epoch 4/200] [Batch 115/815] [D loss: -6.077464] [G loss: -15.029068]\n",
      "[Epoch 4/200] [Batch 120/815] [D loss: -5.601430] [G loss: -18.051617]\n",
      "[Epoch 4/200] [Batch 125/815] [D loss: -5.354719] [G loss: -26.201607]\n",
      "[Epoch 4/200] [Batch 130/815] [D loss: -5.823990] [G loss: -13.275179]\n",
      "[Epoch 4/200] [Batch 135/815] [D loss: -5.383882] [G loss: -21.362413]\n",
      "[Epoch 4/200] [Batch 140/815] [D loss: -5.347937] [G loss: -22.078926]\n",
      "[Epoch 4/200] [Batch 145/815] [D loss: -4.740685] [G loss: -23.655447]\n",
      "[Epoch 4/200] [Batch 150/815] [D loss: -5.131763] [G loss: -25.893620]\n",
      "[Epoch 4/200] [Batch 155/815] [D loss: -4.479864] [G loss: -16.194441]\n",
      "[Epoch 4/200] [Batch 160/815] [D loss: -5.009575] [G loss: -12.509467]\n",
      "[Epoch 4/200] [Batch 165/815] [D loss: -4.255441] [G loss: -31.388540]\n",
      "[Epoch 4/200] [Batch 170/815] [D loss: -5.944710] [G loss: -15.644366]\n",
      "[Epoch 4/200] [Batch 175/815] [D loss: -4.651599] [G loss: -27.069649]\n",
      "[Epoch 4/200] [Batch 180/815] [D loss: -5.154048] [G loss: -20.408905]\n",
      "[Epoch 4/200] [Batch 185/815] [D loss: -4.448198] [G loss: -21.121855]\n",
      "[Epoch 4/200] [Batch 190/815] [D loss: -4.563281] [G loss: -19.000896]\n",
      "[Epoch 4/200] [Batch 195/815] [D loss: -5.310931] [G loss: -22.661629]\n",
      "[Epoch 4/200] [Batch 200/815] [D loss: -5.501382] [G loss: -15.301082]\n",
      "[Epoch 4/200] [Batch 205/815] [D loss: -5.853045] [G loss: -15.969758]\n",
      "[Epoch 4/200] [Batch 210/815] [D loss: -5.610131] [G loss: -16.442425]\n",
      "[Epoch 4/200] [Batch 215/815] [D loss: -5.624286] [G loss: -23.374357]\n",
      "[Epoch 4/200] [Batch 220/815] [D loss: -4.712921] [G loss: -21.892714]\n",
      "[Epoch 4/200] [Batch 225/815] [D loss: -5.931771] [G loss: -17.851057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 230/815] [D loss: -4.488782] [G loss: -30.253174]\n",
      "[Epoch 4/200] [Batch 235/815] [D loss: -5.667208] [G loss: -20.579321]\n",
      "[Epoch 4/200] [Batch 240/815] [D loss: -5.444177] [G loss: -11.640599]\n",
      "[Epoch 4/200] [Batch 245/815] [D loss: -5.497257] [G loss: -20.531006]\n",
      "[Epoch 4/200] [Batch 250/815] [D loss: -5.044823] [G loss: -16.659113]\n",
      "[Epoch 4/200] [Batch 255/815] [D loss: -5.513030] [G loss: -14.900674]\n",
      "[Epoch 4/200] [Batch 260/815] [D loss: -5.079685] [G loss: -27.901134]\n",
      "[Epoch 4/200] [Batch 265/815] [D loss: -6.141220] [G loss: -12.944734]\n",
      "[Epoch 4/200] [Batch 270/815] [D loss: -5.461478] [G loss: -17.772644]\n",
      "[Epoch 4/200] [Batch 275/815] [D loss: -5.671717] [G loss: -17.478636]\n",
      "[Epoch 4/200] [Batch 280/815] [D loss: -5.223181] [G loss: -21.154787]\n",
      "[Epoch 4/200] [Batch 285/815] [D loss: -4.990214] [G loss: -21.568928]\n",
      "[Epoch 4/200] [Batch 290/815] [D loss: -5.682234] [G loss: -14.952456]\n",
      "[Epoch 4/200] [Batch 295/815] [D loss: -5.617064] [G loss: -18.658022]\n",
      "[Epoch 4/200] [Batch 300/815] [D loss: -4.383576] [G loss: -25.531601]\n",
      "[Epoch 4/200] [Batch 305/815] [D loss: -5.524973] [G loss: -23.413923]\n",
      "[Epoch 4/200] [Batch 310/815] [D loss: -4.828314] [G loss: -17.858521]\n",
      "[Epoch 4/200] [Batch 315/815] [D loss: -3.974906] [G loss: -28.179329]\n",
      "[Epoch 4/200] [Batch 320/815] [D loss: -4.793206] [G loss: -29.193911]\n",
      "[Epoch 4/200] [Batch 325/815] [D loss: -5.856977] [G loss: -23.595634]\n",
      "[Epoch 4/200] [Batch 330/815] [D loss: -5.686105] [G loss: -18.658794]\n",
      "[Epoch 4/200] [Batch 335/815] [D loss: -3.219388] [G loss: -32.513706]\n",
      "[Epoch 4/200] [Batch 340/815] [D loss: -5.439354] [G loss: -15.047286]\n",
      "[Epoch 4/200] [Batch 345/815] [D loss: -4.047488] [G loss: -24.724277]\n",
      "[Epoch 4/200] [Batch 350/815] [D loss: -4.928899] [G loss: -18.007517]\n",
      "[Epoch 4/200] [Batch 355/815] [D loss: -4.891465] [G loss: -19.574209]\n",
      "[Epoch 4/200] [Batch 360/815] [D loss: -5.490690] [G loss: -13.675466]\n",
      "[Epoch 4/200] [Batch 365/815] [D loss: -4.637803] [G loss: -22.696840]\n",
      "[Epoch 4/200] [Batch 370/815] [D loss: -4.265027] [G loss: -25.144804]\n",
      "[Epoch 4/200] [Batch 375/815] [D loss: -5.353662] [G loss: -12.801614]\n",
      "[Epoch 4/200] [Batch 380/815] [D loss: -5.172709] [G loss: -20.957005]\n",
      "[Epoch 4/200] [Batch 385/815] [D loss: -5.643950] [G loss: -16.451611]\n",
      "[Epoch 4/200] [Batch 390/815] [D loss: -6.186290] [G loss: -18.793867]\n",
      "[Epoch 4/200] [Batch 395/815] [D loss: -5.954043] [G loss: -19.877466]\n",
      "[Epoch 4/200] [Batch 400/815] [D loss: -4.787737] [G loss: -15.458813]\n",
      "[Epoch 4/200] [Batch 405/815] [D loss: -5.255125] [G loss: -25.796591]\n",
      "[Epoch 4/200] [Batch 410/815] [D loss: -5.466650] [G loss: -16.601871]\n",
      "[Epoch 4/200] [Batch 415/815] [D loss: -6.127760] [G loss: -11.837612]\n",
      "[Epoch 4/200] [Batch 420/815] [D loss: -6.501595] [G loss: -10.428157]\n",
      "[Epoch 4/200] [Batch 425/815] [D loss: -5.394629] [G loss: -20.190931]\n",
      "[Epoch 4/200] [Batch 430/815] [D loss: -4.912354] [G loss: -27.574564]\n",
      "[Epoch 4/200] [Batch 435/815] [D loss: -5.080899] [G loss: -16.467007]\n",
      "[Epoch 4/200] [Batch 440/815] [D loss: -3.594520] [G loss: -30.515785]\n",
      "[Epoch 4/200] [Batch 445/815] [D loss: -4.662198] [G loss: -19.074051]\n",
      "[Epoch 4/200] [Batch 450/815] [D loss: -5.346807] [G loss: -13.834780]\n",
      "[Epoch 4/200] [Batch 455/815] [D loss: -5.444120] [G loss: -15.382028]\n",
      "[Epoch 4/200] [Batch 460/815] [D loss: -6.025841] [G loss: -15.404434]\n",
      "[Epoch 4/200] [Batch 465/815] [D loss: -3.909478] [G loss: -13.681567]\n",
      "[Epoch 4/200] [Batch 470/815] [D loss: -6.216062] [G loss: -21.240742]\n",
      "[Epoch 4/200] [Batch 475/815] [D loss: -4.902038] [G loss: -25.320290]\n",
      "[Epoch 4/200] [Batch 480/815] [D loss: -6.602070] [G loss: -17.540096]\n",
      "[Epoch 4/200] [Batch 485/815] [D loss: -5.981129] [G loss: -25.274548]\n",
      "[Epoch 4/200] [Batch 490/815] [D loss: -5.504014] [G loss: -27.508369]\n",
      "[Epoch 4/200] [Batch 495/815] [D loss: -5.117205] [G loss: -26.873823]\n",
      "[Epoch 4/200] [Batch 500/815] [D loss: -6.165772] [G loss: -12.913415]\n",
      "[Epoch 4/200] [Batch 505/815] [D loss: -3.142472] [G loss: -40.014729]\n",
      "[Epoch 4/200] [Batch 510/815] [D loss: -4.410277] [G loss: -25.512201]\n",
      "[Epoch 4/200] [Batch 515/815] [D loss: -5.102737] [G loss: -23.159740]\n",
      "[Epoch 4/200] [Batch 520/815] [D loss: -5.215357] [G loss: -17.611301]\n",
      "[Epoch 4/200] [Batch 525/815] [D loss: -4.769443] [G loss: -14.664178]\n",
      "[Epoch 4/200] [Batch 530/815] [D loss: -3.972639] [G loss: -33.307476]\n",
      "[Epoch 4/200] [Batch 535/815] [D loss: -4.922213] [G loss: -19.030142]\n",
      "[Epoch 4/200] [Batch 540/815] [D loss: -5.627371] [G loss: -22.642900]\n",
      "[Epoch 4/200] [Batch 545/815] [D loss: -4.940239] [G loss: -26.023735]\n",
      "[Epoch 4/200] [Batch 550/815] [D loss: -5.771721] [G loss: -14.083010]\n",
      "[Epoch 4/200] [Batch 555/815] [D loss: -4.905376] [G loss: -23.772707]\n",
      "[Epoch 4/200] [Batch 560/815] [D loss: -5.669435] [G loss: -14.460128]\n",
      "[Epoch 4/200] [Batch 565/815] [D loss: -5.072638] [G loss: -26.614748]\n",
      "[Epoch 4/200] [Batch 570/815] [D loss: -6.057358] [G loss: -13.140937]\n",
      "[Epoch 4/200] [Batch 575/815] [D loss: -4.905739] [G loss: -28.047453]\n",
      "[Epoch 4/200] [Batch 580/815] [D loss: -4.439525] [G loss: -18.873859]\n",
      "[Epoch 4/200] [Batch 585/815] [D loss: -5.496834] [G loss: -16.069288]\n",
      "[Epoch 4/200] [Batch 590/815] [D loss: -4.612204] [G loss: -25.522367]\n",
      "[Epoch 4/200] [Batch 595/815] [D loss: -5.086138] [G loss: -26.551359]\n",
      "[Epoch 4/200] [Batch 600/815] [D loss: -5.311859] [G loss: -16.843092]\n",
      "[Epoch 4/200] [Batch 605/815] [D loss: -4.907419] [G loss: -17.007977]\n",
      "[Epoch 4/200] [Batch 610/815] [D loss: -5.075817] [G loss: -16.342073]\n",
      "[Epoch 4/200] [Batch 615/815] [D loss: -5.777411] [G loss: -13.735388]\n",
      "[Epoch 4/200] [Batch 620/815] [D loss: -4.332703] [G loss: -37.014412]\n",
      "[Epoch 4/200] [Batch 625/815] [D loss: -5.008865] [G loss: -24.502398]\n",
      "[Epoch 4/200] [Batch 630/815] [D loss: -4.191667] [G loss: -27.235796]\n",
      "[Epoch 4/200] [Batch 635/815] [D loss: -4.832265] [G loss: -21.073986]\n",
      "[Epoch 4/200] [Batch 640/815] [D loss: -5.353328] [G loss: -16.929976]\n",
      "[Epoch 4/200] [Batch 645/815] [D loss: -4.969326] [G loss: -21.544863]\n",
      "[Epoch 4/200] [Batch 650/815] [D loss: -5.676559] [G loss: -17.442228]\n",
      "[Epoch 4/200] [Batch 655/815] [D loss: -5.514682] [G loss: -19.375048]\n",
      "[Epoch 4/200] [Batch 660/815] [D loss: -3.751953] [G loss: -24.667744]\n",
      "[Epoch 4/200] [Batch 665/815] [D loss: -6.063179] [G loss: -12.584447]\n",
      "[Epoch 4/200] [Batch 670/815] [D loss: -5.323740] [G loss: -24.547695]\n",
      "[Epoch 4/200] [Batch 675/815] [D loss: -5.448888] [G loss: -18.135723]\n",
      "[Epoch 4/200] [Batch 680/815] [D loss: -5.329275] [G loss: -14.181835]\n",
      "[Epoch 4/200] [Batch 685/815] [D loss: -4.889961] [G loss: -19.618835]\n",
      "[Epoch 4/200] [Batch 690/815] [D loss: -5.672371] [G loss: -17.879906]\n",
      "[Epoch 4/200] [Batch 695/815] [D loss: -4.815716] [G loss: -30.767382]\n",
      "[Epoch 4/200] [Batch 700/815] [D loss: -5.862295] [G loss: -16.217176]\n",
      "[Epoch 4/200] [Batch 705/815] [D loss: -5.152586] [G loss: -27.825117]\n",
      "[Epoch 4/200] [Batch 710/815] [D loss: -5.512181] [G loss: -15.574145]\n",
      "[Epoch 4/200] [Batch 715/815] [D loss: -5.353314] [G loss: -17.226524]\n",
      "[Epoch 4/200] [Batch 720/815] [D loss: -5.642027] [G loss: -16.568434]\n",
      "[Epoch 4/200] [Batch 725/815] [D loss: -6.681642] [G loss: -13.186355]\n",
      "[Epoch 4/200] [Batch 730/815] [D loss: -4.804424] [G loss: -24.832983]\n",
      "[Epoch 4/200] [Batch 735/815] [D loss: -6.157912] [G loss: -21.880363]\n",
      "[Epoch 4/200] [Batch 740/815] [D loss: -4.752192] [G loss: -19.258926]\n",
      "[Epoch 4/200] [Batch 745/815] [D loss: -4.706949] [G loss: -12.344733]\n",
      "[Epoch 4/200] [Batch 750/815] [D loss: -5.849466] [G loss: -18.957752]\n",
      "[Epoch 4/200] [Batch 755/815] [D loss: -4.066956] [G loss: -27.952394]\n",
      "[Epoch 4/200] [Batch 760/815] [D loss: -4.835865] [G loss: -15.695668]\n",
      "[Epoch 4/200] [Batch 765/815] [D loss: -5.127312] [G loss: -19.516653]\n",
      "[Epoch 4/200] [Batch 770/815] [D loss: -5.736700] [G loss: -18.683239]\n",
      "[Epoch 4/200] [Batch 775/815] [D loss: -5.403663] [G loss: -14.687792]\n",
      "[Epoch 4/200] [Batch 780/815] [D loss: -5.840891] [G loss: -15.089767]\n",
      "[Epoch 4/200] [Batch 785/815] [D loss: -6.055558] [G loss: -15.614334]\n",
      "[Epoch 4/200] [Batch 790/815] [D loss: -3.355042] [G loss: -42.194740]\n",
      "[Epoch 4/200] [Batch 795/815] [D loss: -4.002495] [G loss: -17.380651]\n",
      "[Epoch 4/200] [Batch 800/815] [D loss: -5.184522] [G loss: -11.178651]\n",
      "[Epoch 4/200] [Batch 805/815] [D loss: -4.948000] [G loss: -16.908140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 810/815] [D loss: -5.478027] [G loss: -15.791141]\n",
      "[Epoch 5/200] [Batch 0/815] [D loss: -4.575901] [G loss: -22.733362]\n",
      "[Epoch 5/200] [Batch 5/815] [D loss: -5.704077] [G loss: -13.990450]\n",
      "[Epoch 5/200] [Batch 10/815] [D loss: -5.629762] [G loss: -23.572538]\n",
      "[Epoch 5/200] [Batch 15/815] [D loss: -4.624242] [G loss: -26.689705]\n",
      "[Epoch 5/200] [Batch 20/815] [D loss: -5.586865] [G loss: -15.516639]\n",
      "[Epoch 5/200] [Batch 25/815] [D loss: -4.445528] [G loss: -23.321882]\n",
      "[Epoch 5/200] [Batch 30/815] [D loss: -5.377887] [G loss: -12.072472]\n",
      "[Epoch 5/200] [Batch 35/815] [D loss: -4.717393] [G loss: -27.952660]\n",
      "[Epoch 5/200] [Batch 40/815] [D loss: -5.247107] [G loss: -23.367161]\n",
      "[Epoch 5/200] [Batch 45/815] [D loss: -4.244589] [G loss: -16.429546]\n",
      "[Epoch 5/200] [Batch 50/815] [D loss: -5.333929] [G loss: -13.603382]\n",
      "[Epoch 5/200] [Batch 55/815] [D loss: -4.428474] [G loss: -28.159298]\n",
      "[Epoch 5/200] [Batch 60/815] [D loss: -5.575599] [G loss: -16.427286]\n",
      "[Epoch 5/200] [Batch 65/815] [D loss: -5.155317] [G loss: -24.948618]\n",
      "[Epoch 5/200] [Batch 70/815] [D loss: -4.881715] [G loss: -17.382843]\n",
      "[Epoch 5/200] [Batch 75/815] [D loss: -5.322940] [G loss: -13.028308]\n",
      "[Epoch 5/200] [Batch 80/815] [D loss: -5.115743] [G loss: -25.502161]\n",
      "[Epoch 5/200] [Batch 85/815] [D loss: -6.006452] [G loss: -13.011204]\n",
      "[Epoch 5/200] [Batch 90/815] [D loss: -4.906841] [G loss: -21.489136]\n",
      "[Epoch 5/200] [Batch 95/815] [D loss: -3.916379] [G loss: -31.765123]\n",
      "[Epoch 5/200] [Batch 100/815] [D loss: -6.947304] [G loss: -13.297755]\n",
      "[Epoch 5/200] [Batch 105/815] [D loss: -5.064229] [G loss: -23.283779]\n",
      "[Epoch 5/200] [Batch 110/815] [D loss: -5.476518] [G loss: -13.265078]\n",
      "[Epoch 5/200] [Batch 115/815] [D loss: -5.816304] [G loss: -17.060595]\n",
      "[Epoch 5/200] [Batch 120/815] [D loss: -5.244111] [G loss: -28.086689]\n",
      "[Epoch 5/200] [Batch 125/815] [D loss: -4.504879] [G loss: -22.316032]\n",
      "[Epoch 5/200] [Batch 130/815] [D loss: -4.872239] [G loss: -15.915388]\n",
      "[Epoch 5/200] [Batch 135/815] [D loss: -6.254102] [G loss: -18.065865]\n",
      "[Epoch 5/200] [Batch 140/815] [D loss: -6.251460] [G loss: -12.619885]\n",
      "[Epoch 5/200] [Batch 145/815] [D loss: -6.621183] [G loss: -15.136876]\n",
      "[Epoch 5/200] [Batch 150/815] [D loss: -5.938096] [G loss: -17.021851]\n",
      "[Epoch 5/200] [Batch 155/815] [D loss: -4.294512] [G loss: -30.783363]\n",
      "[Epoch 5/200] [Batch 160/815] [D loss: -5.314322] [G loss: -17.947897]\n",
      "[Epoch 5/200] [Batch 165/815] [D loss: -4.926429] [G loss: -15.591651]\n",
      "[Epoch 5/200] [Batch 170/815] [D loss: -4.036477] [G loss: -30.437483]\n",
      "[Epoch 5/200] [Batch 175/815] [D loss: -4.086535] [G loss: -21.782345]\n",
      "[Epoch 5/200] [Batch 180/815] [D loss: -4.981133] [G loss: -22.155121]\n",
      "[Epoch 5/200] [Batch 185/815] [D loss: -4.681172] [G loss: -21.591702]\n",
      "[Epoch 5/200] [Batch 190/815] [D loss: -4.466582] [G loss: -26.869953]\n",
      "[Epoch 5/200] [Batch 195/815] [D loss: -5.624176] [G loss: -17.579380]\n",
      "[Epoch 5/200] [Batch 200/815] [D loss: -5.258782] [G loss: -13.714696]\n",
      "[Epoch 5/200] [Batch 205/815] [D loss: -5.577477] [G loss: -15.696163]\n",
      "[Epoch 5/200] [Batch 210/815] [D loss: -6.270323] [G loss: -14.764574]\n",
      "[Epoch 5/200] [Batch 215/815] [D loss: -4.922139] [G loss: -17.315525]\n",
      "[Epoch 5/200] [Batch 220/815] [D loss: -5.673105] [G loss: -14.522345]\n",
      "[Epoch 5/200] [Batch 225/815] [D loss: -5.706900] [G loss: -14.623780]\n",
      "[Epoch 5/200] [Batch 230/815] [D loss: -6.255165] [G loss: -13.305587]\n",
      "[Epoch 5/200] [Batch 235/815] [D loss: -3.939502] [G loss: -31.609035]\n",
      "[Epoch 5/200] [Batch 240/815] [D loss: -5.187958] [G loss: -17.798992]\n",
      "[Epoch 5/200] [Batch 245/815] [D loss: -8.049445] [G loss: -12.273596]\n",
      "[Epoch 5/200] [Batch 250/815] [D loss: -4.356035] [G loss: -28.466879]\n",
      "[Epoch 5/200] [Batch 255/815] [D loss: -4.889557] [G loss: -16.478914]\n",
      "[Epoch 5/200] [Batch 260/815] [D loss: -5.668588] [G loss: -16.498877]\n",
      "[Epoch 5/200] [Batch 265/815] [D loss: -5.410980] [G loss: -16.515778]\n",
      "[Epoch 5/200] [Batch 270/815] [D loss: -6.082383] [G loss: -16.873537]\n",
      "[Epoch 5/200] [Batch 275/815] [D loss: -4.732895] [G loss: -23.949972]\n",
      "[Epoch 5/200] [Batch 280/815] [D loss: -5.779552] [G loss: -11.214826]\n",
      "[Epoch 5/200] [Batch 285/815] [D loss: -5.616514] [G loss: -14.243868]\n",
      "[Epoch 5/200] [Batch 290/815] [D loss: -4.933731] [G loss: -27.623861]\n",
      "[Epoch 5/200] [Batch 295/815] [D loss: -4.908740] [G loss: -20.890793]\n",
      "[Epoch 5/200] [Batch 300/815] [D loss: -5.111954] [G loss: -15.647523]\n",
      "[Epoch 5/200] [Batch 305/815] [D loss: -4.721992] [G loss: -13.001806]\n",
      "[Epoch 5/200] [Batch 310/815] [D loss: -5.878242] [G loss: -11.201289]\n",
      "[Epoch 5/200] [Batch 315/815] [D loss: -5.857031] [G loss: -12.201941]\n",
      "[Epoch 5/200] [Batch 320/815] [D loss: -5.630212] [G loss: -23.647297]\n",
      "[Epoch 5/200] [Batch 325/815] [D loss: -5.204045] [G loss: -13.962312]\n",
      "[Epoch 5/200] [Batch 330/815] [D loss: -5.273884] [G loss: -22.670570]\n",
      "[Epoch 5/200] [Batch 335/815] [D loss: -5.525041] [G loss: -16.118374]\n",
      "[Epoch 5/200] [Batch 340/815] [D loss: -5.026266] [G loss: -26.990181]\n",
      "[Epoch 5/200] [Batch 345/815] [D loss: -5.018128] [G loss: -13.885403]\n",
      "[Epoch 5/200] [Batch 350/815] [D loss: -5.682702] [G loss: -10.110877]\n",
      "[Epoch 5/200] [Batch 355/815] [D loss: -5.442568] [G loss: -16.878044]\n",
      "[Epoch 5/200] [Batch 360/815] [D loss: -5.912255] [G loss: -15.924140]\n",
      "[Epoch 5/200] [Batch 365/815] [D loss: -4.947769] [G loss: -18.774036]\n",
      "[Epoch 5/200] [Batch 370/815] [D loss: -4.931663] [G loss: -23.533966]\n",
      "[Epoch 5/200] [Batch 375/815] [D loss: -5.677234] [G loss: -22.728085]\n",
      "[Epoch 5/200] [Batch 380/815] [D loss: -6.079292] [G loss: -14.958937]\n",
      "[Epoch 5/200] [Batch 385/815] [D loss: -5.270982] [G loss: -16.930479]\n",
      "[Epoch 5/200] [Batch 390/815] [D loss: -5.881088] [G loss: -15.672880]\n",
      "[Epoch 5/200] [Batch 395/815] [D loss: -5.133256] [G loss: -20.742695]\n",
      "[Epoch 5/200] [Batch 400/815] [D loss: -5.143092] [G loss: -24.481501]\n",
      "[Epoch 5/200] [Batch 405/815] [D loss: -4.860730] [G loss: -25.277275]\n",
      "[Epoch 5/200] [Batch 410/815] [D loss: -4.711228] [G loss: -19.854666]\n",
      "[Epoch 5/200] [Batch 415/815] [D loss: -5.064413] [G loss: -16.159330]\n",
      "[Epoch 5/200] [Batch 420/815] [D loss: -5.147070] [G loss: -18.628412]\n",
      "[Epoch 5/200] [Batch 425/815] [D loss: -5.879893] [G loss: -14.086855]\n",
      "[Epoch 5/200] [Batch 430/815] [D loss: -6.036400] [G loss: -15.837463]\n",
      "[Epoch 5/200] [Batch 435/815] [D loss: -5.884132] [G loss: -13.553979]\n",
      "[Epoch 5/200] [Batch 440/815] [D loss: -5.674562] [G loss: -19.922424]\n",
      "[Epoch 5/200] [Batch 445/815] [D loss: -6.657955] [G loss: -17.736284]\n",
      "[Epoch 5/200] [Batch 450/815] [D loss: -4.593584] [G loss: -22.661428]\n",
      "[Epoch 5/200] [Batch 455/815] [D loss: -4.305268] [G loss: -20.735125]\n",
      "[Epoch 5/200] [Batch 460/815] [D loss: -6.707873] [G loss: -18.460850]\n",
      "[Epoch 5/200] [Batch 465/815] [D loss: -4.915895] [G loss: -28.006277]\n",
      "[Epoch 5/200] [Batch 470/815] [D loss: -4.359310] [G loss: -26.906399]\n",
      "[Epoch 5/200] [Batch 475/815] [D loss: -3.689756] [G loss: -30.650229]\n",
      "[Epoch 5/200] [Batch 480/815] [D loss: -5.269422] [G loss: -16.515556]\n",
      "[Epoch 5/200] [Batch 485/815] [D loss: -4.693373] [G loss: -22.096375]\n",
      "[Epoch 5/200] [Batch 490/815] [D loss: -5.995976] [G loss: -12.574599]\n",
      "[Epoch 5/200] [Batch 495/815] [D loss: -5.033684] [G loss: -16.383686]\n",
      "[Epoch 5/200] [Batch 500/815] [D loss: -5.620944] [G loss: -14.404506]\n",
      "[Epoch 5/200] [Batch 505/815] [D loss: -5.714343] [G loss: -28.998510]\n",
      "[Epoch 5/200] [Batch 510/815] [D loss: -4.633759] [G loss: -24.748775]\n",
      "[Epoch 5/200] [Batch 515/815] [D loss: -5.490881] [G loss: -17.380709]\n",
      "[Epoch 5/200] [Batch 520/815] [D loss: -4.919035] [G loss: -18.332565]\n",
      "[Epoch 5/200] [Batch 525/815] [D loss: -5.197896] [G loss: -14.507887]\n",
      "[Epoch 5/200] [Batch 530/815] [D loss: -4.792423] [G loss: -22.409376]\n",
      "[Epoch 5/200] [Batch 535/815] [D loss: -4.823007] [G loss: -22.794441]\n",
      "[Epoch 5/200] [Batch 540/815] [D loss: -4.874779] [G loss: -15.764737]\n",
      "[Epoch 5/200] [Batch 545/815] [D loss: -4.879733] [G loss: -28.468191]\n",
      "[Epoch 5/200] [Batch 550/815] [D loss: -4.236201] [G loss: -26.283566]\n",
      "[Epoch 5/200] [Batch 555/815] [D loss: -4.601091] [G loss: -22.518467]\n",
      "[Epoch 5/200] [Batch 560/815] [D loss: -5.301264] [G loss: -19.168566]\n",
      "[Epoch 5/200] [Batch 565/815] [D loss: -6.086329] [G loss: -16.580086]\n",
      "[Epoch 5/200] [Batch 570/815] [D loss: -5.531103] [G loss: -12.579348]\n",
      "[Epoch 5/200] [Batch 575/815] [D loss: -5.021070] [G loss: -24.480087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 580/815] [D loss: -5.180809] [G loss: -17.753416]\n",
      "[Epoch 5/200] [Batch 585/815] [D loss: -4.774716] [G loss: -19.259003]\n",
      "[Epoch 5/200] [Batch 590/815] [D loss: -5.319981] [G loss: -17.245220]\n",
      "[Epoch 5/200] [Batch 595/815] [D loss: -5.108344] [G loss: -13.672192]\n",
      "[Epoch 5/200] [Batch 600/815] [D loss: -6.044212] [G loss: -19.083420]\n",
      "[Epoch 5/200] [Batch 605/815] [D loss: -5.711687] [G loss: -24.800615]\n",
      "[Epoch 5/200] [Batch 610/815] [D loss: -5.774156] [G loss: -16.504078]\n",
      "[Epoch 5/200] [Batch 615/815] [D loss: -6.289764] [G loss: -28.497541]\n",
      "[Epoch 5/200] [Batch 620/815] [D loss: -5.562355] [G loss: -20.519440]\n",
      "[Epoch 5/200] [Batch 625/815] [D loss: -6.199898] [G loss: -10.307041]\n",
      "[Epoch 5/200] [Batch 630/815] [D loss: -5.122775] [G loss: -22.102097]\n",
      "[Epoch 5/200] [Batch 635/815] [D loss: -5.269476] [G loss: -19.451900]\n",
      "[Epoch 5/200] [Batch 640/815] [D loss: -4.629596] [G loss: -27.428062]\n",
      "[Epoch 5/200] [Batch 645/815] [D loss: -5.701728] [G loss: -12.702682]\n",
      "[Epoch 5/200] [Batch 650/815] [D loss: -4.516340] [G loss: -28.482092]\n",
      "[Epoch 5/200] [Batch 655/815] [D loss: -4.389984] [G loss: -23.049883]\n",
      "[Epoch 5/200] [Batch 660/815] [D loss: -5.675111] [G loss: -12.884808]\n",
      "[Epoch 5/200] [Batch 665/815] [D loss: -4.914781] [G loss: -20.494581]\n",
      "[Epoch 5/200] [Batch 670/815] [D loss: -5.385130] [G loss: -16.711586]\n",
      "[Epoch 5/200] [Batch 675/815] [D loss: -5.580789] [G loss: -15.832912]\n",
      "[Epoch 5/200] [Batch 680/815] [D loss: -5.236278] [G loss: -17.701502]\n",
      "[Epoch 5/200] [Batch 685/815] [D loss: -4.954635] [G loss: -17.568262]\n",
      "[Epoch 5/200] [Batch 690/815] [D loss: -5.123355] [G loss: -16.856388]\n",
      "[Epoch 5/200] [Batch 695/815] [D loss: -5.203509] [G loss: -20.721130]\n",
      "[Epoch 5/200] [Batch 700/815] [D loss: -5.442964] [G loss: -14.340698]\n",
      "[Epoch 5/200] [Batch 705/815] [D loss: -4.786431] [G loss: -21.341301]\n",
      "[Epoch 5/200] [Batch 710/815] [D loss: -5.783866] [G loss: -17.789522]\n",
      "[Epoch 5/200] [Batch 715/815] [D loss: -3.645558] [G loss: -44.268158]\n",
      "[Epoch 5/200] [Batch 720/815] [D loss: -4.551195] [G loss: -21.178669]\n",
      "[Epoch 5/200] [Batch 725/815] [D loss: -5.666417] [G loss: -13.451556]\n",
      "[Epoch 5/200] [Batch 730/815] [D loss: -4.985190] [G loss: -16.821815]\n",
      "[Epoch 5/200] [Batch 735/815] [D loss: -5.454244] [G loss: -16.866575]\n",
      "[Epoch 5/200] [Batch 740/815] [D loss: -5.478079] [G loss: -28.248783]\n",
      "[Epoch 5/200] [Batch 745/815] [D loss: -5.577720] [G loss: -18.237074]\n",
      "[Epoch 5/200] [Batch 750/815] [D loss: -4.960146] [G loss: -18.465885]\n",
      "[Epoch 5/200] [Batch 755/815] [D loss: -5.792265] [G loss: -17.554640]\n",
      "[Epoch 5/200] [Batch 760/815] [D loss: -4.767848] [G loss: -27.322487]\n",
      "[Epoch 5/200] [Batch 765/815] [D loss: -5.863681] [G loss: -19.610346]\n",
      "[Epoch 5/200] [Batch 770/815] [D loss: -6.058796] [G loss: -12.744627]\n",
      "[Epoch 5/200] [Batch 775/815] [D loss: -5.228690] [G loss: -23.372055]\n",
      "[Epoch 5/200] [Batch 780/815] [D loss: -5.571943] [G loss: -12.517126]\n",
      "[Epoch 5/200] [Batch 785/815] [D loss: -6.659060] [G loss: -18.829468]\n",
      "[Epoch 5/200] [Batch 790/815] [D loss: -4.474428] [G loss: -26.015818]\n",
      "[Epoch 5/200] [Batch 795/815] [D loss: -5.170155] [G loss: -13.370948]\n",
      "[Epoch 5/200] [Batch 800/815] [D loss: -4.934465] [G loss: -18.334393]\n",
      "[Epoch 5/200] [Batch 805/815] [D loss: -4.160627] [G loss: -33.889011]\n",
      "[Epoch 5/200] [Batch 810/815] [D loss: -4.406714] [G loss: -23.317907]\n",
      "[Epoch 6/200] [Batch 0/815] [D loss: -4.456773] [G loss: -24.823992]\n",
      "[Epoch 6/200] [Batch 5/815] [D loss: -5.133929] [G loss: -13.233558]\n",
      "[Epoch 6/200] [Batch 10/815] [D loss: -4.441134] [G loss: -26.204115]\n",
      "[Epoch 6/200] [Batch 15/815] [D loss: -6.268611] [G loss: -17.158384]\n",
      "[Epoch 6/200] [Batch 20/815] [D loss: -5.911074] [G loss: -14.146154]\n",
      "[Epoch 6/200] [Batch 25/815] [D loss: -5.703183] [G loss: -18.347857]\n",
      "[Epoch 6/200] [Batch 30/815] [D loss: -4.848060] [G loss: -20.104221]\n",
      "[Epoch 6/200] [Batch 35/815] [D loss: -5.403159] [G loss: -14.108291]\n",
      "[Epoch 6/200] [Batch 40/815] [D loss: -5.963144] [G loss: -15.732519]\n",
      "[Epoch 6/200] [Batch 45/815] [D loss: -6.406572] [G loss: -12.884471]\n",
      "[Epoch 6/200] [Batch 50/815] [D loss: -5.441552] [G loss: -23.685572]\n",
      "[Epoch 6/200] [Batch 55/815] [D loss: -5.730936] [G loss: -12.815478]\n",
      "[Epoch 6/200] [Batch 60/815] [D loss: -4.972088] [G loss: -25.522350]\n",
      "[Epoch 6/200] [Batch 65/815] [D loss: -5.275748] [G loss: -13.972198]\n",
      "[Epoch 6/200] [Batch 70/815] [D loss: -5.963085] [G loss: -13.824620]\n",
      "[Epoch 6/200] [Batch 75/815] [D loss: -5.970037] [G loss: -11.159979]\n",
      "[Epoch 6/200] [Batch 80/815] [D loss: -5.035970] [G loss: -25.139687]\n",
      "[Epoch 6/200] [Batch 85/815] [D loss: -5.177516] [G loss: -29.360826]\n",
      "[Epoch 6/200] [Batch 90/815] [D loss: -4.241032] [G loss: -22.409658]\n",
      "[Epoch 6/200] [Batch 95/815] [D loss: -4.564396] [G loss: -27.542564]\n",
      "[Epoch 6/200] [Batch 100/815] [D loss: -5.305416] [G loss: -14.862951]\n",
      "[Epoch 6/200] [Batch 105/815] [D loss: -5.505028] [G loss: -19.996660]\n",
      "[Epoch 6/200] [Batch 110/815] [D loss: -5.068521] [G loss: -15.219685]\n",
      "[Epoch 6/200] [Batch 115/815] [D loss: -5.622264] [G loss: -15.827429]\n",
      "[Epoch 6/200] [Batch 120/815] [D loss: -4.805214] [G loss: -29.311195]\n",
      "[Epoch 6/200] [Batch 125/815] [D loss: -6.201571] [G loss: -18.301767]\n",
      "[Epoch 6/200] [Batch 130/815] [D loss: -4.189444] [G loss: -31.655224]\n",
      "[Epoch 6/200] [Batch 135/815] [D loss: -4.399395] [G loss: -23.567263]\n",
      "[Epoch 6/200] [Batch 140/815] [D loss: -4.554159] [G loss: -16.972843]\n",
      "[Epoch 6/200] [Batch 145/815] [D loss: -5.342591] [G loss: -18.816536]\n",
      "[Epoch 6/200] [Batch 150/815] [D loss: -5.739465] [G loss: -19.104294]\n",
      "[Epoch 6/200] [Batch 155/815] [D loss: -5.596069] [G loss: -15.295739]\n",
      "[Epoch 6/200] [Batch 160/815] [D loss: -5.109478] [G loss: -13.897491]\n",
      "[Epoch 6/200] [Batch 165/815] [D loss: -5.195413] [G loss: -16.424772]\n",
      "[Epoch 6/200] [Batch 170/815] [D loss: -5.606961] [G loss: -25.997736]\n",
      "[Epoch 6/200] [Batch 175/815] [D loss: -5.049192] [G loss: -18.518614]\n",
      "[Epoch 6/200] [Batch 180/815] [D loss: -5.596183] [G loss: -12.072571]\n",
      "[Epoch 6/200] [Batch 185/815] [D loss: -5.352435] [G loss: -17.025738]\n",
      "[Epoch 6/200] [Batch 190/815] [D loss: -5.818650] [G loss: -14.985781]\n",
      "[Epoch 6/200] [Batch 195/815] [D loss: -5.298250] [G loss: -16.522970]\n",
      "[Epoch 6/200] [Batch 200/815] [D loss: -5.380439] [G loss: -13.383088]\n",
      "[Epoch 6/200] [Batch 205/815] [D loss: -5.383417] [G loss: -18.589506]\n",
      "[Epoch 6/200] [Batch 210/815] [D loss: -5.470764] [G loss: -16.846132]\n",
      "[Epoch 6/200] [Batch 215/815] [D loss: -5.794050] [G loss: -19.374952]\n",
      "[Epoch 6/200] [Batch 220/815] [D loss: -5.936090] [G loss: -13.209490]\n",
      "[Epoch 6/200] [Batch 225/815] [D loss: -5.925649] [G loss: -12.826648]\n",
      "[Epoch 6/200] [Batch 230/815] [D loss: -3.931900] [G loss: -29.064812]\n",
      "[Epoch 6/200] [Batch 235/815] [D loss: -4.774798] [G loss: -27.832312]\n",
      "[Epoch 6/200] [Batch 240/815] [D loss: -5.282142] [G loss: -13.225996]\n",
      "[Epoch 6/200] [Batch 245/815] [D loss: -5.609810] [G loss: -23.696877]\n",
      "[Epoch 6/200] [Batch 250/815] [D loss: -4.774944] [G loss: -20.293697]\n",
      "[Epoch 6/200] [Batch 255/815] [D loss: -5.320928] [G loss: -14.928491]\n",
      "[Epoch 6/200] [Batch 260/815] [D loss: -3.685048] [G loss: -30.488277]\n",
      "[Epoch 6/200] [Batch 265/815] [D loss: -5.297646] [G loss: -15.271151]\n",
      "[Epoch 6/200] [Batch 270/815] [D loss: -4.541514] [G loss: -28.400871]\n",
      "[Epoch 6/200] [Batch 275/815] [D loss: -5.988266] [G loss: -14.463363]\n",
      "[Epoch 6/200] [Batch 280/815] [D loss: -5.776177] [G loss: -13.004771]\n",
      "[Epoch 6/200] [Batch 285/815] [D loss: -4.703218] [G loss: -24.472883]\n",
      "[Epoch 6/200] [Batch 290/815] [D loss: -5.148954] [G loss: -18.043732]\n",
      "[Epoch 6/200] [Batch 295/815] [D loss: -4.886641] [G loss: -28.092194]\n",
      "[Epoch 6/200] [Batch 300/815] [D loss: -5.768771] [G loss: -15.167953]\n",
      "[Epoch 6/200] [Batch 305/815] [D loss: -4.907957] [G loss: -16.336374]\n",
      "[Epoch 6/200] [Batch 310/815] [D loss: -5.432623] [G loss: -18.225939]\n",
      "[Epoch 6/200] [Batch 315/815] [D loss: -6.604956] [G loss: -15.437264]\n",
      "[Epoch 6/200] [Batch 320/815] [D loss: -5.222052] [G loss: -17.762119]\n",
      "[Epoch 6/200] [Batch 325/815] [D loss: -5.176228] [G loss: -14.365759]\n",
      "[Epoch 6/200] [Batch 330/815] [D loss: -4.350305] [G loss: -25.103983]\n",
      "[Epoch 6/200] [Batch 335/815] [D loss: -6.397138] [G loss: -11.170003]\n",
      "[Epoch 6/200] [Batch 340/815] [D loss: -6.023755] [G loss: -15.283957]\n",
      "[Epoch 6/200] [Batch 345/815] [D loss: -5.692592] [G loss: -22.093994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 350/815] [D loss: -5.397047] [G loss: -22.812038]\n",
      "[Epoch 6/200] [Batch 355/815] [D loss: -4.953638] [G loss: -32.760971]\n",
      "[Epoch 6/200] [Batch 360/815] [D loss: -5.119325] [G loss: -14.946207]\n",
      "[Epoch 6/200] [Batch 365/815] [D loss: -1.699648] [G loss: -38.625225]\n",
      "[Epoch 6/200] [Batch 370/815] [D loss: -4.839133] [G loss: -11.521330]\n",
      "[Epoch 6/200] [Batch 375/815] [D loss: -4.506004] [G loss: -19.135624]\n",
      "[Epoch 6/200] [Batch 380/815] [D loss: -5.409533] [G loss: -12.917546]\n",
      "[Epoch 6/200] [Batch 385/815] [D loss: -6.607692] [G loss: -11.854216]\n",
      "[Epoch 6/200] [Batch 390/815] [D loss: -4.842930] [G loss: -19.612682]\n",
      "[Epoch 6/200] [Batch 395/815] [D loss: -5.256970] [G loss: -20.047071]\n",
      "[Epoch 6/200] [Batch 400/815] [D loss: -4.981665] [G loss: -15.202329]\n",
      "[Epoch 6/200] [Batch 405/815] [D loss: -5.556429] [G loss: -15.979157]\n",
      "[Epoch 6/200] [Batch 410/815] [D loss: -3.957877] [G loss: -29.500761]\n",
      "[Epoch 6/200] [Batch 415/815] [D loss: -5.813245] [G loss: -18.757965]\n",
      "[Epoch 6/200] [Batch 420/815] [D loss: -5.537601] [G loss: -16.306644]\n",
      "[Epoch 6/200] [Batch 425/815] [D loss: -5.837093] [G loss: -14.059448]\n",
      "[Epoch 6/200] [Batch 430/815] [D loss: -5.758790] [G loss: -14.109463]\n",
      "[Epoch 6/200] [Batch 435/815] [D loss: -5.144041] [G loss: -23.477316]\n",
      "[Epoch 6/200] [Batch 440/815] [D loss: -5.308236] [G loss: -23.743799]\n",
      "[Epoch 6/200] [Batch 445/815] [D loss: -4.176362] [G loss: -27.079140]\n",
      "[Epoch 6/200] [Batch 450/815] [D loss: -4.609262] [G loss: -16.961338]\n",
      "[Epoch 6/200] [Batch 455/815] [D loss: -6.366041] [G loss: -13.482162]\n",
      "[Epoch 6/200] [Batch 460/815] [D loss: -5.854951] [G loss: -22.717751]\n",
      "[Epoch 6/200] [Batch 465/815] [D loss: -5.722377] [G loss: -13.504515]\n",
      "[Epoch 6/200] [Batch 470/815] [D loss: -5.270611] [G loss: -21.819988]\n",
      "[Epoch 6/200] [Batch 475/815] [D loss: -5.239658] [G loss: -25.472792]\n",
      "[Epoch 6/200] [Batch 480/815] [D loss: -4.790261] [G loss: -16.816204]\n",
      "[Epoch 6/200] [Batch 485/815] [D loss: -5.038076] [G loss: -18.240549]\n",
      "[Epoch 6/200] [Batch 490/815] [D loss: -5.764261] [G loss: -18.021418]\n",
      "[Epoch 6/200] [Batch 495/815] [D loss: -5.604873] [G loss: -18.887438]\n",
      "[Epoch 6/200] [Batch 500/815] [D loss: -5.279548] [G loss: -20.808716]\n",
      "[Epoch 6/200] [Batch 505/815] [D loss: -5.870014] [G loss: -18.035177]\n",
      "[Epoch 6/200] [Batch 510/815] [D loss: -5.203071] [G loss: -20.598188]\n",
      "[Epoch 6/200] [Batch 515/815] [D loss: -5.285945] [G loss: -23.659157]\n",
      "[Epoch 6/200] [Batch 520/815] [D loss: -5.065639] [G loss: -26.035435]\n",
      "[Epoch 6/200] [Batch 525/815] [D loss: -4.182931] [G loss: -25.895676]\n",
      "[Epoch 6/200] [Batch 530/815] [D loss: -5.902962] [G loss: -14.006023]\n",
      "[Epoch 6/200] [Batch 535/815] [D loss: -5.167826] [G loss: -24.301985]\n",
      "[Epoch 6/200] [Batch 540/815] [D loss: -5.495518] [G loss: -17.522943]\n",
      "[Epoch 6/200] [Batch 545/815] [D loss: -4.755578] [G loss: -19.134169]\n",
      "[Epoch 6/200] [Batch 550/815] [D loss: -5.771819] [G loss: -11.463231]\n",
      "[Epoch 6/200] [Batch 555/815] [D loss: -4.997340] [G loss: -23.263945]\n",
      "[Epoch 6/200] [Batch 560/815] [D loss: -3.843240] [G loss: -25.607058]\n",
      "[Epoch 6/200] [Batch 565/815] [D loss: -5.549069] [G loss: -13.334373]\n",
      "[Epoch 6/200] [Batch 570/815] [D loss: -4.176541] [G loss: -26.455830]\n",
      "[Epoch 6/200] [Batch 575/815] [D loss: -5.130380] [G loss: -18.387787]\n",
      "[Epoch 6/200] [Batch 580/815] [D loss: -5.464932] [G loss: -25.319147]\n",
      "[Epoch 6/200] [Batch 585/815] [D loss: -5.285356] [G loss: -18.895077]\n",
      "[Epoch 6/200] [Batch 590/815] [D loss: -5.661438] [G loss: -11.863483]\n",
      "[Epoch 6/200] [Batch 595/815] [D loss: -6.229042] [G loss: -15.399240]\n",
      "[Epoch 6/200] [Batch 600/815] [D loss: -6.001586] [G loss: -23.140251]\n",
      "[Epoch 6/200] [Batch 605/815] [D loss: -5.341725] [G loss: -23.200212]\n",
      "[Epoch 6/200] [Batch 610/815] [D loss: -5.030710] [G loss: -17.157299]\n",
      "[Epoch 6/200] [Batch 615/815] [D loss: -3.683338] [G loss: -24.670780]\n",
      "[Epoch 6/200] [Batch 620/815] [D loss: -4.190454] [G loss: -22.867432]\n",
      "[Epoch 6/200] [Batch 625/815] [D loss: -5.601844] [G loss: -16.121250]\n",
      "[Epoch 6/200] [Batch 630/815] [D loss: -5.411593] [G loss: -13.980844]\n",
      "[Epoch 6/200] [Batch 635/815] [D loss: -5.079374] [G loss: -26.998421]\n",
      "[Epoch 6/200] [Batch 640/815] [D loss: -5.906326] [G loss: -18.417606]\n",
      "[Epoch 6/200] [Batch 645/815] [D loss: -5.235460] [G loss: -25.620119]\n",
      "[Epoch 6/200] [Batch 650/815] [D loss: -6.098238] [G loss: -10.666541]\n",
      "[Epoch 6/200] [Batch 655/815] [D loss: -5.918938] [G loss: -12.965505]\n",
      "[Epoch 6/200] [Batch 660/815] [D loss: -4.279049] [G loss: -30.601274]\n",
      "[Epoch 6/200] [Batch 665/815] [D loss: -4.689692] [G loss: -16.545584]\n",
      "[Epoch 6/200] [Batch 670/815] [D loss: -4.801429] [G loss: -22.984484]\n",
      "[Epoch 6/200] [Batch 675/815] [D loss: -5.380531] [G loss: -13.463289]\n",
      "[Epoch 6/200] [Batch 680/815] [D loss: -6.168589] [G loss: -12.896545]\n",
      "[Epoch 6/200] [Batch 685/815] [D loss: -4.620289] [G loss: -23.888700]\n",
      "[Epoch 6/200] [Batch 690/815] [D loss: -5.826090] [G loss: -16.928255]\n",
      "[Epoch 6/200] [Batch 695/815] [D loss: -5.261861] [G loss: -20.270411]\n",
      "[Epoch 6/200] [Batch 700/815] [D loss: -6.064135] [G loss: -13.399348]\n",
      "[Epoch 6/200] [Batch 705/815] [D loss: -5.802223] [G loss: -14.296726]\n",
      "[Epoch 6/200] [Batch 710/815] [D loss: -4.843008] [G loss: -21.567602]\n",
      "[Epoch 6/200] [Batch 715/815] [D loss: -5.369665] [G loss: -19.286421]\n",
      "[Epoch 6/200] [Batch 720/815] [D loss: -5.217566] [G loss: -24.316175]\n",
      "[Epoch 6/200] [Batch 725/815] [D loss: -5.996830] [G loss: -12.599045]\n",
      "[Epoch 6/200] [Batch 730/815] [D loss: -4.744029] [G loss: -25.312447]\n",
      "[Epoch 6/200] [Batch 735/815] [D loss: -5.923141] [G loss: -27.667616]\n",
      "[Epoch 6/200] [Batch 740/815] [D loss: -5.712171] [G loss: -14.819319]\n",
      "[Epoch 6/200] [Batch 745/815] [D loss: -4.454490] [G loss: -27.032803]\n",
      "[Epoch 6/200] [Batch 750/815] [D loss: -4.526325] [G loss: -21.243698]\n",
      "[Epoch 6/200] [Batch 755/815] [D loss: -5.268013] [G loss: -13.238354]\n",
      "[Epoch 6/200] [Batch 760/815] [D loss: -5.384808] [G loss: -16.888725]\n",
      "[Epoch 6/200] [Batch 765/815] [D loss: -4.841047] [G loss: -17.972929]\n",
      "[Epoch 6/200] [Batch 770/815] [D loss: -6.217694] [G loss: -21.402884]\n",
      "[Epoch 6/200] [Batch 775/815] [D loss: -4.867025] [G loss: -25.476986]\n",
      "[Epoch 6/200] [Batch 780/815] [D loss: -4.919217] [G loss: -16.890020]\n",
      "[Epoch 6/200] [Batch 785/815] [D loss: -5.423536] [G loss: -18.164206]\n",
      "[Epoch 6/200] [Batch 790/815] [D loss: -5.352839] [G loss: -17.250963]\n",
      "[Epoch 6/200] [Batch 795/815] [D loss: -4.747849] [G loss: -21.418589]\n",
      "[Epoch 6/200] [Batch 800/815] [D loss: -3.964788] [G loss: -33.424412]\n",
      "[Epoch 6/200] [Batch 805/815] [D loss: -5.604342] [G loss: -17.558165]\n",
      "[Epoch 6/200] [Batch 810/815] [D loss: -5.534330] [G loss: -15.959242]\n",
      "[Epoch 7/200] [Batch 0/815] [D loss: -5.028260] [G loss: -15.325798]\n",
      "[Epoch 7/200] [Batch 5/815] [D loss: -5.082830] [G loss: -15.068019]\n",
      "[Epoch 7/200] [Batch 10/815] [D loss: -5.716035] [G loss: -14.197776]\n",
      "[Epoch 7/200] [Batch 15/815] [D loss: -6.356633] [G loss: -15.125193]\n",
      "[Epoch 7/200] [Batch 20/815] [D loss: -5.407190] [G loss: -15.517456]\n",
      "[Epoch 7/200] [Batch 25/815] [D loss: -5.456319] [G loss: -17.035936]\n",
      "[Epoch 7/200] [Batch 30/815] [D loss: -5.345994] [G loss: -26.091496]\n",
      "[Epoch 7/200] [Batch 35/815] [D loss: -4.762268] [G loss: -26.051338]\n",
      "[Epoch 7/200] [Batch 40/815] [D loss: -4.947861] [G loss: -25.956001]\n",
      "[Epoch 7/200] [Batch 45/815] [D loss: -4.540147] [G loss: -17.801674]\n",
      "[Epoch 7/200] [Batch 50/815] [D loss: -4.998208] [G loss: -23.253326]\n",
      "[Epoch 7/200] [Batch 55/815] [D loss: -6.733594] [G loss: -11.056439]\n",
      "[Epoch 7/200] [Batch 60/815] [D loss: -5.917167] [G loss: -13.223960]\n",
      "[Epoch 7/200] [Batch 65/815] [D loss: -5.666631] [G loss: -16.821459]\n",
      "[Epoch 7/200] [Batch 70/815] [D loss: -6.308245] [G loss: -16.697008]\n",
      "[Epoch 7/200] [Batch 75/815] [D loss: -6.226370] [G loss: -13.912562]\n",
      "[Epoch 7/200] [Batch 80/815] [D loss: -6.180212] [G loss: -19.605598]\n",
      "[Epoch 7/200] [Batch 85/815] [D loss: -5.714137] [G loss: -24.181303]\n",
      "[Epoch 7/200] [Batch 90/815] [D loss: -6.359174] [G loss: -14.041345]\n",
      "[Epoch 7/200] [Batch 95/815] [D loss: -5.435200] [G loss: -22.962055]\n",
      "[Epoch 7/200] [Batch 100/815] [D loss: -7.096998] [G loss: -12.126928]\n",
      "[Epoch 7/200] [Batch 105/815] [D loss: -5.535760] [G loss: -20.588453]\n",
      "[Epoch 7/200] [Batch 110/815] [D loss: -5.313662] [G loss: -18.971952]\n",
      "[Epoch 7/200] [Batch 115/815] [D loss: -5.355402] [G loss: -13.755926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 120/815] [D loss: -5.255652] [G loss: -17.513960]\n",
      "[Epoch 7/200] [Batch 125/815] [D loss: -5.511523] [G loss: -24.326086]\n",
      "[Epoch 7/200] [Batch 130/815] [D loss: -2.993834] [G loss: -16.697683]\n",
      "[Epoch 7/200] [Batch 135/815] [D loss: -5.852724] [G loss: -12.762714]\n",
      "[Epoch 7/200] [Batch 140/815] [D loss: -5.377177] [G loss: -17.597837]\n",
      "[Epoch 7/200] [Batch 145/815] [D loss: -5.384968] [G loss: -16.705814]\n",
      "[Epoch 7/200] [Batch 150/815] [D loss: -3.738024] [G loss: -27.326792]\n",
      "[Epoch 7/200] [Batch 155/815] [D loss: -5.070225] [G loss: -27.646833]\n",
      "[Epoch 7/200] [Batch 160/815] [D loss: -5.409346] [G loss: -18.534088]\n",
      "[Epoch 7/200] [Batch 165/815] [D loss: -6.126267] [G loss: -11.756170]\n",
      "[Epoch 7/200] [Batch 170/815] [D loss: -5.827599] [G loss: -11.591362]\n",
      "[Epoch 7/200] [Batch 175/815] [D loss: -5.099144] [G loss: -25.523090]\n",
      "[Epoch 7/200] [Batch 180/815] [D loss: -5.646343] [G loss: -14.229088]\n",
      "[Epoch 7/200] [Batch 185/815] [D loss: -4.886257] [G loss: -26.359169]\n",
      "[Epoch 7/200] [Batch 190/815] [D loss: -4.580855] [G loss: -28.487797]\n",
      "[Epoch 7/200] [Batch 195/815] [D loss: -5.770274] [G loss: -13.235802]\n",
      "[Epoch 7/200] [Batch 200/815] [D loss: -5.574462] [G loss: -25.297468]\n",
      "[Epoch 7/200] [Batch 205/815] [D loss: -4.922552] [G loss: -11.267178]\n",
      "[Epoch 7/200] [Batch 210/815] [D loss: -3.782625] [G loss: -36.845936]\n",
      "[Epoch 7/200] [Batch 215/815] [D loss: -5.091180] [G loss: -13.594441]\n",
      "[Epoch 7/200] [Batch 220/815] [D loss: -5.450521] [G loss: -16.896013]\n",
      "[Epoch 7/200] [Batch 225/815] [D loss: -4.585338] [G loss: -16.722256]\n",
      "[Epoch 7/200] [Batch 230/815] [D loss: -6.352839] [G loss: -11.469958]\n",
      "[Epoch 7/200] [Batch 235/815] [D loss: -4.881854] [G loss: -25.002148]\n",
      "[Epoch 7/200] [Batch 240/815] [D loss: -4.733632] [G loss: -24.514109]\n",
      "[Epoch 7/200] [Batch 245/815] [D loss: -5.980983] [G loss: -17.750572]\n",
      "[Epoch 7/200] [Batch 250/815] [D loss: -6.268247] [G loss: -15.554676]\n",
      "[Epoch 7/200] [Batch 255/815] [D loss: -4.903068] [G loss: -18.750099]\n",
      "[Epoch 7/200] [Batch 260/815] [D loss: -5.505585] [G loss: -14.480728]\n",
      "[Epoch 7/200] [Batch 265/815] [D loss: -4.405694] [G loss: -17.257347]\n",
      "[Epoch 7/200] [Batch 270/815] [D loss: -5.633058] [G loss: -14.902021]\n",
      "[Epoch 7/200] [Batch 275/815] [D loss: -5.596399] [G loss: -13.869880]\n",
      "[Epoch 7/200] [Batch 280/815] [D loss: -5.242122] [G loss: -23.594677]\n",
      "[Epoch 7/200] [Batch 285/815] [D loss: -6.607908] [G loss: -14.858818]\n",
      "[Epoch 7/200] [Batch 290/815] [D loss: -5.330200] [G loss: -29.966417]\n",
      "[Epoch 7/200] [Batch 295/815] [D loss: -4.939760] [G loss: -17.627605]\n",
      "[Epoch 7/200] [Batch 300/815] [D loss: -5.459829] [G loss: -13.571050]\n",
      "[Epoch 7/200] [Batch 305/815] [D loss: -4.532471] [G loss: -20.263624]\n",
      "[Epoch 7/200] [Batch 310/815] [D loss: -5.144204] [G loss: -14.255096]\n",
      "[Epoch 7/200] [Batch 315/815] [D loss: -5.522431] [G loss: -15.792774]\n",
      "[Epoch 7/200] [Batch 320/815] [D loss: -6.446792] [G loss: -14.875288]\n",
      "[Epoch 7/200] [Batch 325/815] [D loss: -6.222024] [G loss: -11.852761]\n",
      "[Epoch 7/200] [Batch 330/815] [D loss: -5.495789] [G loss: -23.807194]\n",
      "[Epoch 7/200] [Batch 335/815] [D loss: -5.318706] [G loss: -16.938740]\n",
      "[Epoch 7/200] [Batch 340/815] [D loss: -4.721872] [G loss: -20.857639]\n",
      "[Epoch 7/200] [Batch 345/815] [D loss: -6.034792] [G loss: -14.168200]\n",
      "[Epoch 7/200] [Batch 350/815] [D loss: -5.543737] [G loss: -19.777964]\n",
      "[Epoch 7/200] [Batch 355/815] [D loss: -5.876943] [G loss: -14.215552]\n",
      "[Epoch 7/200] [Batch 360/815] [D loss: -3.241009] [G loss: -30.077494]\n",
      "[Epoch 7/200] [Batch 365/815] [D loss: -5.416173] [G loss: -14.561679]\n",
      "[Epoch 7/200] [Batch 370/815] [D loss: -6.011794] [G loss: -14.702207]\n",
      "[Epoch 7/200] [Batch 375/815] [D loss: -6.065079] [G loss: -10.937126]\n",
      "[Epoch 7/200] [Batch 380/815] [D loss: -4.825038] [G loss: -22.590607]\n",
      "[Epoch 7/200] [Batch 385/815] [D loss: -6.267431] [G loss: -17.313246]\n",
      "[Epoch 7/200] [Batch 390/815] [D loss: -4.415341] [G loss: -37.896046]\n",
      "[Epoch 7/200] [Batch 395/815] [D loss: -4.676669] [G loss: -13.551001]\n",
      "[Epoch 7/200] [Batch 400/815] [D loss: -4.710932] [G loss: -27.319780]\n",
      "[Epoch 7/200] [Batch 405/815] [D loss: -5.879155] [G loss: -17.411909]\n",
      "[Epoch 7/200] [Batch 410/815] [D loss: -4.233409] [G loss: -28.079268]\n",
      "[Epoch 7/200] [Batch 415/815] [D loss: -5.121800] [G loss: -21.602697]\n",
      "[Epoch 7/200] [Batch 420/815] [D loss: -5.658838] [G loss: -23.950087]\n",
      "[Epoch 7/200] [Batch 425/815] [D loss: -4.179902] [G loss: -27.050879]\n",
      "[Epoch 7/200] [Batch 430/815] [D loss: -5.057237] [G loss: -18.231993]\n",
      "[Epoch 7/200] [Batch 435/815] [D loss: -5.334763] [G loss: -14.891423]\n",
      "[Epoch 7/200] [Batch 440/815] [D loss: -5.638313] [G loss: -21.431965]\n",
      "[Epoch 7/200] [Batch 445/815] [D loss: -4.828184] [G loss: -27.889206]\n",
      "[Epoch 7/200] [Batch 450/815] [D loss: -5.040745] [G loss: -20.639143]\n",
      "[Epoch 7/200] [Batch 455/815] [D loss: -5.938053] [G loss: -19.608912]\n",
      "[Epoch 7/200] [Batch 460/815] [D loss: -4.939946] [G loss: -15.979751]\n",
      "[Epoch 7/200] [Batch 465/815] [D loss: -4.090126] [G loss: -32.100113]\n",
      "[Epoch 7/200] [Batch 470/815] [D loss: -4.721290] [G loss: -19.499285]\n",
      "[Epoch 7/200] [Batch 475/815] [D loss: -5.651718] [G loss: -12.664233]\n",
      "[Epoch 7/200] [Batch 480/815] [D loss: -5.523049] [G loss: -18.426935]\n",
      "[Epoch 7/200] [Batch 485/815] [D loss: -6.109940] [G loss: -11.481809]\n",
      "[Epoch 7/200] [Batch 490/815] [D loss: -5.379354] [G loss: -16.057360]\n",
      "[Epoch 7/200] [Batch 495/815] [D loss: -5.162772] [G loss: -20.245169]\n",
      "[Epoch 7/200] [Batch 500/815] [D loss: -5.285172] [G loss: -18.632627]\n",
      "[Epoch 7/200] [Batch 505/815] [D loss: -4.542652] [G loss: -23.764534]\n",
      "[Epoch 7/200] [Batch 510/815] [D loss: -5.652213] [G loss: -20.981436]\n",
      "[Epoch 7/200] [Batch 515/815] [D loss: -5.771380] [G loss: -14.314611]\n",
      "[Epoch 7/200] [Batch 520/815] [D loss: -5.285067] [G loss: -12.822678]\n",
      "[Epoch 7/200] [Batch 525/815] [D loss: -4.801344] [G loss: -23.750505]\n",
      "[Epoch 7/200] [Batch 530/815] [D loss: -5.942931] [G loss: -10.121855]\n",
      "[Epoch 7/200] [Batch 535/815] [D loss: -4.325454] [G loss: -30.519619]\n",
      "[Epoch 7/200] [Batch 540/815] [D loss: -5.241921] [G loss: -14.057510]\n",
      "[Epoch 7/200] [Batch 545/815] [D loss: -5.218562] [G loss: -13.363593]\n",
      "[Epoch 7/200] [Batch 550/815] [D loss: -4.359781] [G loss: -30.277060]\n",
      "[Epoch 7/200] [Batch 555/815] [D loss: -4.853316] [G loss: -16.014574]\n",
      "[Epoch 7/200] [Batch 560/815] [D loss: -2.960180] [G loss: -30.513708]\n",
      "[Epoch 7/200] [Batch 565/815] [D loss: -4.908122] [G loss: -16.251444]\n",
      "[Epoch 7/200] [Batch 570/815] [D loss: -4.820861] [G loss: -17.172981]\n",
      "[Epoch 7/200] [Batch 575/815] [D loss: -4.129903] [G loss: -25.806147]\n",
      "[Epoch 7/200] [Batch 580/815] [D loss: -5.176157] [G loss: -21.759245]\n",
      "[Epoch 7/200] [Batch 585/815] [D loss: -4.692022] [G loss: -18.337406]\n",
      "[Epoch 7/200] [Batch 590/815] [D loss: -5.787460] [G loss: -21.841595]\n",
      "[Epoch 7/200] [Batch 595/815] [D loss: -5.739705] [G loss: -14.658696]\n",
      "[Epoch 7/200] [Batch 600/815] [D loss: -5.365247] [G loss: -15.452628]\n",
      "[Epoch 7/200] [Batch 605/815] [D loss: -5.394965] [G loss: -18.663683]\n",
      "[Epoch 7/200] [Batch 610/815] [D loss: -4.904795] [G loss: -15.829884]\n",
      "[Epoch 7/200] [Batch 615/815] [D loss: -5.088236] [G loss: -15.234046]\n",
      "[Epoch 7/200] [Batch 620/815] [D loss: -5.756425] [G loss: -13.569338]\n",
      "[Epoch 7/200] [Batch 625/815] [D loss: -4.462316] [G loss: -31.818260]\n",
      "[Epoch 7/200] [Batch 630/815] [D loss: -4.681181] [G loss: -19.683908]\n",
      "[Epoch 7/200] [Batch 635/815] [D loss: -5.405154] [G loss: -16.107773]\n",
      "[Epoch 7/200] [Batch 640/815] [D loss: -5.067844] [G loss: -25.378592]\n",
      "[Epoch 7/200] [Batch 645/815] [D loss: -4.904546] [G loss: -16.749287]\n",
      "[Epoch 7/200] [Batch 650/815] [D loss: -5.653502] [G loss: -22.871181]\n",
      "[Epoch 7/200] [Batch 655/815] [D loss: -5.474088] [G loss: -11.601441]\n",
      "[Epoch 7/200] [Batch 660/815] [D loss: -5.759451] [G loss: -20.257729]\n",
      "[Epoch 7/200] [Batch 665/815] [D loss: -4.921010] [G loss: -17.403395]\n",
      "[Epoch 7/200] [Batch 670/815] [D loss: -5.925611] [G loss: -16.468958]\n",
      "[Epoch 7/200] [Batch 675/815] [D loss: -5.704468] [G loss: -17.383492]\n",
      "[Epoch 7/200] [Batch 680/815] [D loss: -5.565948] [G loss: -18.118408]\n",
      "[Epoch 7/200] [Batch 685/815] [D loss: -5.472943] [G loss: -20.354126]\n",
      "[Epoch 7/200] [Batch 690/815] [D loss: -5.830610] [G loss: -16.225704]\n",
      "[Epoch 7/200] [Batch 695/815] [D loss: -4.951473] [G loss: -20.156092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 700/815] [D loss: -3.425338] [G loss: -29.034464]\n",
      "[Epoch 7/200] [Batch 705/815] [D loss: -5.576608] [G loss: -13.508424]\n",
      "[Epoch 7/200] [Batch 710/815] [D loss: -4.776670] [G loss: -16.447737]\n",
      "[Epoch 7/200] [Batch 715/815] [D loss: -6.079451] [G loss: -13.666039]\n",
      "[Epoch 7/200] [Batch 720/815] [D loss: -5.674853] [G loss: -16.885252]\n",
      "[Epoch 7/200] [Batch 725/815] [D loss: -4.720233] [G loss: -18.520565]\n",
      "[Epoch 7/200] [Batch 730/815] [D loss: -4.629924] [G loss: -17.749058]\n",
      "[Epoch 7/200] [Batch 735/815] [D loss: -7.117145] [G loss: -11.375237]\n",
      "[Epoch 7/200] [Batch 740/815] [D loss: -4.487150] [G loss: -20.324978]\n",
      "[Epoch 7/200] [Batch 745/815] [D loss: -4.576408] [G loss: -25.175131]\n",
      "[Epoch 7/200] [Batch 750/815] [D loss: -4.894988] [G loss: -33.650162]\n",
      "[Epoch 7/200] [Batch 755/815] [D loss: -4.553538] [G loss: -19.537537]\n",
      "[Epoch 7/200] [Batch 760/815] [D loss: -4.819211] [G loss: -19.490948]\n",
      "[Epoch 7/200] [Batch 765/815] [D loss: -4.785713] [G loss: -17.781122]\n",
      "[Epoch 7/200] [Batch 770/815] [D loss: -5.638285] [G loss: -18.604696]\n",
      "[Epoch 7/200] [Batch 775/815] [D loss: -5.533520] [G loss: -13.533715]\n",
      "[Epoch 7/200] [Batch 780/815] [D loss: -5.721410] [G loss: -13.359109]\n",
      "[Epoch 7/200] [Batch 785/815] [D loss: -5.209619] [G loss: -14.182926]\n",
      "[Epoch 7/200] [Batch 790/815] [D loss: -4.857512] [G loss: -33.431503]\n",
      "[Epoch 7/200] [Batch 795/815] [D loss: -4.573032] [G loss: -27.900490]\n",
      "[Epoch 7/200] [Batch 800/815] [D loss: -5.076474] [G loss: -19.349150]\n",
      "[Epoch 7/200] [Batch 805/815] [D loss: -4.579581] [G loss: -21.915903]\n",
      "[Epoch 7/200] [Batch 810/815] [D loss: -5.877934] [G loss: -21.661631]\n",
      "[Epoch 8/200] [Batch 0/815] [D loss: -4.635156] [G loss: -19.948751]\n",
      "[Epoch 8/200] [Batch 5/815] [D loss: -4.797586] [G loss: -26.177464]\n",
      "[Epoch 8/200] [Batch 10/815] [D loss: -5.193498] [G loss: -20.091038]\n",
      "[Epoch 8/200] [Batch 15/815] [D loss: -4.884336] [G loss: -16.507177]\n",
      "[Epoch 8/200] [Batch 20/815] [D loss: -5.166419] [G loss: -23.209032]\n",
      "[Epoch 8/200] [Batch 25/815] [D loss: -5.628609] [G loss: -11.754134]\n",
      "[Epoch 8/200] [Batch 30/815] [D loss: -4.859735] [G loss: -17.257690]\n",
      "[Epoch 8/200] [Batch 35/815] [D loss: -6.495872] [G loss: -13.695275]\n",
      "[Epoch 8/200] [Batch 40/815] [D loss: -4.801335] [G loss: -23.654751]\n",
      "[Epoch 8/200] [Batch 45/815] [D loss: -6.268134] [G loss: -13.173410]\n",
      "[Epoch 8/200] [Batch 50/815] [D loss: -4.957766] [G loss: -22.982695]\n",
      "[Epoch 8/200] [Batch 55/815] [D loss: -4.477857] [G loss: -24.890377]\n",
      "[Epoch 8/200] [Batch 60/815] [D loss: -5.307107] [G loss: -15.236810]\n",
      "[Epoch 8/200] [Batch 65/815] [D loss: -5.763555] [G loss: -21.375868]\n",
      "[Epoch 8/200] [Batch 70/815] [D loss: -6.234686] [G loss: -13.993779]\n",
      "[Epoch 8/200] [Batch 75/815] [D loss: -4.632488] [G loss: -32.699932]\n",
      "[Epoch 8/200] [Batch 80/815] [D loss: -6.053378] [G loss: -10.795390]\n",
      "[Epoch 8/200] [Batch 85/815] [D loss: -4.275502] [G loss: -24.209938]\n",
      "[Epoch 8/200] [Batch 90/815] [D loss: -5.772631] [G loss: -16.039518]\n",
      "[Epoch 8/200] [Batch 95/815] [D loss: -5.435891] [G loss: -23.338833]\n",
      "[Epoch 8/200] [Batch 100/815] [D loss: -5.382543] [G loss: -23.381264]\n",
      "[Epoch 8/200] [Batch 105/815] [D loss: -5.300216] [G loss: -12.941023]\n",
      "[Epoch 8/200] [Batch 110/815] [D loss: -6.517960] [G loss: -10.885550]\n",
      "[Epoch 8/200] [Batch 115/815] [D loss: -6.008159] [G loss: -15.425573]\n",
      "[Epoch 8/200] [Batch 120/815] [D loss: -6.091947] [G loss: -20.086796]\n",
      "[Epoch 8/200] [Batch 125/815] [D loss: -5.720039] [G loss: -13.100204]\n",
      "[Epoch 8/200] [Batch 130/815] [D loss: -5.504860] [G loss: -16.396818]\n",
      "[Epoch 8/200] [Batch 135/815] [D loss: -4.871526] [G loss: -19.202536]\n",
      "[Epoch 8/200] [Batch 140/815] [D loss: -5.488042] [G loss: -18.435339]\n",
      "[Epoch 8/200] [Batch 145/815] [D loss: -5.194832] [G loss: -17.666792]\n",
      "[Epoch 8/200] [Batch 150/815] [D loss: -4.545828] [G loss: -21.658092]\n",
      "[Epoch 8/200] [Batch 155/815] [D loss: -5.041294] [G loss: -20.770016]\n",
      "[Epoch 8/200] [Batch 160/815] [D loss: -6.829540] [G loss: -14.203410]\n",
      "[Epoch 8/200] [Batch 165/815] [D loss: -5.139914] [G loss: -15.369313]\n",
      "[Epoch 8/200] [Batch 170/815] [D loss: -5.524549] [G loss: -20.894491]\n",
      "[Epoch 8/200] [Batch 175/815] [D loss: -5.472243] [G loss: -13.756698]\n",
      "[Epoch 8/200] [Batch 180/815] [D loss: -4.784353] [G loss: -18.299988]\n",
      "[Epoch 8/200] [Batch 185/815] [D loss: -5.748923] [G loss: -11.638381]\n",
      "[Epoch 8/200] [Batch 190/815] [D loss: -5.787010] [G loss: -17.938972]\n",
      "[Epoch 8/200] [Batch 195/815] [D loss: -5.042867] [G loss: -19.465061]\n",
      "[Epoch 8/200] [Batch 200/815] [D loss: -5.160870] [G loss: -19.805597]\n",
      "[Epoch 8/200] [Batch 205/815] [D loss: -5.874629] [G loss: -17.513672]\n",
      "[Epoch 8/200] [Batch 210/815] [D loss: -5.200813] [G loss: -17.827620]\n",
      "[Epoch 8/200] [Batch 215/815] [D loss: -4.584435] [G loss: -26.716475]\n",
      "[Epoch 8/200] [Batch 220/815] [D loss: -5.302228] [G loss: -17.684996]\n",
      "[Epoch 8/200] [Batch 225/815] [D loss: -6.500033] [G loss: -10.664797]\n",
      "[Epoch 8/200] [Batch 230/815] [D loss: -5.675399] [G loss: -17.339296]\n",
      "[Epoch 8/200] [Batch 235/815] [D loss: -5.456723] [G loss: -18.676565]\n",
      "[Epoch 8/200] [Batch 240/815] [D loss: -5.385207] [G loss: -19.839577]\n",
      "[Epoch 8/200] [Batch 245/815] [D loss: -4.711313] [G loss: -22.978605]\n",
      "[Epoch 8/200] [Batch 250/815] [D loss: -5.078361] [G loss: -25.339912]\n",
      "[Epoch 8/200] [Batch 255/815] [D loss: -5.830864] [G loss: -17.830610]\n",
      "[Epoch 8/200] [Batch 260/815] [D loss: -4.513264] [G loss: -30.986645]\n",
      "[Epoch 8/200] [Batch 265/815] [D loss: -4.667274] [G loss: -30.040955]\n",
      "[Epoch 8/200] [Batch 270/815] [D loss: -5.350731] [G loss: -14.277616]\n",
      "[Epoch 8/200] [Batch 275/815] [D loss: -5.681343] [G loss: -14.916370]\n",
      "[Epoch 8/200] [Batch 280/815] [D loss: -5.537171] [G loss: -24.267578]\n",
      "[Epoch 8/200] [Batch 285/815] [D loss: -6.155722] [G loss: -14.281068]\n",
      "[Epoch 8/200] [Batch 290/815] [D loss: -5.756510] [G loss: -11.775264]\n",
      "[Epoch 8/200] [Batch 295/815] [D loss: -6.558137] [G loss: -17.126987]\n",
      "[Epoch 8/200] [Batch 300/815] [D loss: -6.899576] [G loss: -12.126270]\n",
      "[Epoch 8/200] [Batch 305/815] [D loss: -5.373415] [G loss: -21.902386]\n",
      "[Epoch 8/200] [Batch 310/815] [D loss: -5.425709] [G loss: -16.240883]\n",
      "[Epoch 8/200] [Batch 315/815] [D loss: -5.605299] [G loss: -16.949184]\n",
      "[Epoch 8/200] [Batch 320/815] [D loss: -5.334257] [G loss: -16.957361]\n",
      "[Epoch 8/200] [Batch 325/815] [D loss: -6.586048] [G loss: -11.754074]\n",
      "[Epoch 8/200] [Batch 330/815] [D loss: -5.643642] [G loss: -22.773996]\n",
      "[Epoch 8/200] [Batch 335/815] [D loss: -6.073958] [G loss: -15.752559]\n",
      "[Epoch 8/200] [Batch 340/815] [D loss: -5.630438] [G loss: -19.695429]\n",
      "[Epoch 8/200] [Batch 345/815] [D loss: -4.746572] [G loss: -18.835083]\n",
      "[Epoch 8/200] [Batch 350/815] [D loss: -5.977050] [G loss: -16.908228]\n",
      "[Epoch 8/200] [Batch 355/815] [D loss: -4.725455] [G loss: -23.976343]\n",
      "[Epoch 8/200] [Batch 360/815] [D loss: -4.990260] [G loss: -19.095636]\n",
      "[Epoch 8/200] [Batch 365/815] [D loss: -5.864337] [G loss: -14.356670]\n",
      "[Epoch 8/200] [Batch 370/815] [D loss: -5.415048] [G loss: -17.649380]\n",
      "[Epoch 8/200] [Batch 375/815] [D loss: -5.467251] [G loss: -20.970749]\n",
      "[Epoch 8/200] [Batch 380/815] [D loss: -3.909218] [G loss: -27.573856]\n",
      "[Epoch 8/200] [Batch 385/815] [D loss: -5.055298] [G loss: -17.559513]\n",
      "[Epoch 8/200] [Batch 390/815] [D loss: -6.308244] [G loss: -16.745514]\n",
      "[Epoch 8/200] [Batch 395/815] [D loss: -5.761229] [G loss: -15.064785]\n",
      "[Epoch 8/200] [Batch 400/815] [D loss: -3.893667] [G loss: -26.848398]\n",
      "[Epoch 8/200] [Batch 405/815] [D loss: -4.576959] [G loss: -26.469870]\n",
      "[Epoch 8/200] [Batch 410/815] [D loss: -4.096378] [G loss: -30.547333]\n",
      "[Epoch 8/200] [Batch 415/815] [D loss: -4.970091] [G loss: -21.445105]\n",
      "[Epoch 8/200] [Batch 420/815] [D loss: -4.296159] [G loss: -30.145361]\n",
      "[Epoch 8/200] [Batch 425/815] [D loss: -5.514559] [G loss: -14.641754]\n",
      "[Epoch 8/200] [Batch 430/815] [D loss: -5.646370] [G loss: -15.841269]\n",
      "[Epoch 8/200] [Batch 435/815] [D loss: -4.362344] [G loss: -20.240450]\n",
      "[Epoch 8/200] [Batch 440/815] [D loss: -4.167433] [G loss: -15.746740]\n",
      "[Epoch 8/200] [Batch 445/815] [D loss: -5.942705] [G loss: -18.347490]\n",
      "[Epoch 8/200] [Batch 450/815] [D loss: -4.889086] [G loss: -23.210836]\n",
      "[Epoch 8/200] [Batch 455/815] [D loss: -6.159252] [G loss: -13.517627]\n",
      "[Epoch 8/200] [Batch 460/815] [D loss: -5.030660] [G loss: -23.186436]\n",
      "[Epoch 8/200] [Batch 465/815] [D loss: -6.423390] [G loss: -18.273207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 470/815] [D loss: -6.047270] [G loss: -14.627403]\n",
      "[Epoch 8/200] [Batch 475/815] [D loss: -4.969536] [G loss: -23.428719]\n",
      "[Epoch 8/200] [Batch 480/815] [D loss: -5.902713] [G loss: -14.506123]\n",
      "[Epoch 8/200] [Batch 485/815] [D loss: -5.426825] [G loss: -16.706409]\n",
      "[Epoch 8/200] [Batch 490/815] [D loss: -5.461553] [G loss: -13.008442]\n",
      "[Epoch 8/200] [Batch 495/815] [D loss: -5.425716] [G loss: -14.238832]\n",
      "[Epoch 8/200] [Batch 500/815] [D loss: -5.248765] [G loss: -17.083004]\n",
      "[Epoch 8/200] [Batch 505/815] [D loss: -5.176259] [G loss: -27.258068]\n",
      "[Epoch 8/200] [Batch 510/815] [D loss: -5.151264] [G loss: -18.639708]\n",
      "[Epoch 8/200] [Batch 515/815] [D loss: -6.171676] [G loss: -17.757235]\n",
      "[Epoch 8/200] [Batch 520/815] [D loss: -4.845382] [G loss: -22.122429]\n",
      "[Epoch 8/200] [Batch 525/815] [D loss: -5.427540] [G loss: -19.299385]\n",
      "[Epoch 8/200] [Batch 530/815] [D loss: -4.815145] [G loss: -22.828644]\n",
      "[Epoch 8/200] [Batch 535/815] [D loss: -5.337245] [G loss: -17.477201]\n",
      "[Epoch 8/200] [Batch 540/815] [D loss: -5.392600] [G loss: -19.515848]\n",
      "[Epoch 8/200] [Batch 545/815] [D loss: -4.713690] [G loss: -37.358143]\n",
      "[Epoch 8/200] [Batch 550/815] [D loss: -5.052728] [G loss: -17.642138]\n",
      "[Epoch 8/200] [Batch 555/815] [D loss: -5.512569] [G loss: -14.436766]\n",
      "[Epoch 8/200] [Batch 560/815] [D loss: -5.103446] [G loss: -19.454166]\n",
      "[Epoch 8/200] [Batch 565/815] [D loss: -5.124960] [G loss: -14.445040]\n",
      "[Epoch 8/200] [Batch 570/815] [D loss: -5.441823] [G loss: -16.630106]\n",
      "[Epoch 8/200] [Batch 575/815] [D loss: -4.852071] [G loss: -22.841143]\n",
      "[Epoch 8/200] [Batch 580/815] [D loss: -4.775911] [G loss: -31.215187]\n",
      "[Epoch 8/200] [Batch 585/815] [D loss: -5.346953] [G loss: -17.842949]\n",
      "[Epoch 8/200] [Batch 590/815] [D loss: -5.698965] [G loss: -13.287002]\n",
      "[Epoch 8/200] [Batch 595/815] [D loss: -4.284044] [G loss: -20.937971]\n",
      "[Epoch 8/200] [Batch 600/815] [D loss: -5.467654] [G loss: -12.751467]\n",
      "[Epoch 8/200] [Batch 605/815] [D loss: -5.469882] [G loss: -17.944086]\n",
      "[Epoch 8/200] [Batch 610/815] [D loss: -4.750744] [G loss: -16.624987]\n",
      "[Epoch 8/200] [Batch 615/815] [D loss: -5.561066] [G loss: -21.681660]\n",
      "[Epoch 8/200] [Batch 620/815] [D loss: -5.009594] [G loss: -15.884478]\n",
      "[Epoch 8/200] [Batch 625/815] [D loss: -5.234735] [G loss: -21.602325]\n",
      "[Epoch 8/200] [Batch 630/815] [D loss: -4.558085] [G loss: -23.179863]\n",
      "[Epoch 8/200] [Batch 635/815] [D loss: -5.542998] [G loss: -17.940485]\n",
      "[Epoch 8/200] [Batch 640/815] [D loss: -5.502973] [G loss: -19.189915]\n",
      "[Epoch 8/200] [Batch 645/815] [D loss: -5.716257] [G loss: -16.590889]\n",
      "[Epoch 8/200] [Batch 650/815] [D loss: -6.147103] [G loss: -14.011806]\n",
      "[Epoch 8/200] [Batch 655/815] [D loss: -5.469327] [G loss: -21.864626]\n",
      "[Epoch 8/200] [Batch 660/815] [D loss: -5.411125] [G loss: -13.535723]\n",
      "[Epoch 8/200] [Batch 665/815] [D loss: -4.661414] [G loss: -30.231796]\n",
      "[Epoch 8/200] [Batch 670/815] [D loss: -4.596665] [G loss: -18.754852]\n",
      "[Epoch 8/200] [Batch 675/815] [D loss: -5.858706] [G loss: -15.467836]\n",
      "[Epoch 8/200] [Batch 680/815] [D loss: -6.439222] [G loss: -19.245392]\n",
      "[Epoch 8/200] [Batch 685/815] [D loss: -5.294682] [G loss: -17.561367]\n",
      "[Epoch 8/200] [Batch 690/815] [D loss: -4.963174] [G loss: -14.559004]\n",
      "[Epoch 8/200] [Batch 695/815] [D loss: -4.579096] [G loss: -19.787350]\n",
      "[Epoch 8/200] [Batch 700/815] [D loss: -5.356514] [G loss: -23.805746]\n",
      "[Epoch 8/200] [Batch 705/815] [D loss: -5.589128] [G loss: -18.068943]\n",
      "[Epoch 8/200] [Batch 710/815] [D loss: -5.711084] [G loss: -15.279919]\n",
      "[Epoch 8/200] [Batch 715/815] [D loss: -5.441275] [G loss: -23.408239]\n",
      "[Epoch 8/200] [Batch 720/815] [D loss: -5.206390] [G loss: -15.811324]\n",
      "[Epoch 8/200] [Batch 725/815] [D loss: -5.623517] [G loss: -12.628541]\n",
      "[Epoch 8/200] [Batch 730/815] [D loss: -4.252347] [G loss: -21.556231]\n",
      "[Epoch 8/200] [Batch 735/815] [D loss: -5.181571] [G loss: -15.349156]\n",
      "[Epoch 8/200] [Batch 740/815] [D loss: -5.002116] [G loss: -20.810165]\n",
      "[Epoch 8/200] [Batch 745/815] [D loss: -5.050061] [G loss: -24.022980]\n",
      "[Epoch 8/200] [Batch 750/815] [D loss: -5.686059] [G loss: -14.156036]\n",
      "[Epoch 8/200] [Batch 755/815] [D loss: -5.212658] [G loss: -15.805762]\n",
      "[Epoch 8/200] [Batch 760/815] [D loss: -5.070889] [G loss: -14.103285]\n",
      "[Epoch 8/200] [Batch 765/815] [D loss: -4.274677] [G loss: -21.358103]\n",
      "[Epoch 8/200] [Batch 770/815] [D loss: -6.380391] [G loss: -14.825202]\n",
      "[Epoch 8/200] [Batch 775/815] [D loss: -5.470658] [G loss: -17.882601]\n",
      "[Epoch 8/200] [Batch 780/815] [D loss: -4.497593] [G loss: -28.092203]\n",
      "[Epoch 8/200] [Batch 785/815] [D loss: -5.621032] [G loss: -15.207293]\n",
      "[Epoch 8/200] [Batch 790/815] [D loss: -5.535724] [G loss: -15.077761]\n",
      "[Epoch 8/200] [Batch 795/815] [D loss: -5.683236] [G loss: -21.982573]\n",
      "[Epoch 8/200] [Batch 800/815] [D loss: -5.017167] [G loss: -16.530643]\n",
      "[Epoch 8/200] [Batch 805/815] [D loss: -4.974185] [G loss: -25.628853]\n",
      "[Epoch 8/200] [Batch 810/815] [D loss: -4.814666] [G loss: -13.325528]\n",
      "[Epoch 9/200] [Batch 0/815] [D loss: -5.051744] [G loss: -21.811186]\n",
      "[Epoch 9/200] [Batch 5/815] [D loss: -5.533680] [G loss: -20.085888]\n",
      "[Epoch 9/200] [Batch 10/815] [D loss: -5.129860] [G loss: -17.724388]\n",
      "[Epoch 9/200] [Batch 15/815] [D loss: -4.950540] [G loss: -15.248147]\n",
      "[Epoch 9/200] [Batch 20/815] [D loss: -6.091566] [G loss: -12.074958]\n",
      "[Epoch 9/200] [Batch 25/815] [D loss: -5.213776] [G loss: -17.489042]\n",
      "[Epoch 9/200] [Batch 30/815] [D loss: -7.146476] [G loss: -10.318172]\n",
      "[Epoch 9/200] [Batch 35/815] [D loss: -5.375202] [G loss: -19.501829]\n",
      "[Epoch 9/200] [Batch 40/815] [D loss: -5.360290] [G loss: -20.946541]\n",
      "[Epoch 9/200] [Batch 45/815] [D loss: -5.274626] [G loss: -14.513886]\n",
      "[Epoch 9/200] [Batch 50/815] [D loss: -5.993394] [G loss: -13.908984]\n",
      "[Epoch 9/200] [Batch 55/815] [D loss: -6.196933] [G loss: -14.082079]\n",
      "[Epoch 9/200] [Batch 60/815] [D loss: -5.637390] [G loss: -20.142891]\n",
      "[Epoch 9/200] [Batch 65/815] [D loss: -5.426953] [G loss: -15.818385]\n",
      "[Epoch 9/200] [Batch 70/815] [D loss: -6.000025] [G loss: -13.513497]\n",
      "[Epoch 9/200] [Batch 75/815] [D loss: -5.615771] [G loss: -13.823890]\n",
      "[Epoch 9/200] [Batch 80/815] [D loss: -5.012021] [G loss: -21.819872]\n",
      "[Epoch 9/200] [Batch 85/815] [D loss: -6.132935] [G loss: -22.808054]\n",
      "[Epoch 9/200] [Batch 90/815] [D loss: -5.552978] [G loss: -15.461856]\n",
      "[Epoch 9/200] [Batch 95/815] [D loss: -5.306803] [G loss: -16.846981]\n",
      "[Epoch 9/200] [Batch 100/815] [D loss: -5.117959] [G loss: -22.081308]\n",
      "[Epoch 9/200] [Batch 105/815] [D loss: -5.447845] [G loss: -18.141140]\n",
      "[Epoch 9/200] [Batch 110/815] [D loss: -4.660742] [G loss: -22.631456]\n",
      "[Epoch 9/200] [Batch 115/815] [D loss: -5.159768] [G loss: -18.011095]\n",
      "[Epoch 9/200] [Batch 120/815] [D loss: -5.538475] [G loss: -15.678181]\n",
      "[Epoch 9/200] [Batch 125/815] [D loss: -6.132442] [G loss: -12.630990]\n",
      "[Epoch 9/200] [Batch 130/815] [D loss: -4.775865] [G loss: -25.890520]\n",
      "[Epoch 9/200] [Batch 135/815] [D loss: -5.201317] [G loss: -16.237505]\n",
      "[Epoch 9/200] [Batch 140/815] [D loss: -4.806056] [G loss: -26.109928]\n",
      "[Epoch 9/200] [Batch 145/815] [D loss: -4.877377] [G loss: -12.499330]\n",
      "[Epoch 9/200] [Batch 150/815] [D loss: -5.855199] [G loss: -14.558502]\n",
      "[Epoch 9/200] [Batch 155/815] [D loss: -4.588596] [G loss: -19.429756]\n",
      "[Epoch 9/200] [Batch 160/815] [D loss: -6.004567] [G loss: -16.045862]\n",
      "[Epoch 9/200] [Batch 165/815] [D loss: -5.478570] [G loss: -19.001659]\n",
      "[Epoch 9/200] [Batch 170/815] [D loss: -4.692129] [G loss: -24.399204]\n",
      "[Epoch 9/200] [Batch 175/815] [D loss: -5.548784] [G loss: -14.509829]\n",
      "[Epoch 9/200] [Batch 180/815] [D loss: -5.435249] [G loss: -22.732822]\n",
      "[Epoch 9/200] [Batch 185/815] [D loss: -5.708818] [G loss: -22.682348]\n",
      "[Epoch 9/200] [Batch 190/815] [D loss: -5.120087] [G loss: -13.923768]\n",
      "[Epoch 9/200] [Batch 195/815] [D loss: -5.738407] [G loss: -15.815896]\n",
      "[Epoch 9/200] [Batch 200/815] [D loss: -5.644838] [G loss: -15.838141]\n",
      "[Epoch 9/200] [Batch 205/815] [D loss: -5.227971] [G loss: -22.046139]\n",
      "[Epoch 9/200] [Batch 210/815] [D loss: -5.227952] [G loss: -21.087772]\n",
      "[Epoch 9/200] [Batch 215/815] [D loss: -5.515738] [G loss: -14.258396]\n",
      "[Epoch 9/200] [Batch 220/815] [D loss: -6.685333] [G loss: -12.182818]\n",
      "[Epoch 9/200] [Batch 225/815] [D loss: -6.041041] [G loss: -16.945290]\n",
      "[Epoch 9/200] [Batch 230/815] [D loss: -5.332804] [G loss: -16.111246]\n",
      "[Epoch 9/200] [Batch 235/815] [D loss: -1.978686] [G loss: -24.196974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 240/815] [D loss: -5.322313] [G loss: -19.985189]\n",
      "[Epoch 9/200] [Batch 245/815] [D loss: -4.863173] [G loss: -17.440676]\n",
      "[Epoch 9/200] [Batch 250/815] [D loss: -3.854771] [G loss: -17.620268]\n",
      "[Epoch 9/200] [Batch 255/815] [D loss: -5.540995] [G loss: -13.454039]\n",
      "[Epoch 9/200] [Batch 260/815] [D loss: -5.217056] [G loss: -16.870705]\n",
      "[Epoch 9/200] [Batch 265/815] [D loss: -6.301844] [G loss: -12.849309]\n",
      "[Epoch 9/200] [Batch 270/815] [D loss: -4.781648] [G loss: -24.060953]\n",
      "[Epoch 9/200] [Batch 275/815] [D loss: -4.578229] [G loss: -17.660023]\n",
      "[Epoch 9/200] [Batch 280/815] [D loss: -6.287367] [G loss: -15.095547]\n",
      "[Epoch 9/200] [Batch 285/815] [D loss: -4.764013] [G loss: -24.155752]\n",
      "[Epoch 9/200] [Batch 290/815] [D loss: -5.513961] [G loss: -15.319407]\n",
      "[Epoch 9/200] [Batch 295/815] [D loss: -5.578828] [G loss: -14.876757]\n",
      "[Epoch 9/200] [Batch 300/815] [D loss: -5.236215] [G loss: -15.583797]\n",
      "[Epoch 9/200] [Batch 305/815] [D loss: -5.348646] [G loss: -26.805285]\n",
      "[Epoch 9/200] [Batch 310/815] [D loss: -5.837721] [G loss: -15.693331]\n",
      "[Epoch 9/200] [Batch 315/815] [D loss: -5.607317] [G loss: -17.580107]\n",
      "[Epoch 9/200] [Batch 320/815] [D loss: -5.505826] [G loss: -22.351582]\n",
      "[Epoch 9/200] [Batch 325/815] [D loss: -5.797381] [G loss: -14.931250]\n",
      "[Epoch 9/200] [Batch 330/815] [D loss: -6.255249] [G loss: -20.390388]\n",
      "[Epoch 9/200] [Batch 335/815] [D loss: -5.067715] [G loss: -16.695917]\n",
      "[Epoch 9/200] [Batch 340/815] [D loss: -3.958873] [G loss: -29.325836]\n",
      "[Epoch 9/200] [Batch 345/815] [D loss: -5.767851] [G loss: -9.061728]\n",
      "[Epoch 9/200] [Batch 350/815] [D loss: -5.831381] [G loss: -14.902362]\n",
      "[Epoch 9/200] [Batch 355/815] [D loss: -6.020485] [G loss: -15.868025]\n",
      "[Epoch 9/200] [Batch 360/815] [D loss: -4.548923] [G loss: -18.960257]\n",
      "[Epoch 9/200] [Batch 365/815] [D loss: -5.232933] [G loss: -26.002502]\n",
      "[Epoch 9/200] [Batch 370/815] [D loss: -5.259322] [G loss: -21.353970]\n",
      "[Epoch 9/200] [Batch 375/815] [D loss: -4.519661] [G loss: -27.155678]\n",
      "[Epoch 9/200] [Batch 380/815] [D loss: -5.285354] [G loss: -16.450830]\n",
      "[Epoch 9/200] [Batch 385/815] [D loss: -5.742305] [G loss: -13.638796]\n",
      "[Epoch 9/200] [Batch 390/815] [D loss: -3.918338] [G loss: -24.403786]\n",
      "[Epoch 9/200] [Batch 395/815] [D loss: -4.595255] [G loss: -23.096020]\n",
      "[Epoch 9/200] [Batch 400/815] [D loss: -5.307043] [G loss: -13.335372]\n",
      "[Epoch 9/200] [Batch 405/815] [D loss: -5.480106] [G loss: -24.933258]\n",
      "[Epoch 9/200] [Batch 410/815] [D loss: -5.792522] [G loss: -10.468851]\n",
      "[Epoch 9/200] [Batch 415/815] [D loss: -6.297210] [G loss: -12.849868]\n",
      "[Epoch 9/200] [Batch 420/815] [D loss: -5.373947] [G loss: -14.773971]\n",
      "[Epoch 9/200] [Batch 425/815] [D loss: -5.487510] [G loss: -17.535900]\n",
      "[Epoch 9/200] [Batch 430/815] [D loss: -5.981966] [G loss: -14.349262]\n",
      "[Epoch 9/200] [Batch 435/815] [D loss: -5.383587] [G loss: -17.551882]\n",
      "[Epoch 9/200] [Batch 440/815] [D loss: -5.764377] [G loss: -19.579327]\n",
      "[Epoch 9/200] [Batch 445/815] [D loss: -5.036008] [G loss: -12.326736]\n",
      "[Epoch 9/200] [Batch 450/815] [D loss: -4.830389] [G loss: -27.501894]\n",
      "[Epoch 9/200] [Batch 455/815] [D loss: -5.476144] [G loss: -15.909671]\n",
      "[Epoch 9/200] [Batch 460/815] [D loss: -4.802045] [G loss: -19.706619]\n",
      "[Epoch 9/200] [Batch 465/815] [D loss: -5.361441] [G loss: -16.715231]\n",
      "[Epoch 9/200] [Batch 470/815] [D loss: -5.253743] [G loss: -19.807558]\n",
      "[Epoch 9/200] [Batch 475/815] [D loss: -5.211877] [G loss: -20.259796]\n",
      "[Epoch 9/200] [Batch 480/815] [D loss: -6.124248] [G loss: -13.475494]\n",
      "[Epoch 9/200] [Batch 485/815] [D loss: -4.968100] [G loss: -15.676555]\n",
      "[Epoch 9/200] [Batch 490/815] [D loss: -4.741817] [G loss: -21.776104]\n",
      "[Epoch 9/200] [Batch 495/815] [D loss: -4.986301] [G loss: -11.810019]\n",
      "[Epoch 9/200] [Batch 500/815] [D loss: -5.268460] [G loss: -16.554176]\n",
      "[Epoch 9/200] [Batch 505/815] [D loss: -6.054365] [G loss: -11.054282]\n",
      "[Epoch 9/200] [Batch 510/815] [D loss: -4.501322] [G loss: -31.540949]\n",
      "[Epoch 9/200] [Batch 515/815] [D loss: -5.336422] [G loss: -14.509252]\n",
      "[Epoch 9/200] [Batch 520/815] [D loss: -5.825234] [G loss: -14.322533]\n",
      "[Epoch 9/200] [Batch 525/815] [D loss: -4.785030] [G loss: -27.358835]\n",
      "[Epoch 9/200] [Batch 530/815] [D loss: -5.383553] [G loss: -20.616055]\n",
      "[Epoch 9/200] [Batch 535/815] [D loss: -5.431584] [G loss: -17.361996]\n",
      "[Epoch 9/200] [Batch 540/815] [D loss: -4.514759] [G loss: -23.388151]\n",
      "[Epoch 9/200] [Batch 545/815] [D loss: -5.019300] [G loss: -18.311794]\n",
      "[Epoch 9/200] [Batch 550/815] [D loss: -4.889115] [G loss: -16.688412]\n",
      "[Epoch 9/200] [Batch 555/815] [D loss: -5.726880] [G loss: -12.844430]\n",
      "[Epoch 9/200] [Batch 560/815] [D loss: -5.491507] [G loss: -15.363958]\n",
      "[Epoch 9/200] [Batch 565/815] [D loss: -4.716405] [G loss: -18.754133]\n",
      "[Epoch 9/200] [Batch 570/815] [D loss: -5.819148] [G loss: -18.522028]\n",
      "[Epoch 9/200] [Batch 575/815] [D loss: -5.611792] [G loss: -14.340635]\n",
      "[Epoch 9/200] [Batch 580/815] [D loss: -5.379294] [G loss: -14.956676]\n",
      "[Epoch 9/200] [Batch 585/815] [D loss: -5.512905] [G loss: -15.075582]\n",
      "[Epoch 9/200] [Batch 590/815] [D loss: -5.455701] [G loss: -26.757465]\n",
      "[Epoch 9/200] [Batch 595/815] [D loss: -3.846408] [G loss: -31.117243]\n",
      "[Epoch 9/200] [Batch 600/815] [D loss: -4.836355] [G loss: -21.056362]\n",
      "[Epoch 9/200] [Batch 605/815] [D loss: -4.795142] [G loss: -16.045601]\n",
      "[Epoch 9/200] [Batch 610/815] [D loss: -5.777418] [G loss: -13.987716]\n",
      "[Epoch 9/200] [Batch 615/815] [D loss: -5.258383] [G loss: -21.163738]\n",
      "[Epoch 9/200] [Batch 620/815] [D loss: -3.712382] [G loss: -23.686563]\n",
      "[Epoch 9/200] [Batch 625/815] [D loss: -5.435462] [G loss: -17.240032]\n",
      "[Epoch 9/200] [Batch 630/815] [D loss: -5.513105] [G loss: -17.009972]\n",
      "[Epoch 9/200] [Batch 635/815] [D loss: -6.675738] [G loss: -11.694895]\n",
      "[Epoch 9/200] [Batch 640/815] [D loss: -7.591224] [G loss: -14.564497]\n",
      "[Epoch 9/200] [Batch 645/815] [D loss: -4.678111] [G loss: -18.406286]\n",
      "[Epoch 9/200] [Batch 650/815] [D loss: -6.017250] [G loss: -12.693065]\n",
      "[Epoch 9/200] [Batch 655/815] [D loss: -5.813128] [G loss: -10.814298]\n",
      "[Epoch 9/200] [Batch 660/815] [D loss: -5.597795] [G loss: -14.296601]\n",
      "[Epoch 9/200] [Batch 665/815] [D loss: -5.535151] [G loss: -18.568777]\n",
      "[Epoch 9/200] [Batch 670/815] [D loss: -5.772746] [G loss: -13.520216]\n",
      "[Epoch 9/200] [Batch 675/815] [D loss: -5.418786] [G loss: -15.894748]\n",
      "[Epoch 9/200] [Batch 680/815] [D loss: -5.525662] [G loss: -17.621542]\n",
      "[Epoch 9/200] [Batch 685/815] [D loss: -5.994213] [G loss: -18.625570]\n",
      "[Epoch 9/200] [Batch 690/815] [D loss: -3.341759] [G loss: -28.671410]\n",
      "[Epoch 9/200] [Batch 695/815] [D loss: -5.213142] [G loss: -15.370406]\n",
      "[Epoch 9/200] [Batch 700/815] [D loss: -4.929533] [G loss: -21.150402]\n",
      "[Epoch 9/200] [Batch 705/815] [D loss: -4.542200] [G loss: -15.720037]\n",
      "[Epoch 9/200] [Batch 710/815] [D loss: -4.974319] [G loss: -16.163094]\n",
      "[Epoch 9/200] [Batch 715/815] [D loss: -6.103848] [G loss: -11.125393]\n",
      "[Epoch 9/200] [Batch 720/815] [D loss: -5.165946] [G loss: -23.401474]\n",
      "[Epoch 9/200] [Batch 725/815] [D loss: -4.707831] [G loss: -26.271009]\n",
      "[Epoch 9/200] [Batch 730/815] [D loss: -5.119359] [G loss: -22.048971]\n",
      "[Epoch 9/200] [Batch 735/815] [D loss: -5.204621] [G loss: -23.628059]\n",
      "[Epoch 9/200] [Batch 740/815] [D loss: -5.202289] [G loss: -14.477505]\n",
      "[Epoch 9/200] [Batch 745/815] [D loss: -5.159493] [G loss: -27.639648]\n",
      "[Epoch 9/200] [Batch 750/815] [D loss: -5.172325] [G loss: -15.893910]\n",
      "[Epoch 9/200] [Batch 755/815] [D loss: -4.983273] [G loss: -16.075586]\n",
      "[Epoch 9/200] [Batch 760/815] [D loss: -4.938405] [G loss: -28.969675]\n",
      "[Epoch 9/200] [Batch 765/815] [D loss: -4.362653] [G loss: -24.574226]\n",
      "[Epoch 9/200] [Batch 770/815] [D loss: -4.672985] [G loss: -16.200233]\n",
      "[Epoch 9/200] [Batch 775/815] [D loss: -5.457660] [G loss: -20.259733]\n",
      "[Epoch 9/200] [Batch 780/815] [D loss: -5.206059] [G loss: -11.945306]\n",
      "[Epoch 9/200] [Batch 785/815] [D loss: -6.038460] [G loss: -18.664400]\n",
      "[Epoch 9/200] [Batch 790/815] [D loss: -4.347722] [G loss: -22.295359]\n",
      "[Epoch 9/200] [Batch 795/815] [D loss: -4.938826] [G loss: -25.560488]\n",
      "[Epoch 9/200] [Batch 800/815] [D loss: -4.684010] [G loss: -16.335814]\n",
      "[Epoch 9/200] [Batch 805/815] [D loss: -6.081775] [G loss: -16.727953]\n",
      "[Epoch 9/200] [Batch 810/815] [D loss: -5.752651] [G loss: -21.927074]\n",
      "[Epoch 10/200] [Batch 0/815] [D loss: -2.652869] [G loss: -17.241646]\n",
      "[Epoch 10/200] [Batch 5/815] [D loss: -5.940349] [G loss: -13.987117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 10/815] [D loss: -5.602415] [G loss: -22.096237]\n",
      "[Epoch 10/200] [Batch 15/815] [D loss: -5.187534] [G loss: -23.173317]\n",
      "[Epoch 10/200] [Batch 20/815] [D loss: -4.345328] [G loss: -27.073139]\n",
      "[Epoch 10/200] [Batch 25/815] [D loss: -5.573545] [G loss: -18.056173]\n",
      "[Epoch 10/200] [Batch 30/815] [D loss: -5.356817] [G loss: -16.998339]\n",
      "[Epoch 10/200] [Batch 35/815] [D loss: -5.841283] [G loss: -16.539013]\n",
      "[Epoch 10/200] [Batch 40/815] [D loss: -5.830472] [G loss: -14.919331]\n",
      "[Epoch 10/200] [Batch 45/815] [D loss: -4.917006] [G loss: -16.851326]\n",
      "[Epoch 10/200] [Batch 50/815] [D loss: -5.460155] [G loss: -13.461324]\n",
      "[Epoch 10/200] [Batch 55/815] [D loss: -7.008275] [G loss: -15.616494]\n",
      "[Epoch 10/200] [Batch 60/815] [D loss: -5.638953] [G loss: -18.782221]\n",
      "[Epoch 10/200] [Batch 65/815] [D loss: -6.049026] [G loss: -13.738570]\n",
      "[Epoch 10/200] [Batch 70/815] [D loss: -5.446087] [G loss: -21.051918]\n",
      "[Epoch 10/200] [Batch 75/815] [D loss: -5.123178] [G loss: -16.150871]\n",
      "[Epoch 10/200] [Batch 80/815] [D loss: -5.561663] [G loss: -13.684551]\n",
      "[Epoch 10/200] [Batch 85/815] [D loss: -5.360422] [G loss: -17.075665]\n",
      "[Epoch 10/200] [Batch 90/815] [D loss: -5.811331] [G loss: -17.045404]\n",
      "[Epoch 10/200] [Batch 95/815] [D loss: -6.462752] [G loss: -15.446947]\n",
      "[Epoch 10/200] [Batch 100/815] [D loss: -4.742430] [G loss: -19.364157]\n",
      "[Epoch 10/200] [Batch 105/815] [D loss: -5.261419] [G loss: -19.393318]\n",
      "[Epoch 10/200] [Batch 110/815] [D loss: -6.209486] [G loss: -21.748867]\n",
      "[Epoch 10/200] [Batch 115/815] [D loss: -5.760693] [G loss: -11.355203]\n",
      "[Epoch 10/200] [Batch 120/815] [D loss: -5.545902] [G loss: -14.743474]\n",
      "[Epoch 10/200] [Batch 125/815] [D loss: -5.845320] [G loss: -22.237658]\n",
      "[Epoch 10/200] [Batch 130/815] [D loss: -5.102145] [G loss: -16.820002]\n",
      "[Epoch 10/200] [Batch 135/815] [D loss: -3.811184] [G loss: -34.720516]\n",
      "[Epoch 10/200] [Batch 140/815] [D loss: -5.279387] [G loss: -19.041813]\n",
      "[Epoch 10/200] [Batch 145/815] [D loss: -5.703708] [G loss: -16.460283]\n",
      "[Epoch 10/200] [Batch 150/815] [D loss: -5.266650] [G loss: -19.229910]\n",
      "[Epoch 10/200] [Batch 155/815] [D loss: -4.701748] [G loss: -30.352959]\n",
      "[Epoch 10/200] [Batch 160/815] [D loss: -5.035529] [G loss: -16.965790]\n",
      "[Epoch 10/200] [Batch 165/815] [D loss: -5.073677] [G loss: -19.932652]\n",
      "[Epoch 10/200] [Batch 170/815] [D loss: -4.922810] [G loss: -17.357862]\n",
      "[Epoch 10/200] [Batch 175/815] [D loss: -6.101805] [G loss: -12.343429]\n",
      "[Epoch 10/200] [Batch 180/815] [D loss: -5.094711] [G loss: -22.886242]\n",
      "[Epoch 10/200] [Batch 185/815] [D loss: -5.481060] [G loss: -13.742002]\n",
      "[Epoch 10/200] [Batch 190/815] [D loss: -6.014970] [G loss: -12.798676]\n",
      "[Epoch 10/200] [Batch 195/815] [D loss: -5.277427] [G loss: -12.981771]\n",
      "[Epoch 10/200] [Batch 200/815] [D loss: -5.075000] [G loss: -21.627895]\n",
      "[Epoch 10/200] [Batch 205/815] [D loss: -4.978855] [G loss: -15.288034]\n",
      "[Epoch 10/200] [Batch 210/815] [D loss: -5.609977] [G loss: -15.083777]\n",
      "[Epoch 10/200] [Batch 215/815] [D loss: -5.064689] [G loss: -23.964479]\n",
      "[Epoch 10/200] [Batch 220/815] [D loss: -5.321444] [G loss: -15.327080]\n",
      "[Epoch 10/200] [Batch 225/815] [D loss: -4.867498] [G loss: -16.447037]\n",
      "[Epoch 10/200] [Batch 230/815] [D loss: -5.572061] [G loss: -17.789507]\n",
      "[Epoch 10/200] [Batch 235/815] [D loss: -5.748480] [G loss: -17.434072]\n",
      "[Epoch 10/200] [Batch 240/815] [D loss: -6.316946] [G loss: -15.629316]\n",
      "[Epoch 10/200] [Batch 245/815] [D loss: -5.514544] [G loss: -16.769852]\n",
      "[Epoch 10/200] [Batch 250/815] [D loss: -5.985285] [G loss: -18.714863]\n",
      "[Epoch 10/200] [Batch 255/815] [D loss: -5.794157] [G loss: -18.509951]\n",
      "[Epoch 10/200] [Batch 260/815] [D loss: -5.975543] [G loss: -22.786760]\n",
      "[Epoch 10/200] [Batch 265/815] [D loss: -5.692082] [G loss: -16.257750]\n",
      "[Epoch 10/200] [Batch 270/815] [D loss: -4.999430] [G loss: -20.173178]\n",
      "[Epoch 10/200] [Batch 275/815] [D loss: -4.591001] [G loss: -22.142559]\n",
      "[Epoch 10/200] [Batch 280/815] [D loss: -4.826694] [G loss: -18.946100]\n",
      "[Epoch 10/200] [Batch 285/815] [D loss: -5.244579] [G loss: -18.953779]\n",
      "[Epoch 10/200] [Batch 290/815] [D loss: -6.629118] [G loss: -14.457529]\n",
      "[Epoch 10/200] [Batch 295/815] [D loss: -4.817231] [G loss: -25.622423]\n",
      "[Epoch 10/200] [Batch 300/815] [D loss: -4.675366] [G loss: -23.249880]\n",
      "[Epoch 10/200] [Batch 305/815] [D loss: -5.585118] [G loss: -18.703350]\n",
      "[Epoch 10/200] [Batch 310/815] [D loss: -6.517542] [G loss: -17.026512]\n",
      "[Epoch 10/200] [Batch 315/815] [D loss: -6.444761] [G loss: -14.093061]\n",
      "[Epoch 10/200] [Batch 320/815] [D loss: -5.478370] [G loss: -15.885812]\n",
      "[Epoch 10/200] [Batch 325/815] [D loss: -6.541239] [G loss: -14.276125]\n",
      "[Epoch 10/200] [Batch 330/815] [D loss: -5.007160] [G loss: -28.242304]\n",
      "[Epoch 10/200] [Batch 335/815] [D loss: -5.026630] [G loss: -21.567583]\n",
      "[Epoch 10/200] [Batch 340/815] [D loss: -5.561618] [G loss: -16.995113]\n",
      "[Epoch 10/200] [Batch 345/815] [D loss: -5.184820] [G loss: -20.163557]\n",
      "[Epoch 10/200] [Batch 350/815] [D loss: -5.300376] [G loss: -13.765115]\n",
      "[Epoch 10/200] [Batch 355/815] [D loss: -6.320441] [G loss: -14.451221]\n",
      "[Epoch 10/200] [Batch 360/815] [D loss: -5.678436] [G loss: -23.453396]\n",
      "[Epoch 10/200] [Batch 365/815] [D loss: -6.921333] [G loss: -16.456591]\n",
      "[Epoch 10/200] [Batch 370/815] [D loss: -4.655266] [G loss: -25.912382]\n",
      "[Epoch 10/200] [Batch 375/815] [D loss: -5.999143] [G loss: -12.882261]\n",
      "[Epoch 10/200] [Batch 380/815] [D loss: -4.763024] [G loss: -23.572273]\n",
      "[Epoch 10/200] [Batch 385/815] [D loss: -4.430373] [G loss: -24.106579]\n",
      "[Epoch 10/200] [Batch 390/815] [D loss: -5.547329] [G loss: -14.520296]\n",
      "[Epoch 10/200] [Batch 395/815] [D loss: -6.067600] [G loss: -14.401644]\n",
      "[Epoch 10/200] [Batch 400/815] [D loss: -5.705428] [G loss: -16.614344]\n",
      "[Epoch 10/200] [Batch 405/815] [D loss: -5.051163] [G loss: -26.553291]\n",
      "[Epoch 10/200] [Batch 410/815] [D loss: -4.524655] [G loss: -27.835051]\n",
      "[Epoch 10/200] [Batch 415/815] [D loss: -5.099063] [G loss: -17.095707]\n",
      "[Epoch 10/200] [Batch 420/815] [D loss: -5.336579] [G loss: -16.745642]\n",
      "[Epoch 10/200] [Batch 425/815] [D loss: -4.766404] [G loss: -22.203915]\n",
      "[Epoch 10/200] [Batch 430/815] [D loss: -4.208831] [G loss: -19.629276]\n",
      "[Epoch 10/200] [Batch 435/815] [D loss: -5.757237] [G loss: -13.989581]\n",
      "[Epoch 10/200] [Batch 440/815] [D loss: -5.357136] [G loss: -19.552929]\n",
      "[Epoch 10/200] [Batch 445/815] [D loss: -5.667782] [G loss: -13.959708]\n",
      "[Epoch 10/200] [Batch 450/815] [D loss: -4.752584] [G loss: -20.690485]\n",
      "[Epoch 10/200] [Batch 455/815] [D loss: -4.732200] [G loss: -29.606964]\n",
      "[Epoch 10/200] [Batch 460/815] [D loss: -4.733017] [G loss: -20.766670]\n",
      "[Epoch 10/200] [Batch 465/815] [D loss: -5.361959] [G loss: -11.871282]\n",
      "[Epoch 10/200] [Batch 470/815] [D loss: -5.654236] [G loss: -10.610676]\n",
      "[Epoch 10/200] [Batch 475/815] [D loss: -4.570710] [G loss: -24.062656]\n",
      "[Epoch 10/200] [Batch 480/815] [D loss: -4.456044] [G loss: -26.229218]\n",
      "[Epoch 10/200] [Batch 485/815] [D loss: -5.530962] [G loss: -14.509179]\n",
      "[Epoch 10/200] [Batch 490/815] [D loss: -5.489626] [G loss: -22.014845]\n",
      "[Epoch 10/200] [Batch 495/815] [D loss: -5.184650] [G loss: -13.658471]\n",
      "[Epoch 10/200] [Batch 500/815] [D loss: -5.957222] [G loss: -15.581375]\n",
      "[Epoch 10/200] [Batch 505/815] [D loss: -3.523808] [G loss: -37.412273]\n",
      "[Epoch 10/200] [Batch 510/815] [D loss: -5.534912] [G loss: -15.103608]\n",
      "[Epoch 10/200] [Batch 515/815] [D loss: -5.506022] [G loss: -13.671099]\n",
      "[Epoch 10/200] [Batch 520/815] [D loss: -6.238635] [G loss: -11.760620]\n",
      "[Epoch 10/200] [Batch 525/815] [D loss: -4.979115] [G loss: -19.201363]\n",
      "[Epoch 10/200] [Batch 530/815] [D loss: -4.974717] [G loss: -24.252851]\n",
      "[Epoch 10/200] [Batch 535/815] [D loss: -4.991798] [G loss: -28.029165]\n",
      "[Epoch 10/200] [Batch 540/815] [D loss: -5.513102] [G loss: -13.865991]\n",
      "[Epoch 10/200] [Batch 545/815] [D loss: -4.648097] [G loss: -31.652550]\n",
      "[Epoch 10/200] [Batch 550/815] [D loss: -6.593657] [G loss: -12.211063]\n",
      "[Epoch 10/200] [Batch 555/815] [D loss: -6.321836] [G loss: -16.289165]\n",
      "[Epoch 10/200] [Batch 560/815] [D loss: -5.194528] [G loss: -21.401934]\n",
      "[Epoch 10/200] [Batch 565/815] [D loss: -5.134354] [G loss: -14.904295]\n",
      "[Epoch 10/200] [Batch 570/815] [D loss: -5.326519] [G loss: -14.662663]\n",
      "[Epoch 10/200] [Batch 575/815] [D loss: -5.319842] [G loss: -28.481960]\n",
      "[Epoch 10/200] [Batch 580/815] [D loss: -4.618239] [G loss: -23.330692]\n",
      "[Epoch 10/200] [Batch 585/815] [D loss: -5.317824] [G loss: -16.021074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/200] [Batch 590/815] [D loss: -4.091475] [G loss: -18.618778]\n",
      "[Epoch 10/200] [Batch 595/815] [D loss: -6.396653] [G loss: -22.323832]\n",
      "[Epoch 10/200] [Batch 600/815] [D loss: -4.897419] [G loss: -23.215490]\n",
      "[Epoch 10/200] [Batch 605/815] [D loss: -4.667513] [G loss: -20.802341]\n",
      "[Epoch 10/200] [Batch 610/815] [D loss: -4.888280] [G loss: -16.414568]\n",
      "[Epoch 10/200] [Batch 615/815] [D loss: -5.369035] [G loss: -16.324244]\n",
      "[Epoch 10/200] [Batch 620/815] [D loss: -4.680907] [G loss: -11.684625]\n",
      "[Epoch 10/200] [Batch 625/815] [D loss: -5.004513] [G loss: -16.888567]\n",
      "[Epoch 10/200] [Batch 630/815] [D loss: -5.317194] [G loss: -17.730137]\n",
      "[Epoch 10/200] [Batch 635/815] [D loss: -5.842248] [G loss: -12.970479]\n",
      "[Epoch 10/200] [Batch 640/815] [D loss: -5.103732] [G loss: -20.982199]\n",
      "[Epoch 10/200] [Batch 645/815] [D loss: -5.820107] [G loss: -16.537649]\n",
      "[Epoch 10/200] [Batch 650/815] [D loss: -3.433036] [G loss: -18.460508]\n",
      "[Epoch 10/200] [Batch 655/815] [D loss: -5.996755] [G loss: -13.563574]\n",
      "[Epoch 10/200] [Batch 660/815] [D loss: -4.587254] [G loss: -23.891296]\n",
      "[Epoch 10/200] [Batch 665/815] [D loss: -5.938185] [G loss: -15.384236]\n",
      "[Epoch 10/200] [Batch 670/815] [D loss: -5.077378] [G loss: -24.295588]\n",
      "[Epoch 10/200] [Batch 675/815] [D loss: -5.003148] [G loss: -21.033600]\n",
      "[Epoch 10/200] [Batch 680/815] [D loss: -5.785161] [G loss: -20.370865]\n",
      "[Epoch 10/200] [Batch 685/815] [D loss: -5.656117] [G loss: -18.723402]\n",
      "[Epoch 10/200] [Batch 690/815] [D loss: -5.505599] [G loss: -20.047077]\n",
      "[Epoch 10/200] [Batch 695/815] [D loss: -5.739663] [G loss: -14.294299]\n",
      "[Epoch 10/200] [Batch 700/815] [D loss: -5.435919] [G loss: -13.148226]\n",
      "[Epoch 10/200] [Batch 705/815] [D loss: -6.546500] [G loss: -12.724552]\n",
      "[Epoch 10/200] [Batch 710/815] [D loss: -5.625733] [G loss: -13.169662]\n",
      "[Epoch 10/200] [Batch 715/815] [D loss: -4.892162] [G loss: -21.747824]\n",
      "[Epoch 10/200] [Batch 720/815] [D loss: -4.569814] [G loss: -21.810482]\n",
      "[Epoch 10/200] [Batch 725/815] [D loss: -6.061178] [G loss: -15.010605]\n",
      "[Epoch 10/200] [Batch 730/815] [D loss: -4.917284] [G loss: -28.302546]\n",
      "[Epoch 10/200] [Batch 735/815] [D loss: -5.895246] [G loss: -11.261692]\n",
      "[Epoch 10/200] [Batch 740/815] [D loss: -4.752466] [G loss: -29.441589]\n",
      "[Epoch 10/200] [Batch 745/815] [D loss: -5.083424] [G loss: -17.858402]\n",
      "[Epoch 10/200] [Batch 750/815] [D loss: -5.814500] [G loss: -14.931239]\n",
      "[Epoch 10/200] [Batch 755/815] [D loss: -5.704554] [G loss: -16.534086]\n",
      "[Epoch 10/200] [Batch 760/815] [D loss: -5.221993] [G loss: -15.724620]\n",
      "[Epoch 10/200] [Batch 765/815] [D loss: -3.752466] [G loss: -27.538910]\n",
      "[Epoch 10/200] [Batch 770/815] [D loss: -5.185715] [G loss: -13.079581]\n",
      "[Epoch 10/200] [Batch 775/815] [D loss: -6.318142] [G loss: -13.912786]\n",
      "[Epoch 10/200] [Batch 780/815] [D loss: -5.477241] [G loss: -16.756315]\n",
      "[Epoch 10/200] [Batch 785/815] [D loss: -4.396476] [G loss: -20.252861]\n",
      "[Epoch 10/200] [Batch 790/815] [D loss: -5.465743] [G loss: -13.590277]\n",
      "[Epoch 10/200] [Batch 795/815] [D loss: -4.898319] [G loss: -17.552708]\n",
      "[Epoch 10/200] [Batch 800/815] [D loss: -4.480085] [G loss: -23.599499]\n",
      "[Epoch 10/200] [Batch 805/815] [D loss: -5.453233] [G loss: -14.426671]\n",
      "[Epoch 10/200] [Batch 810/815] [D loss: -5.276208] [G loss: -21.900660]\n",
      "[Epoch 11/200] [Batch 0/815] [D loss: -4.627879] [G loss: -27.523335]\n",
      "[Epoch 11/200] [Batch 5/815] [D loss: -5.250198] [G loss: -16.205997]\n",
      "[Epoch 11/200] [Batch 10/815] [D loss: -4.362141] [G loss: -24.821651]\n",
      "[Epoch 11/200] [Batch 15/815] [D loss: -4.369683] [G loss: -28.537519]\n",
      "[Epoch 11/200] [Batch 20/815] [D loss: -5.579944] [G loss: -16.958416]\n",
      "[Epoch 11/200] [Batch 25/815] [D loss: -5.132151] [G loss: -25.065369]\n",
      "[Epoch 11/200] [Batch 30/815] [D loss: -5.956560] [G loss: -12.429691]\n",
      "[Epoch 11/200] [Batch 35/815] [D loss: -5.720441] [G loss: -11.670298]\n",
      "[Epoch 11/200] [Batch 40/815] [D loss: -6.285493] [G loss: -17.170242]\n",
      "[Epoch 11/200] [Batch 45/815] [D loss: -4.003821] [G loss: -25.258986]\n",
      "[Epoch 11/200] [Batch 50/815] [D loss: -6.148592] [G loss: -11.763823]\n",
      "[Epoch 11/200] [Batch 55/815] [D loss: -4.904301] [G loss: -15.312701]\n",
      "[Epoch 11/200] [Batch 60/815] [D loss: -5.924535] [G loss: -21.218824]\n",
      "[Epoch 11/200] [Batch 65/815] [D loss: -5.073049] [G loss: -17.661299]\n",
      "[Epoch 11/200] [Batch 70/815] [D loss: -5.200155] [G loss: -23.181328]\n",
      "[Epoch 11/200] [Batch 75/815] [D loss: -4.608762] [G loss: -23.921944]\n",
      "[Epoch 11/200] [Batch 80/815] [D loss: -5.215643] [G loss: -18.655287]\n",
      "[Epoch 11/200] [Batch 85/815] [D loss: -5.477323] [G loss: -14.257291]\n",
      "[Epoch 11/200] [Batch 90/815] [D loss: -6.678926] [G loss: -11.341598]\n",
      "[Epoch 11/200] [Batch 95/815] [D loss: -5.182890] [G loss: -20.635506]\n",
      "[Epoch 11/200] [Batch 100/815] [D loss: -4.966017] [G loss: -28.062843]\n",
      "[Epoch 11/200] [Batch 105/815] [D loss: -5.884714] [G loss: -11.788886]\n",
      "[Epoch 11/200] [Batch 110/815] [D loss: -5.392463] [G loss: -16.480570]\n",
      "[Epoch 11/200] [Batch 115/815] [D loss: -5.361829] [G loss: -16.913208]\n",
      "[Epoch 11/200] [Batch 120/815] [D loss: -5.251260] [G loss: -17.451628]\n",
      "[Epoch 11/200] [Batch 125/815] [D loss: -5.203711] [G loss: -16.081682]\n",
      "[Epoch 11/200] [Batch 130/815] [D loss: -6.146287] [G loss: -23.825651]\n",
      "[Epoch 11/200] [Batch 135/815] [D loss: -5.212674] [G loss: -18.784969]\n",
      "[Epoch 11/200] [Batch 140/815] [D loss: -5.095671] [G loss: -16.935778]\n",
      "[Epoch 11/200] [Batch 145/815] [D loss: -5.882911] [G loss: -13.863661]\n",
      "[Epoch 11/200] [Batch 150/815] [D loss: -5.112484] [G loss: -19.761593]\n",
      "[Epoch 11/200] [Batch 155/815] [D loss: -6.263981] [G loss: -16.022230]\n",
      "[Epoch 11/200] [Batch 160/815] [D loss: -5.888876] [G loss: -18.239777]\n",
      "[Epoch 11/200] [Batch 165/815] [D loss: -5.609012] [G loss: -17.531767]\n",
      "[Epoch 11/200] [Batch 170/815] [D loss: -5.458881] [G loss: -16.648983]\n",
      "[Epoch 11/200] [Batch 175/815] [D loss: -4.844368] [G loss: -19.483814]\n",
      "[Epoch 11/200] [Batch 180/815] [D loss: -5.195065] [G loss: -14.475959]\n",
      "[Epoch 11/200] [Batch 185/815] [D loss: -6.152831] [G loss: -14.500338]\n",
      "[Epoch 11/200] [Batch 190/815] [D loss: -5.571267] [G loss: -18.206621]\n",
      "[Epoch 11/200] [Batch 195/815] [D loss: -5.705955] [G loss: -14.547197]\n",
      "[Epoch 11/200] [Batch 200/815] [D loss: -4.974020] [G loss: -20.584814]\n",
      "[Epoch 11/200] [Batch 205/815] [D loss: -6.679080] [G loss: -19.321781]\n",
      "[Epoch 11/200] [Batch 210/815] [D loss: -5.176957] [G loss: -15.948386]\n",
      "[Epoch 11/200] [Batch 215/815] [D loss: -4.674349] [G loss: -18.495070]\n",
      "[Epoch 11/200] [Batch 220/815] [D loss: -5.637487] [G loss: -14.521794]\n",
      "[Epoch 11/200] [Batch 225/815] [D loss: -5.354943] [G loss: -12.673757]\n",
      "[Epoch 11/200] [Batch 230/815] [D loss: -4.657263] [G loss: -22.244379]\n",
      "[Epoch 11/200] [Batch 235/815] [D loss: -5.199839] [G loss: -15.665754]\n",
      "[Epoch 11/200] [Batch 240/815] [D loss: -5.392642] [G loss: -16.751350]\n",
      "[Epoch 11/200] [Batch 245/815] [D loss: -5.257677] [G loss: -15.330415]\n",
      "[Epoch 11/200] [Batch 250/815] [D loss: -5.647465] [G loss: -21.113100]\n",
      "[Epoch 11/200] [Batch 255/815] [D loss: -5.406880] [G loss: -14.928578]\n",
      "[Epoch 11/200] [Batch 260/815] [D loss: -5.474443] [G loss: -11.616238]\n",
      "[Epoch 11/200] [Batch 265/815] [D loss: -5.861028] [G loss: -15.164383]\n",
      "[Epoch 11/200] [Batch 270/815] [D loss: -6.080229] [G loss: -23.036812]\n",
      "[Epoch 11/200] [Batch 275/815] [D loss: -4.676265] [G loss: -14.736215]\n",
      "[Epoch 11/200] [Batch 280/815] [D loss: -4.804293] [G loss: -20.667465]\n",
      "[Epoch 11/200] [Batch 285/815] [D loss: -5.068912] [G loss: -15.730067]\n",
      "[Epoch 11/200] [Batch 290/815] [D loss: -5.722369] [G loss: -17.159809]\n",
      "[Epoch 11/200] [Batch 295/815] [D loss: -5.536370] [G loss: -15.344606]\n",
      "[Epoch 11/200] [Batch 300/815] [D loss: -5.029619] [G loss: -15.239090]\n",
      "[Epoch 11/200] [Batch 305/815] [D loss: -5.328056] [G loss: -17.251974]\n",
      "[Epoch 11/200] [Batch 310/815] [D loss: -5.456116] [G loss: -14.351120]\n",
      "[Epoch 11/200] [Batch 315/815] [D loss: -4.425324] [G loss: -23.170290]\n",
      "[Epoch 11/200] [Batch 320/815] [D loss: -4.723513] [G loss: -20.372040]\n",
      "[Epoch 11/200] [Batch 325/815] [D loss: -5.060557] [G loss: -15.863532]\n",
      "[Epoch 11/200] [Batch 330/815] [D loss: -6.225475] [G loss: -24.215273]\n",
      "[Epoch 11/200] [Batch 335/815] [D loss: -5.584179] [G loss: -16.576050]\n",
      "[Epoch 11/200] [Batch 340/815] [D loss: -6.874146] [G loss: -10.200604]\n",
      "[Epoch 11/200] [Batch 345/815] [D loss: -5.566706] [G loss: -20.998255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/200] [Batch 350/815] [D loss: -5.006342] [G loss: -19.226912]\n",
      "[Epoch 11/200] [Batch 355/815] [D loss: -6.518073] [G loss: -15.952255]\n",
      "[Epoch 11/200] [Batch 360/815] [D loss: -5.910288] [G loss: -20.904221]\n",
      "[Epoch 11/200] [Batch 365/815] [D loss: -6.055677] [G loss: -18.003054]\n",
      "[Epoch 11/200] [Batch 370/815] [D loss: -5.860356] [G loss: -15.449233]\n",
      "[Epoch 11/200] [Batch 375/815] [D loss: -5.130338] [G loss: -24.274065]\n",
      "[Epoch 11/200] [Batch 380/815] [D loss: -5.472215] [G loss: -21.021053]\n",
      "[Epoch 11/200] [Batch 385/815] [D loss: -7.365034] [G loss: -11.805499]\n",
      "[Epoch 11/200] [Batch 390/815] [D loss: -6.109713] [G loss: -11.299306]\n",
      "[Epoch 11/200] [Batch 395/815] [D loss: -4.291221] [G loss: -22.253819]\n",
      "[Epoch 11/200] [Batch 400/815] [D loss: -4.899590] [G loss: -23.268583]\n",
      "[Epoch 11/200] [Batch 405/815] [D loss: -5.187350] [G loss: -14.097113]\n",
      "[Epoch 11/200] [Batch 410/815] [D loss: -4.329856] [G loss: -22.317150]\n",
      "[Epoch 11/200] [Batch 415/815] [D loss: -5.158701] [G loss: -17.512346]\n",
      "[Epoch 11/200] [Batch 420/815] [D loss: -6.280111] [G loss: -17.091045]\n",
      "[Epoch 11/200] [Batch 425/815] [D loss: -5.206985] [G loss: -11.258043]\n",
      "[Epoch 11/200] [Batch 430/815] [D loss: -5.604344] [G loss: -15.154493]\n",
      "[Epoch 11/200] [Batch 435/815] [D loss: -6.352252] [G loss: -14.498353]\n",
      "[Epoch 11/200] [Batch 440/815] [D loss: -6.288145] [G loss: -12.755603]\n",
      "[Epoch 11/200] [Batch 445/815] [D loss: -5.976157] [G loss: -13.845875]\n",
      "[Epoch 11/200] [Batch 450/815] [D loss: -4.532251] [G loss: -33.753304]\n",
      "[Epoch 11/200] [Batch 455/815] [D loss: -5.835727] [G loss: -15.899663]\n",
      "[Epoch 11/200] [Batch 460/815] [D loss: -4.711562] [G loss: -26.622383]\n",
      "[Epoch 11/200] [Batch 465/815] [D loss: -5.771485] [G loss: -17.963211]\n",
      "[Epoch 11/200] [Batch 470/815] [D loss: -4.089844] [G loss: -29.135979]\n",
      "[Epoch 11/200] [Batch 475/815] [D loss: -6.175940] [G loss: -13.809977]\n",
      "[Epoch 11/200] [Batch 480/815] [D loss: -5.196672] [G loss: -17.039267]\n",
      "[Epoch 11/200] [Batch 485/815] [D loss: -4.623863] [G loss: -22.702019]\n",
      "[Epoch 11/200] [Batch 490/815] [D loss: -5.031224] [G loss: -16.331810]\n",
      "[Epoch 11/200] [Batch 495/815] [D loss: -5.939248] [G loss: -13.323493]\n",
      "[Epoch 11/200] [Batch 500/815] [D loss: -5.160769] [G loss: -28.109797]\n",
      "[Epoch 11/200] [Batch 505/815] [D loss: -5.097144] [G loss: -13.240933]\n",
      "[Epoch 11/200] [Batch 510/815] [D loss: -5.677758] [G loss: -17.183210]\n",
      "[Epoch 11/200] [Batch 515/815] [D loss: -5.434419] [G loss: -19.379459]\n",
      "[Epoch 11/200] [Batch 520/815] [D loss: -5.644117] [G loss: -15.744778]\n",
      "[Epoch 11/200] [Batch 525/815] [D loss: -5.299360] [G loss: -24.149305]\n",
      "[Epoch 11/200] [Batch 530/815] [D loss: -5.530745] [G loss: -20.294538]\n",
      "[Epoch 11/200] [Batch 535/815] [D loss: -6.697568] [G loss: -13.030597]\n",
      "[Epoch 11/200] [Batch 540/815] [D loss: -5.111430] [G loss: -17.385651]\n",
      "[Epoch 11/200] [Batch 545/815] [D loss: -5.384286] [G loss: -17.586874]\n",
      "[Epoch 11/200] [Batch 550/815] [D loss: -6.140077] [G loss: -11.450445]\n",
      "[Epoch 11/200] [Batch 555/815] [D loss: -4.777298] [G loss: -26.355251]\n",
      "[Epoch 11/200] [Batch 560/815] [D loss: -5.113353] [G loss: -27.028399]\n",
      "[Epoch 11/200] [Batch 565/815] [D loss: -5.754533] [G loss: -14.093575]\n",
      "[Epoch 11/200] [Batch 570/815] [D loss: -5.604032] [G loss: -20.225727]\n",
      "[Epoch 11/200] [Batch 575/815] [D loss: -6.701055] [G loss: -18.318449]\n",
      "[Epoch 11/200] [Batch 580/815] [D loss: -5.560701] [G loss: -16.020014]\n",
      "[Epoch 11/200] [Batch 585/815] [D loss: -5.234923] [G loss: -18.953304]\n",
      "[Epoch 11/200] [Batch 590/815] [D loss: -6.631763] [G loss: -15.803368]\n",
      "[Epoch 11/200] [Batch 595/815] [D loss: -5.538986] [G loss: -18.440125]\n",
      "[Epoch 11/200] [Batch 600/815] [D loss: -5.157888] [G loss: -14.822579]\n",
      "[Epoch 11/200] [Batch 605/815] [D loss: -4.268815] [G loss: -27.144064]\n",
      "[Epoch 11/200] [Batch 610/815] [D loss: -5.074431] [G loss: -17.888401]\n",
      "[Epoch 11/200] [Batch 615/815] [D loss: -4.875076] [G loss: -22.860485]\n",
      "[Epoch 11/200] [Batch 620/815] [D loss: -4.522127] [G loss: -25.666565]\n",
      "[Epoch 11/200] [Batch 625/815] [D loss: -5.146335] [G loss: -17.323572]\n",
      "[Epoch 11/200] [Batch 630/815] [D loss: -5.479499] [G loss: -15.179463]\n",
      "[Epoch 11/200] [Batch 635/815] [D loss: -4.338129] [G loss: -28.267477]\n",
      "[Epoch 11/200] [Batch 640/815] [D loss: -4.963453] [G loss: -23.998241]\n",
      "[Epoch 11/200] [Batch 645/815] [D loss: -5.179674] [G loss: -25.841024]\n",
      "[Epoch 11/200] [Batch 650/815] [D loss: -4.402506] [G loss: -20.984962]\n",
      "[Epoch 11/200] [Batch 655/815] [D loss: -5.910209] [G loss: -14.418650]\n",
      "[Epoch 11/200] [Batch 660/815] [D loss: -5.721976] [G loss: -11.308102]\n",
      "[Epoch 11/200] [Batch 665/815] [D loss: -5.924921] [G loss: -12.395577]\n",
      "[Epoch 11/200] [Batch 670/815] [D loss: -5.486565] [G loss: -19.713810]\n",
      "[Epoch 11/200] [Batch 675/815] [D loss: -5.229623] [G loss: -16.991117]\n",
      "[Epoch 11/200] [Batch 680/815] [D loss: -4.984200] [G loss: -16.190750]\n",
      "[Epoch 11/200] [Batch 685/815] [D loss: -6.296064] [G loss: -17.937407]\n",
      "[Epoch 11/200] [Batch 690/815] [D loss: -5.128288] [G loss: -19.034559]\n",
      "[Epoch 11/200] [Batch 695/815] [D loss: -5.085564] [G loss: -17.909559]\n",
      "[Epoch 11/200] [Batch 700/815] [D loss: -5.575413] [G loss: -15.945065]\n",
      "[Epoch 11/200] [Batch 705/815] [D loss: -5.014300] [G loss: -13.247062]\n",
      "[Epoch 11/200] [Batch 710/815] [D loss: -5.118680] [G loss: -17.609379]\n",
      "[Epoch 11/200] [Batch 715/815] [D loss: -5.802136] [G loss: -20.250141]\n",
      "[Epoch 11/200] [Batch 720/815] [D loss: -4.899878] [G loss: -18.763521]\n",
      "[Epoch 11/200] [Batch 725/815] [D loss: -5.866065] [G loss: -17.518114]\n",
      "[Epoch 11/200] [Batch 730/815] [D loss: -5.322103] [G loss: -37.015808]\n",
      "[Epoch 11/200] [Batch 735/815] [D loss: -4.795581] [G loss: -25.240759]\n",
      "[Epoch 11/200] [Batch 740/815] [D loss: -5.073586] [G loss: -23.534319]\n",
      "[Epoch 11/200] [Batch 745/815] [D loss: -5.576121] [G loss: -14.409343]\n",
      "[Epoch 11/200] [Batch 750/815] [D loss: -4.677796] [G loss: -20.806240]\n",
      "[Epoch 11/200] [Batch 755/815] [D loss: -5.813303] [G loss: -14.840480]\n",
      "[Epoch 11/200] [Batch 760/815] [D loss: -4.824791] [G loss: -18.786882]\n",
      "[Epoch 11/200] [Batch 765/815] [D loss: -6.152627] [G loss: -14.166418]\n",
      "[Epoch 11/200] [Batch 770/815] [D loss: -5.910203] [G loss: -14.480013]\n",
      "[Epoch 11/200] [Batch 775/815] [D loss: -4.951246] [G loss: -30.812172]\n",
      "[Epoch 11/200] [Batch 780/815] [D loss: -5.191677] [G loss: -19.650280]\n",
      "[Epoch 11/200] [Batch 785/815] [D loss: -5.980717] [G loss: -16.432093]\n",
      "[Epoch 11/200] [Batch 790/815] [D loss: -6.519356] [G loss: -17.487085]\n",
      "[Epoch 11/200] [Batch 795/815] [D loss: -4.625498] [G loss: -17.749863]\n",
      "[Epoch 11/200] [Batch 800/815] [D loss: -5.791624] [G loss: -25.741539]\n",
      "[Epoch 11/200] [Batch 805/815] [D loss: -4.919886] [G loss: -27.342922]\n",
      "[Epoch 11/200] [Batch 810/815] [D loss: -5.454485] [G loss: -15.148349]\n",
      "[Epoch 12/200] [Batch 0/815] [D loss: -4.396311] [G loss: -22.977375]\n",
      "[Epoch 12/200] [Batch 5/815] [D loss: -4.695040] [G loss: -24.145239]\n",
      "[Epoch 12/200] [Batch 10/815] [D loss: -4.654533] [G loss: -12.991145]\n",
      "[Epoch 12/200] [Batch 15/815] [D loss: -5.078177] [G loss: -14.488907]\n",
      "[Epoch 12/200] [Batch 20/815] [D loss: -5.414303] [G loss: -13.654744]\n",
      "[Epoch 12/200] [Batch 25/815] [D loss: -5.021125] [G loss: -18.449312]\n",
      "[Epoch 12/200] [Batch 30/815] [D loss: -5.098916] [G loss: -22.402538]\n",
      "[Epoch 12/200] [Batch 35/815] [D loss: -4.942103] [G loss: -14.867067]\n",
      "[Epoch 12/200] [Batch 40/815] [D loss: -5.326753] [G loss: -17.351295]\n",
      "[Epoch 12/200] [Batch 45/815] [D loss: -5.713437] [G loss: -18.246752]\n",
      "[Epoch 12/200] [Batch 50/815] [D loss: -5.456054] [G loss: -14.254627]\n",
      "[Epoch 12/200] [Batch 55/815] [D loss: -5.576223] [G loss: -14.181091]\n",
      "[Epoch 12/200] [Batch 60/815] [D loss: -5.357416] [G loss: -15.100766]\n",
      "[Epoch 12/200] [Batch 65/815] [D loss: -5.013766] [G loss: -23.301008]\n",
      "[Epoch 12/200] [Batch 70/815] [D loss: -5.709595] [G loss: -19.298496]\n",
      "[Epoch 12/200] [Batch 75/815] [D loss: -4.872015] [G loss: -29.897053]\n",
      "[Epoch 12/200] [Batch 80/815] [D loss: -5.108089] [G loss: -15.331600]\n",
      "[Epoch 12/200] [Batch 85/815] [D loss: -5.383420] [G loss: -21.326672]\n",
      "[Epoch 12/200] [Batch 90/815] [D loss: -4.760831] [G loss: -18.081316]\n",
      "[Epoch 12/200] [Batch 95/815] [D loss: -4.404795] [G loss: -22.092018]\n",
      "[Epoch 12/200] [Batch 100/815] [D loss: -6.132949] [G loss: -14.321355]\n",
      "[Epoch 12/200] [Batch 105/815] [D loss: -4.219503] [G loss: -23.438559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 110/815] [D loss: -5.305234] [G loss: -11.704787]\n",
      "[Epoch 12/200] [Batch 115/815] [D loss: -5.606192] [G loss: -19.310022]\n",
      "[Epoch 12/200] [Batch 120/815] [D loss: -5.695766] [G loss: -19.653603]\n",
      "[Epoch 12/200] [Batch 125/815] [D loss: -5.360674] [G loss: -14.542939]\n",
      "[Epoch 12/200] [Batch 130/815] [D loss: -5.343289] [G loss: -18.821327]\n",
      "[Epoch 12/200] [Batch 135/815] [D loss: -5.469453] [G loss: -23.949625]\n",
      "[Epoch 12/200] [Batch 140/815] [D loss: -4.364909] [G loss: -26.081743]\n",
      "[Epoch 12/200] [Batch 145/815] [D loss: -5.331557] [G loss: -26.173613]\n",
      "[Epoch 12/200] [Batch 150/815] [D loss: -6.035138] [G loss: -15.078716]\n",
      "[Epoch 12/200] [Batch 155/815] [D loss: -5.378822] [G loss: -14.659276]\n",
      "[Epoch 12/200] [Batch 160/815] [D loss: -5.970222] [G loss: -14.844789]\n",
      "[Epoch 12/200] [Batch 165/815] [D loss: -6.006336] [G loss: -11.192853]\n",
      "[Epoch 12/200] [Batch 170/815] [D loss: -6.080368] [G loss: -14.908423]\n",
      "[Epoch 12/200] [Batch 175/815] [D loss: -5.987183] [G loss: -19.459953]\n",
      "[Epoch 12/200] [Batch 180/815] [D loss: -5.378298] [G loss: -21.947519]\n",
      "[Epoch 12/200] [Batch 185/815] [D loss: -5.378146] [G loss: -19.616604]\n",
      "[Epoch 12/200] [Batch 190/815] [D loss: -4.609423] [G loss: -29.657932]\n",
      "[Epoch 12/200] [Batch 195/815] [D loss: -5.932872] [G loss: -14.352007]\n",
      "[Epoch 12/200] [Batch 200/815] [D loss: -4.536832] [G loss: -23.315481]\n",
      "[Epoch 12/200] [Batch 205/815] [D loss: -5.308366] [G loss: -13.257187]\n",
      "[Epoch 12/200] [Batch 210/815] [D loss: -5.004606] [G loss: -15.693879]\n",
      "[Epoch 12/200] [Batch 215/815] [D loss: -6.101843] [G loss: -12.069798]\n",
      "[Epoch 12/200] [Batch 220/815] [D loss: -5.017970] [G loss: -16.488668]\n",
      "[Epoch 12/200] [Batch 225/815] [D loss: -5.501611] [G loss: -17.092773]\n",
      "[Epoch 12/200] [Batch 230/815] [D loss: -4.670362] [G loss: -32.195652]\n",
      "[Epoch 12/200] [Batch 235/815] [D loss: -5.369009] [G loss: -16.859875]\n",
      "[Epoch 12/200] [Batch 240/815] [D loss: -5.983525] [G loss: -15.510830]\n",
      "[Epoch 12/200] [Batch 245/815] [D loss: -5.225531] [G loss: -14.987184]\n",
      "[Epoch 12/200] [Batch 250/815] [D loss: -5.236123] [G loss: -26.028273]\n",
      "[Epoch 12/200] [Batch 255/815] [D loss: -5.745797] [G loss: -20.192522]\n",
      "[Epoch 12/200] [Batch 260/815] [D loss: -4.930412] [G loss: -15.293436]\n",
      "[Epoch 12/200] [Batch 265/815] [D loss: -4.411944] [G loss: -20.190062]\n",
      "[Epoch 12/200] [Batch 270/815] [D loss: -4.824502] [G loss: -13.159325]\n",
      "[Epoch 12/200] [Batch 275/815] [D loss: -4.973012] [G loss: -23.635866]\n",
      "[Epoch 12/200] [Batch 280/815] [D loss: -6.318330] [G loss: -16.015827]\n",
      "[Epoch 12/200] [Batch 285/815] [D loss: -5.020826] [G loss: -14.722404]\n",
      "[Epoch 12/200] [Batch 290/815] [D loss: -5.159457] [G loss: -22.294735]\n",
      "[Epoch 12/200] [Batch 295/815] [D loss: -5.548064] [G loss: -12.049033]\n",
      "[Epoch 12/200] [Batch 300/815] [D loss: -4.898764] [G loss: -22.386618]\n",
      "[Epoch 12/200] [Batch 305/815] [D loss: -6.270903] [G loss: -12.107697]\n",
      "[Epoch 12/200] [Batch 310/815] [D loss: -4.774726] [G loss: -16.508608]\n",
      "[Epoch 12/200] [Batch 315/815] [D loss: -4.660266] [G loss: -16.872557]\n",
      "[Epoch 12/200] [Batch 320/815] [D loss: -4.782609] [G loss: -18.902178]\n",
      "[Epoch 12/200] [Batch 325/815] [D loss: -5.037377] [G loss: -17.037199]\n",
      "[Epoch 12/200] [Batch 330/815] [D loss: -6.517499] [G loss: -18.837536]\n",
      "[Epoch 12/200] [Batch 335/815] [D loss: -4.806391] [G loss: -15.645577]\n",
      "[Epoch 12/200] [Batch 340/815] [D loss: -5.836911] [G loss: -15.598609]\n",
      "[Epoch 12/200] [Batch 345/815] [D loss: -5.348060] [G loss: -15.503682]\n",
      "[Epoch 12/200] [Batch 350/815] [D loss: -5.419316] [G loss: -15.632870]\n",
      "[Epoch 12/200] [Batch 355/815] [D loss: -5.539443] [G loss: -17.589285]\n",
      "[Epoch 12/200] [Batch 360/815] [D loss: -5.207322] [G loss: -20.531597]\n",
      "[Epoch 12/200] [Batch 365/815] [D loss: -5.640531] [G loss: -13.802579]\n",
      "[Epoch 12/200] [Batch 370/815] [D loss: -5.912426] [G loss: -14.962026]\n",
      "[Epoch 12/200] [Batch 375/815] [D loss: -6.272376] [G loss: -24.429838]\n",
      "[Epoch 12/200] [Batch 380/815] [D loss: -5.693707] [G loss: -15.172012]\n",
      "[Epoch 12/200] [Batch 385/815] [D loss: -5.795882] [G loss: -19.463598]\n",
      "[Epoch 12/200] [Batch 390/815] [D loss: -5.231217] [G loss: -25.059877]\n",
      "[Epoch 12/200] [Batch 395/815] [D loss: -4.847275] [G loss: -19.600420]\n",
      "[Epoch 12/200] [Batch 400/815] [D loss: -6.656022] [G loss: -10.953691]\n",
      "[Epoch 12/200] [Batch 405/815] [D loss: -5.350700] [G loss: -15.688005]\n",
      "[Epoch 12/200] [Batch 410/815] [D loss: -4.853058] [G loss: -27.985334]\n",
      "[Epoch 12/200] [Batch 415/815] [D loss: -5.349575] [G loss: -13.869241]\n",
      "[Epoch 12/200] [Batch 420/815] [D loss: -4.741303] [G loss: -32.398827]\n",
      "[Epoch 12/200] [Batch 425/815] [D loss: -4.983343] [G loss: -19.444746]\n",
      "[Epoch 12/200] [Batch 430/815] [D loss: -5.813581] [G loss: -14.636727]\n",
      "[Epoch 12/200] [Batch 435/815] [D loss: -4.791841] [G loss: -14.353521]\n",
      "[Epoch 12/200] [Batch 440/815] [D loss: -6.430230] [G loss: -17.132862]\n",
      "[Epoch 12/200] [Batch 445/815] [D loss: -5.789406] [G loss: -22.631670]\n",
      "[Epoch 12/200] [Batch 450/815] [D loss: -4.632329] [G loss: -24.330437]\n",
      "[Epoch 12/200] [Batch 455/815] [D loss: -6.530443] [G loss: -10.995077]\n",
      "[Epoch 12/200] [Batch 460/815] [D loss: -5.956433] [G loss: -13.644819]\n",
      "[Epoch 12/200] [Batch 465/815] [D loss: -5.717078] [G loss: -16.708235]\n",
      "[Epoch 12/200] [Batch 470/815] [D loss: -5.260996] [G loss: -24.080391]\n",
      "[Epoch 12/200] [Batch 475/815] [D loss: -6.378646] [G loss: -11.333819]\n",
      "[Epoch 12/200] [Batch 480/815] [D loss: -5.859364] [G loss: -19.461233]\n",
      "[Epoch 12/200] [Batch 485/815] [D loss: -4.758673] [G loss: -18.475779]\n",
      "[Epoch 12/200] [Batch 490/815] [D loss: -5.927943] [G loss: -13.028540]\n",
      "[Epoch 12/200] [Batch 495/815] [D loss: -4.917445] [G loss: -23.631998]\n",
      "[Epoch 12/200] [Batch 500/815] [D loss: -4.812617] [G loss: -13.135417]\n",
      "[Epoch 12/200] [Batch 505/815] [D loss: -5.336569] [G loss: -21.555960]\n",
      "[Epoch 12/200] [Batch 510/815] [D loss: -4.346393] [G loss: -21.734020]\n",
      "[Epoch 12/200] [Batch 515/815] [D loss: -4.219431] [G loss: -27.900234]\n",
      "[Epoch 12/200] [Batch 520/815] [D loss: -5.138158] [G loss: -15.935316]\n",
      "[Epoch 12/200] [Batch 525/815] [D loss: -5.649698] [G loss: -16.690189]\n",
      "[Epoch 12/200] [Batch 530/815] [D loss: -5.129612] [G loss: -19.158676]\n",
      "[Epoch 12/200] [Batch 535/815] [D loss: -5.845966] [G loss: -12.438375]\n",
      "[Epoch 12/200] [Batch 540/815] [D loss: -6.790109] [G loss: -15.916815]\n",
      "[Epoch 12/200] [Batch 545/815] [D loss: -5.283922] [G loss: -17.877216]\n",
      "[Epoch 12/200] [Batch 550/815] [D loss: -5.908301] [G loss: -20.998003]\n",
      "[Epoch 12/200] [Batch 555/815] [D loss: -6.061829] [G loss: -14.342564]\n",
      "[Epoch 12/200] [Batch 560/815] [D loss: -5.537168] [G loss: -15.336446]\n",
      "[Epoch 12/200] [Batch 565/815] [D loss: -5.366563] [G loss: -20.313490]\n",
      "[Epoch 12/200] [Batch 570/815] [D loss: -5.857089] [G loss: -17.413168]\n",
      "[Epoch 12/200] [Batch 575/815] [D loss: -4.914805] [G loss: -32.457474]\n",
      "[Epoch 12/200] [Batch 580/815] [D loss: -5.076258] [G loss: -13.824276]\n",
      "[Epoch 12/200] [Batch 585/815] [D loss: -6.381514] [G loss: -13.159101]\n",
      "[Epoch 12/200] [Batch 590/815] [D loss: -6.254488] [G loss: -13.774620]\n",
      "[Epoch 12/200] [Batch 595/815] [D loss: -4.098771] [G loss: -27.041656]\n",
      "[Epoch 12/200] [Batch 600/815] [D loss: -5.199261] [G loss: -14.089924]\n",
      "[Epoch 12/200] [Batch 605/815] [D loss: -5.443035] [G loss: -15.052270]\n",
      "[Epoch 12/200] [Batch 610/815] [D loss: -5.022808] [G loss: -21.155066]\n",
      "[Epoch 12/200] [Batch 615/815] [D loss: -3.938796] [G loss: -26.391247]\n",
      "[Epoch 12/200] [Batch 620/815] [D loss: -4.327996] [G loss: -21.384329]\n",
      "[Epoch 12/200] [Batch 625/815] [D loss: -4.791254] [G loss: -17.249407]\n",
      "[Epoch 12/200] [Batch 630/815] [D loss: -5.025406] [G loss: -16.553782]\n",
      "[Epoch 12/200] [Batch 635/815] [D loss: -4.921484] [G loss: -14.677626]\n",
      "[Epoch 12/200] [Batch 640/815] [D loss: -5.206910] [G loss: -16.036499]\n",
      "[Epoch 12/200] [Batch 645/815] [D loss: -5.629528] [G loss: -27.033085]\n",
      "[Epoch 12/200] [Batch 650/815] [D loss: -4.890770] [G loss: -16.944065]\n",
      "[Epoch 12/200] [Batch 655/815] [D loss: -5.971949] [G loss: -19.640314]\n",
      "[Epoch 12/200] [Batch 660/815] [D loss: -5.359446] [G loss: -10.014308]\n",
      "[Epoch 12/200] [Batch 665/815] [D loss: -6.014187] [G loss: -14.865515]\n",
      "[Epoch 12/200] [Batch 670/815] [D loss: -5.006784] [G loss: -16.855433]\n",
      "[Epoch 12/200] [Batch 675/815] [D loss: -4.973513] [G loss: -24.363573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 680/815] [D loss: -5.053064] [G loss: -21.336704]\n",
      "[Epoch 12/200] [Batch 685/815] [D loss: -5.509264] [G loss: -20.616638]\n",
      "[Epoch 12/200] [Batch 690/815] [D loss: -5.780079] [G loss: -14.222561]\n",
      "[Epoch 12/200] [Batch 695/815] [D loss: -7.125468] [G loss: -14.253152]\n",
      "[Epoch 12/200] [Batch 700/815] [D loss: -5.458113] [G loss: -14.898717]\n",
      "[Epoch 12/200] [Batch 705/815] [D loss: -5.429780] [G loss: -23.401415]\n",
      "[Epoch 12/200] [Batch 710/815] [D loss: -5.593744] [G loss: -18.779413]\n",
      "[Epoch 12/200] [Batch 715/815] [D loss: -5.475663] [G loss: -14.472202]\n",
      "[Epoch 12/200] [Batch 720/815] [D loss: -6.115707] [G loss: -16.851122]\n",
      "[Epoch 12/200] [Batch 725/815] [D loss: -4.716858] [G loss: -20.230305]\n",
      "[Epoch 12/200] [Batch 730/815] [D loss: -6.353034] [G loss: -12.677052]\n",
      "[Epoch 12/200] [Batch 735/815] [D loss: -6.358509] [G loss: -25.034384]\n",
      "[Epoch 12/200] [Batch 740/815] [D loss: -5.160686] [G loss: -19.793554]\n",
      "[Epoch 12/200] [Batch 745/815] [D loss: -6.170889] [G loss: -14.974309]\n",
      "[Epoch 12/200] [Batch 750/815] [D loss: -5.813925] [G loss: -14.917980]\n",
      "[Epoch 12/200] [Batch 755/815] [D loss: -5.505257] [G loss: -22.107416]\n",
      "[Epoch 12/200] [Batch 760/815] [D loss: -4.985706] [G loss: -14.381186]\n",
      "[Epoch 12/200] [Batch 765/815] [D loss: -5.393746] [G loss: -24.482700]\n",
      "[Epoch 12/200] [Batch 770/815] [D loss: -6.419563] [G loss: -15.311221]\n",
      "[Epoch 12/200] [Batch 775/815] [D loss: -4.586983] [G loss: -28.083731]\n",
      "[Epoch 12/200] [Batch 780/815] [D loss: -5.762151] [G loss: -13.210648]\n",
      "[Epoch 12/200] [Batch 785/815] [D loss: -5.538160] [G loss: -18.013697]\n",
      "[Epoch 12/200] [Batch 790/815] [D loss: -2.619836] [G loss: -35.433754]\n",
      "[Epoch 12/200] [Batch 795/815] [D loss: -5.609592] [G loss: -15.976110]\n",
      "[Epoch 12/200] [Batch 800/815] [D loss: -5.629681] [G loss: -15.263556]\n",
      "[Epoch 12/200] [Batch 805/815] [D loss: -5.965384] [G loss: -13.704810]\n",
      "[Epoch 12/200] [Batch 810/815] [D loss: -5.628507] [G loss: -14.376061]\n",
      "[Epoch 13/200] [Batch 0/815] [D loss: -4.763634] [G loss: -25.593916]\n",
      "[Epoch 13/200] [Batch 5/815] [D loss: -6.364647] [G loss: -10.901073]\n",
      "[Epoch 13/200] [Batch 10/815] [D loss: -4.838003] [G loss: -13.630369]\n",
      "[Epoch 13/200] [Batch 15/815] [D loss: -5.417886] [G loss: -18.316174]\n",
      "[Epoch 13/200] [Batch 20/815] [D loss: -5.597925] [G loss: -22.440554]\n",
      "[Epoch 13/200] [Batch 25/815] [D loss: -5.965675] [G loss: -21.511822]\n",
      "[Epoch 13/200] [Batch 30/815] [D loss: -5.055160] [G loss: -33.738697]\n",
      "[Epoch 13/200] [Batch 35/815] [D loss: -5.219034] [G loss: -26.139414]\n",
      "[Epoch 13/200] [Batch 40/815] [D loss: -5.132454] [G loss: -17.985264]\n",
      "[Epoch 13/200] [Batch 45/815] [D loss: -4.638812] [G loss: -22.107046]\n",
      "[Epoch 13/200] [Batch 50/815] [D loss: -4.653446] [G loss: -19.347738]\n",
      "[Epoch 13/200] [Batch 55/815] [D loss: -5.686178] [G loss: -15.697072]\n",
      "[Epoch 13/200] [Batch 60/815] [D loss: -5.187620] [G loss: -27.186892]\n",
      "[Epoch 13/200] [Batch 65/815] [D loss: -5.223331] [G loss: -15.433616]\n",
      "[Epoch 13/200] [Batch 70/815] [D loss: -4.983193] [G loss: -19.352364]\n",
      "[Epoch 13/200] [Batch 75/815] [D loss: -5.743215] [G loss: -12.855521]\n",
      "[Epoch 13/200] [Batch 80/815] [D loss: -5.035284] [G loss: -16.670544]\n",
      "[Epoch 13/200] [Batch 85/815] [D loss: -6.344588] [G loss: -15.658120]\n",
      "[Epoch 13/200] [Batch 90/815] [D loss: -5.323626] [G loss: -24.711983]\n",
      "[Epoch 13/200] [Batch 95/815] [D loss: -5.951737] [G loss: -14.587032]\n",
      "[Epoch 13/200] [Batch 100/815] [D loss: -5.475338] [G loss: -16.506296]\n",
      "[Epoch 13/200] [Batch 105/815] [D loss: -4.137307] [G loss: -34.022316]\n",
      "[Epoch 13/200] [Batch 110/815] [D loss: -5.410107] [G loss: -15.540168]\n",
      "[Epoch 13/200] [Batch 115/815] [D loss: -4.766371] [G loss: -25.384150]\n",
      "[Epoch 13/200] [Batch 120/815] [D loss: -6.003148] [G loss: -17.581402]\n",
      "[Epoch 13/200] [Batch 125/815] [D loss: -5.420777] [G loss: -16.015284]\n",
      "[Epoch 13/200] [Batch 130/815] [D loss: -5.110304] [G loss: -14.385288]\n",
      "[Epoch 13/200] [Batch 135/815] [D loss: -5.043508] [G loss: -17.815550]\n",
      "[Epoch 13/200] [Batch 140/815] [D loss: -4.693924] [G loss: -20.282576]\n",
      "[Epoch 13/200] [Batch 145/815] [D loss: -5.361485] [G loss: -23.883589]\n",
      "[Epoch 13/200] [Batch 150/815] [D loss: -6.090836] [G loss: -13.647301]\n",
      "[Epoch 13/200] [Batch 155/815] [D loss: -5.535254] [G loss: -25.752554]\n",
      "[Epoch 13/200] [Batch 160/815] [D loss: -6.161839] [G loss: -12.749805]\n",
      "[Epoch 13/200] [Batch 165/815] [D loss: -5.029621] [G loss: -32.159504]\n",
      "[Epoch 13/200] [Batch 170/815] [D loss: -5.841730] [G loss: -15.371432]\n",
      "[Epoch 13/200] [Batch 175/815] [D loss: -5.641454] [G loss: -12.733015]\n",
      "[Epoch 13/200] [Batch 180/815] [D loss: -5.427558] [G loss: -19.058262]\n",
      "[Epoch 13/200] [Batch 185/815] [D loss: -6.140684] [G loss: -14.722876]\n",
      "[Epoch 13/200] [Batch 190/815] [D loss: -5.394502] [G loss: -29.872782]\n",
      "[Epoch 13/200] [Batch 195/815] [D loss: -5.396237] [G loss: -17.259645]\n",
      "[Epoch 13/200] [Batch 200/815] [D loss: -5.351932] [G loss: -22.198687]\n",
      "[Epoch 13/200] [Batch 205/815] [D loss: -5.174755] [G loss: -14.129928]\n",
      "[Epoch 13/200] [Batch 210/815] [D loss: -5.356165] [G loss: -18.867605]\n",
      "[Epoch 13/200] [Batch 215/815] [D loss: -5.250281] [G loss: -23.782463]\n",
      "[Epoch 13/200] [Batch 220/815] [D loss: -5.104390] [G loss: -16.768963]\n",
      "[Epoch 13/200] [Batch 225/815] [D loss: -5.708171] [G loss: -15.778920]\n",
      "[Epoch 13/200] [Batch 230/815] [D loss: -4.962266] [G loss: -25.440197]\n",
      "[Epoch 13/200] [Batch 235/815] [D loss: -5.659912] [G loss: -11.957830]\n",
      "[Epoch 13/200] [Batch 240/815] [D loss: -5.300268] [G loss: -20.365608]\n",
      "[Epoch 13/200] [Batch 245/815] [D loss: -5.553601] [G loss: -16.302282]\n",
      "[Epoch 13/200] [Batch 250/815] [D loss: -6.210519] [G loss: -15.588260]\n",
      "[Epoch 13/200] [Batch 255/815] [D loss: -6.052406] [G loss: -17.231390]\n",
      "[Epoch 13/200] [Batch 260/815] [D loss: -6.690435] [G loss: -18.532562]\n",
      "[Epoch 13/200] [Batch 265/815] [D loss: -6.237044] [G loss: -13.894691]\n",
      "[Epoch 13/200] [Batch 270/815] [D loss: -6.185671] [G loss: -15.918960]\n",
      "[Epoch 13/200] [Batch 275/815] [D loss: -6.262208] [G loss: -13.701891]\n",
      "[Epoch 13/200] [Batch 280/815] [D loss: -5.822509] [G loss: -13.835578]\n",
      "[Epoch 13/200] [Batch 285/815] [D loss: -6.623490] [G loss: -11.000051]\n",
      "[Epoch 13/200] [Batch 290/815] [D loss: -5.510896] [G loss: -30.986839]\n",
      "[Epoch 13/200] [Batch 295/815] [D loss: -5.607920] [G loss: -13.258852]\n",
      "[Epoch 13/200] [Batch 300/815] [D loss: -5.772237] [G loss: -15.113437]\n",
      "[Epoch 13/200] [Batch 305/815] [D loss: -5.455939] [G loss: -14.749448]\n",
      "[Epoch 13/200] [Batch 310/815] [D loss: -5.484390] [G loss: -22.363258]\n",
      "[Epoch 13/200] [Batch 315/815] [D loss: -4.686980] [G loss: -32.765831]\n",
      "[Epoch 13/200] [Batch 320/815] [D loss: -6.203440] [G loss: -15.280644]\n",
      "[Epoch 13/200] [Batch 325/815] [D loss: -5.539791] [G loss: -13.206893]\n",
      "[Epoch 13/200] [Batch 330/815] [D loss: -5.381784] [G loss: -16.528732]\n",
      "[Epoch 13/200] [Batch 335/815] [D loss: -6.114499] [G loss: -15.215025]\n",
      "[Epoch 13/200] [Batch 340/815] [D loss: -5.191810] [G loss: -16.629189]\n",
      "[Epoch 13/200] [Batch 345/815] [D loss: -6.440278] [G loss: -15.815422]\n",
      "[Epoch 13/200] [Batch 350/815] [D loss: -5.753367] [G loss: -15.611506]\n",
      "[Epoch 13/200] [Batch 355/815] [D loss: -5.455394] [G loss: -19.254978]\n",
      "[Epoch 13/200] [Batch 360/815] [D loss: -5.002452] [G loss: -24.128992]\n",
      "[Epoch 13/200] [Batch 365/815] [D loss: -5.146929] [G loss: -20.016911]\n",
      "[Epoch 13/200] [Batch 370/815] [D loss: -5.818563] [G loss: -12.503840]\n",
      "[Epoch 13/200] [Batch 375/815] [D loss: -4.958354] [G loss: -21.188845]\n",
      "[Epoch 13/200] [Batch 380/815] [D loss: -4.842162] [G loss: -16.867426]\n",
      "[Epoch 13/200] [Batch 385/815] [D loss: -5.547474] [G loss: -16.267836]\n",
      "[Epoch 13/200] [Batch 390/815] [D loss: -4.802917] [G loss: -25.360991]\n",
      "[Epoch 13/200] [Batch 395/815] [D loss: -5.319671] [G loss: -17.642693]\n",
      "[Epoch 13/200] [Batch 400/815] [D loss: -4.006109] [G loss: -25.217730]\n",
      "[Epoch 13/200] [Batch 405/815] [D loss: -6.606815] [G loss: -13.840826]\n",
      "[Epoch 13/200] [Batch 410/815] [D loss: -6.083583] [G loss: -14.873245]\n",
      "[Epoch 13/200] [Batch 415/815] [D loss: -5.872715] [G loss: -16.970957]\n",
      "[Epoch 13/200] [Batch 420/815] [D loss: -4.865007] [G loss: -19.723768]\n",
      "[Epoch 13/200] [Batch 425/815] [D loss: -4.308155] [G loss: -30.873833]\n",
      "[Epoch 13/200] [Batch 430/815] [D loss: -5.989356] [G loss: -17.050117]\n",
      "[Epoch 13/200] [Batch 435/815] [D loss: -5.156273] [G loss: -17.782352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/200] [Batch 440/815] [D loss: -6.333880] [G loss: -15.583529]\n",
      "[Epoch 13/200] [Batch 445/815] [D loss: -5.115643] [G loss: -32.620106]\n",
      "[Epoch 13/200] [Batch 450/815] [D loss: -5.196916] [G loss: -15.892168]\n",
      "[Epoch 13/200] [Batch 455/815] [D loss: -5.446900] [G loss: -13.579111]\n",
      "[Epoch 13/200] [Batch 460/815] [D loss: -5.334769] [G loss: -17.083666]\n",
      "[Epoch 13/200] [Batch 465/815] [D loss: -4.383173] [G loss: -16.004683]\n",
      "[Epoch 13/200] [Batch 470/815] [D loss: -5.822904] [G loss: -19.802345]\n",
      "[Epoch 13/200] [Batch 475/815] [D loss: -4.690521] [G loss: -26.313173]\n",
      "[Epoch 13/200] [Batch 480/815] [D loss: -5.378452] [G loss: -19.129787]\n",
      "[Epoch 13/200] [Batch 485/815] [D loss: -5.861255] [G loss: -16.424019]\n",
      "[Epoch 13/200] [Batch 490/815] [D loss: -5.137660] [G loss: -21.920706]\n",
      "[Epoch 13/200] [Batch 495/815] [D loss: -6.453557] [G loss: -16.404152]\n",
      "[Epoch 13/200] [Batch 500/815] [D loss: -4.979159] [G loss: -13.030127]\n",
      "[Epoch 13/200] [Batch 505/815] [D loss: -5.629615] [G loss: -15.871985]\n",
      "[Epoch 13/200] [Batch 510/815] [D loss: -5.263482] [G loss: -24.400316]\n",
      "[Epoch 13/200] [Batch 515/815] [D loss: -4.803117] [G loss: -26.336626]\n",
      "[Epoch 13/200] [Batch 520/815] [D loss: -6.282156] [G loss: -18.224699]\n",
      "[Epoch 13/200] [Batch 525/815] [D loss: -5.726030] [G loss: -12.857000]\n",
      "[Epoch 13/200] [Batch 530/815] [D loss: -5.501024] [G loss: -24.462416]\n",
      "[Epoch 13/200] [Batch 535/815] [D loss: -6.163982] [G loss: -17.760319]\n",
      "[Epoch 13/200] [Batch 540/815] [D loss: -5.642025] [G loss: -14.782506]\n",
      "[Epoch 13/200] [Batch 545/815] [D loss: -5.734423] [G loss: -14.928430]\n",
      "[Epoch 13/200] [Batch 550/815] [D loss: -4.868530] [G loss: -24.770657]\n",
      "[Epoch 13/200] [Batch 555/815] [D loss: -5.540536] [G loss: -15.343861]\n",
      "[Epoch 13/200] [Batch 560/815] [D loss: -4.844433] [G loss: -23.858810]\n",
      "[Epoch 13/200] [Batch 565/815] [D loss: -4.802175] [G loss: -20.856781]\n",
      "[Epoch 13/200] [Batch 570/815] [D loss: -6.276478] [G loss: -13.709940]\n",
      "[Epoch 13/200] [Batch 575/815] [D loss: -5.236214] [G loss: -19.294140]\n",
      "[Epoch 13/200] [Batch 580/815] [D loss: -4.899349] [G loss: -17.146833]\n",
      "[Epoch 13/200] [Batch 585/815] [D loss: -6.434381] [G loss: -16.027473]\n",
      "[Epoch 13/200] [Batch 590/815] [D loss: -4.482648] [G loss: -24.744081]\n",
      "[Epoch 13/200] [Batch 595/815] [D loss: -4.379471] [G loss: -18.553112]\n",
      "[Epoch 13/200] [Batch 600/815] [D loss: -6.333024] [G loss: -11.753291]\n",
      "[Epoch 13/200] [Batch 605/815] [D loss: -4.929132] [G loss: -25.172131]\n",
      "[Epoch 13/200] [Batch 610/815] [D loss: -5.945108] [G loss: -26.036160]\n",
      "[Epoch 13/200] [Batch 615/815] [D loss: -5.353657] [G loss: -19.574686]\n",
      "[Epoch 13/200] [Batch 620/815] [D loss: -4.862803] [G loss: -19.909546]\n",
      "[Epoch 13/200] [Batch 625/815] [D loss: -6.327159] [G loss: -17.623402]\n",
      "[Epoch 13/200] [Batch 630/815] [D loss: -5.197522] [G loss: -14.442807]\n",
      "[Epoch 13/200] [Batch 635/815] [D loss: -5.629513] [G loss: -16.135258]\n",
      "[Epoch 13/200] [Batch 640/815] [D loss: -5.511100] [G loss: -14.816465]\n",
      "[Epoch 13/200] [Batch 645/815] [D loss: -5.746137] [G loss: -29.799900]\n",
      "[Epoch 13/200] [Batch 650/815] [D loss: -6.580058] [G loss: -18.496267]\n",
      "[Epoch 13/200] [Batch 655/815] [D loss: -6.173371] [G loss: -16.007212]\n",
      "[Epoch 13/200] [Batch 660/815] [D loss: -4.850039] [G loss: -26.807486]\n",
      "[Epoch 13/200] [Batch 665/815] [D loss: -5.396824] [G loss: -14.696945]\n",
      "[Epoch 13/200] [Batch 670/815] [D loss: -6.094415] [G loss: -18.481783]\n",
      "[Epoch 13/200] [Batch 675/815] [D loss: -5.889590] [G loss: -15.841729]\n",
      "[Epoch 13/200] [Batch 680/815] [D loss: -6.474025] [G loss: -16.979601]\n",
      "[Epoch 13/200] [Batch 685/815] [D loss: -4.775561] [G loss: -29.086395]\n",
      "[Epoch 13/200] [Batch 690/815] [D loss: -5.012151] [G loss: -17.636438]\n",
      "[Epoch 13/200] [Batch 695/815] [D loss: -5.030967] [G loss: -35.180576]\n",
      "[Epoch 13/200] [Batch 700/815] [D loss: -5.142726] [G loss: -17.173925]\n",
      "[Epoch 13/200] [Batch 705/815] [D loss: -5.312029] [G loss: -18.006969]\n",
      "[Epoch 13/200] [Batch 710/815] [D loss: -4.472945] [G loss: -32.509800]\n",
      "[Epoch 13/200] [Batch 715/815] [D loss: -7.543481] [G loss: -10.249191]\n",
      "[Epoch 13/200] [Batch 720/815] [D loss: -5.314017] [G loss: -19.000900]\n",
      "[Epoch 13/200] [Batch 725/815] [D loss: -5.036571] [G loss: -21.260546]\n",
      "[Epoch 13/200] [Batch 730/815] [D loss: -5.557787] [G loss: -15.993537]\n",
      "[Epoch 13/200] [Batch 735/815] [D loss: -5.351082] [G loss: -21.382555]\n",
      "[Epoch 13/200] [Batch 740/815] [D loss: -5.687989] [G loss: -23.674755]\n",
      "[Epoch 13/200] [Batch 745/815] [D loss: -4.795285] [G loss: -23.943010]\n",
      "[Epoch 13/200] [Batch 750/815] [D loss: -6.692259] [G loss: -14.544726]\n",
      "[Epoch 13/200] [Batch 755/815] [D loss: -4.614024] [G loss: -27.923925]\n",
      "[Epoch 13/200] [Batch 760/815] [D loss: -5.719381] [G loss: -15.236162]\n",
      "[Epoch 13/200] [Batch 765/815] [D loss: -4.809052] [G loss: -32.227642]\n",
      "[Epoch 13/200] [Batch 770/815] [D loss: -5.319055] [G loss: -22.345510]\n",
      "[Epoch 13/200] [Batch 775/815] [D loss: -5.102347] [G loss: -12.063797]\n",
      "[Epoch 13/200] [Batch 780/815] [D loss: -5.268479] [G loss: -18.496210]\n",
      "[Epoch 13/200] [Batch 785/815] [D loss: -5.549359] [G loss: -20.406319]\n",
      "[Epoch 13/200] [Batch 790/815] [D loss: -5.764595] [G loss: -16.176191]\n",
      "[Epoch 13/200] [Batch 795/815] [D loss: -4.706924] [G loss: -19.488588]\n",
      "[Epoch 13/200] [Batch 800/815] [D loss: -5.935577] [G loss: -15.063544]\n",
      "[Epoch 13/200] [Batch 805/815] [D loss: -5.236934] [G loss: -24.984842]\n",
      "[Epoch 13/200] [Batch 810/815] [D loss: -5.977337] [G loss: -16.921469]\n",
      "[Epoch 14/200] [Batch 0/815] [D loss: -3.460603] [G loss: -32.305336]\n",
      "[Epoch 14/200] [Batch 5/815] [D loss: -5.008996] [G loss: -19.894199]\n",
      "[Epoch 14/200] [Batch 10/815] [D loss: -4.889541] [G loss: -18.368198]\n",
      "[Epoch 14/200] [Batch 15/815] [D loss: -5.574983] [G loss: -26.990225]\n",
      "[Epoch 14/200] [Batch 20/815] [D loss: -6.449939] [G loss: -24.409618]\n",
      "[Epoch 14/200] [Batch 25/815] [D loss: -4.937029] [G loss: -21.157690]\n",
      "[Epoch 14/200] [Batch 30/815] [D loss: -4.906925] [G loss: -19.708521]\n",
      "[Epoch 14/200] [Batch 35/815] [D loss: -5.185609] [G loss: -17.812407]\n",
      "[Epoch 14/200] [Batch 40/815] [D loss: -4.322730] [G loss: -25.861650]\n",
      "[Epoch 14/200] [Batch 45/815] [D loss: -6.371381] [G loss: -17.024364]\n",
      "[Epoch 14/200] [Batch 50/815] [D loss: -5.720187] [G loss: -11.406080]\n",
      "[Epoch 14/200] [Batch 55/815] [D loss: -5.275262] [G loss: -18.518713]\n",
      "[Epoch 14/200] [Batch 60/815] [D loss: -5.349150] [G loss: -22.472574]\n",
      "[Epoch 14/200] [Batch 65/815] [D loss: -5.197007] [G loss: -14.545285]\n",
      "[Epoch 14/200] [Batch 70/815] [D loss: -4.890329] [G loss: -17.446058]\n",
      "[Epoch 14/200] [Batch 75/815] [D loss: -5.409703] [G loss: -21.697651]\n",
      "[Epoch 14/200] [Batch 80/815] [D loss: -5.356197] [G loss: -18.080801]\n",
      "[Epoch 14/200] [Batch 85/815] [D loss: -4.910410] [G loss: -24.544218]\n",
      "[Epoch 14/200] [Batch 90/815] [D loss: -6.336966] [G loss: -10.955390]\n",
      "[Epoch 14/200] [Batch 95/815] [D loss: -4.944953] [G loss: -19.449755]\n",
      "[Epoch 14/200] [Batch 100/815] [D loss: -5.514765] [G loss: -14.604869]\n",
      "[Epoch 14/200] [Batch 105/815] [D loss: -5.210131] [G loss: -25.316759]\n",
      "[Epoch 14/200] [Batch 110/815] [D loss: -6.224813] [G loss: -20.239670]\n",
      "[Epoch 14/200] [Batch 115/815] [D loss: -5.250100] [G loss: -16.558300]\n",
      "[Epoch 14/200] [Batch 120/815] [D loss: -5.512090] [G loss: -19.017086]\n",
      "[Epoch 14/200] [Batch 125/815] [D loss: -4.613583] [G loss: -22.645325]\n",
      "[Epoch 14/200] [Batch 130/815] [D loss: -5.145070] [G loss: -20.176193]\n",
      "[Epoch 14/200] [Batch 135/815] [D loss: -4.730823] [G loss: -14.383176]\n",
      "[Epoch 14/200] [Batch 140/815] [D loss: -4.223790] [G loss: -23.557302]\n",
      "[Epoch 14/200] [Batch 145/815] [D loss: -5.654858] [G loss: -16.222694]\n",
      "[Epoch 14/200] [Batch 150/815] [D loss: -4.411638] [G loss: -22.335558]\n",
      "[Epoch 14/200] [Batch 155/815] [D loss: -4.259726] [G loss: -27.677874]\n",
      "[Epoch 14/200] [Batch 160/815] [D loss: -5.248467] [G loss: -15.078322]\n",
      "[Epoch 14/200] [Batch 165/815] [D loss: -5.185842] [G loss: -20.233776]\n",
      "[Epoch 14/200] [Batch 170/815] [D loss: -7.486039] [G loss: -16.788126]\n",
      "[Epoch 14/200] [Batch 175/815] [D loss: -5.767969] [G loss: -15.305625]\n",
      "[Epoch 14/200] [Batch 180/815] [D loss: -5.580938] [G loss: -16.643595]\n",
      "[Epoch 14/200] [Batch 185/815] [D loss: -4.680571] [G loss: -26.363903]\n",
      "[Epoch 14/200] [Batch 190/815] [D loss: -5.418230] [G loss: -13.062898]\n",
      "[Epoch 14/200] [Batch 195/815] [D loss: -4.927806] [G loss: -19.708067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 200/815] [D loss: -5.147439] [G loss: -14.821623]\n",
      "[Epoch 14/200] [Batch 205/815] [D loss: -5.196122] [G loss: -21.476154]\n",
      "[Epoch 14/200] [Batch 210/815] [D loss: -5.055547] [G loss: -17.029057]\n",
      "[Epoch 14/200] [Batch 215/815] [D loss: -5.291572] [G loss: -14.336230]\n",
      "[Epoch 14/200] [Batch 220/815] [D loss: -6.777834] [G loss: -11.901766]\n",
      "[Epoch 14/200] [Batch 225/815] [D loss: -5.778614] [G loss: -21.707088]\n",
      "[Epoch 14/200] [Batch 230/815] [D loss: -5.275815] [G loss: -20.017534]\n",
      "[Epoch 14/200] [Batch 235/815] [D loss: -6.364357] [G loss: -13.011963]\n",
      "[Epoch 14/200] [Batch 240/815] [D loss: -5.182774] [G loss: -15.996301]\n",
      "[Epoch 14/200] [Batch 245/815] [D loss: -6.062467] [G loss: -13.210519]\n",
      "[Epoch 14/200] [Batch 250/815] [D loss: -6.450295] [G loss: -13.920032]\n",
      "[Epoch 14/200] [Batch 255/815] [D loss: -6.686679] [G loss: -14.264680]\n",
      "[Epoch 14/200] [Batch 260/815] [D loss: -6.706722] [G loss: -13.050633]\n",
      "[Epoch 14/200] [Batch 265/815] [D loss: -6.094051] [G loss: -22.096558]\n",
      "[Epoch 14/200] [Batch 270/815] [D loss: -5.966492] [G loss: -21.717299]\n",
      "[Epoch 14/200] [Batch 275/815] [D loss: -5.427773] [G loss: -17.231153]\n",
      "[Epoch 14/200] [Batch 280/815] [D loss: -6.516611] [G loss: -15.055218]\n",
      "[Epoch 14/200] [Batch 285/815] [D loss: -5.080237] [G loss: -22.372871]\n",
      "[Epoch 14/200] [Batch 290/815] [D loss: -5.154980] [G loss: -14.841383]\n",
      "[Epoch 14/200] [Batch 295/815] [D loss: -5.638991] [G loss: -17.019053]\n",
      "[Epoch 14/200] [Batch 300/815] [D loss: -5.578482] [G loss: -11.619061]\n",
      "[Epoch 14/200] [Batch 305/815] [D loss: -5.150603] [G loss: -13.949080]\n",
      "[Epoch 14/200] [Batch 310/815] [D loss: -6.528995] [G loss: -14.886224]\n",
      "[Epoch 14/200] [Batch 315/815] [D loss: -5.550551] [G loss: -13.537842]\n",
      "[Epoch 14/200] [Batch 320/815] [D loss: -4.870085] [G loss: -27.527555]\n",
      "[Epoch 14/200] [Batch 325/815] [D loss: -5.541578] [G loss: -20.577787]\n",
      "[Epoch 14/200] [Batch 330/815] [D loss: -5.663687] [G loss: -16.224600]\n",
      "[Epoch 14/200] [Batch 335/815] [D loss: -6.087104] [G loss: -14.240483]\n",
      "[Epoch 14/200] [Batch 340/815] [D loss: -6.195664] [G loss: -26.709894]\n",
      "[Epoch 14/200] [Batch 345/815] [D loss: -5.708013] [G loss: -14.044065]\n",
      "[Epoch 14/200] [Batch 350/815] [D loss: -5.478449] [G loss: -14.647372]\n",
      "[Epoch 14/200] [Batch 355/815] [D loss: -5.169884] [G loss: -22.288664]\n",
      "[Epoch 14/200] [Batch 360/815] [D loss: -5.464297] [G loss: -16.951181]\n",
      "[Epoch 14/200] [Batch 365/815] [D loss: -5.830119] [G loss: -15.739826]\n",
      "[Epoch 14/200] [Batch 370/815] [D loss: -5.064600] [G loss: -18.221544]\n",
      "[Epoch 14/200] [Batch 375/815] [D loss: -5.613589] [G loss: -21.791557]\n",
      "[Epoch 14/200] [Batch 380/815] [D loss: -5.382713] [G loss: -13.024451]\n",
      "[Epoch 14/200] [Batch 385/815] [D loss: -5.427027] [G loss: -14.505602]\n",
      "[Epoch 14/200] [Batch 390/815] [D loss: -6.572451] [G loss: -13.984384]\n",
      "[Epoch 14/200] [Batch 395/815] [D loss: -4.570363] [G loss: -19.119968]\n",
      "[Epoch 14/200] [Batch 400/815] [D loss: -4.665223] [G loss: -25.713102]\n",
      "[Epoch 14/200] [Batch 405/815] [D loss: -5.143420] [G loss: -15.269719]\n",
      "[Epoch 14/200] [Batch 410/815] [D loss: -4.757967] [G loss: -19.978615]\n",
      "[Epoch 14/200] [Batch 415/815] [D loss: -5.665866] [G loss: -17.600964]\n",
      "[Epoch 14/200] [Batch 420/815] [D loss: -4.955695] [G loss: -26.398424]\n",
      "[Epoch 14/200] [Batch 425/815] [D loss: -5.541475] [G loss: -15.007806]\n",
      "[Epoch 14/200] [Batch 430/815] [D loss: -4.280607] [G loss: -26.203310]\n",
      "[Epoch 14/200] [Batch 435/815] [D loss: -6.077842] [G loss: -13.424242]\n",
      "[Epoch 14/200] [Batch 440/815] [D loss: -5.861143] [G loss: -14.385024]\n",
      "[Epoch 14/200] [Batch 445/815] [D loss: -4.864698] [G loss: -18.000692]\n",
      "[Epoch 14/200] [Batch 450/815] [D loss: -6.400324] [G loss: -14.594153]\n",
      "[Epoch 14/200] [Batch 455/815] [D loss: -5.492224] [G loss: -22.042761]\n",
      "[Epoch 14/200] [Batch 460/815] [D loss: -6.056444] [G loss: -16.771084]\n",
      "[Epoch 14/200] [Batch 465/815] [D loss: -5.911742] [G loss: -16.938129]\n",
      "[Epoch 14/200] [Batch 470/815] [D loss: -5.640657] [G loss: -22.053459]\n",
      "[Epoch 14/200] [Batch 475/815] [D loss: -5.417608] [G loss: -13.848285]\n",
      "[Epoch 14/200] [Batch 480/815] [D loss: -5.294392] [G loss: -12.126192]\n",
      "[Epoch 14/200] [Batch 485/815] [D loss: -5.469885] [G loss: -21.991657]\n",
      "[Epoch 14/200] [Batch 490/815] [D loss: -6.248934] [G loss: -14.686115]\n",
      "[Epoch 14/200] [Batch 495/815] [D loss: -5.574095] [G loss: -14.888531]\n",
      "[Epoch 14/200] [Batch 500/815] [D loss: -5.015718] [G loss: -19.726587]\n",
      "[Epoch 14/200] [Batch 505/815] [D loss: -5.322390] [G loss: -12.232306]\n",
      "[Epoch 14/200] [Batch 510/815] [D loss: -6.817781] [G loss: -11.012562]\n",
      "[Epoch 14/200] [Batch 515/815] [D loss: -4.739531] [G loss: -23.722439]\n",
      "[Epoch 14/200] [Batch 520/815] [D loss: -5.233821] [G loss: -27.845678]\n",
      "[Epoch 14/200] [Batch 525/815] [D loss: -5.006860] [G loss: -16.540457]\n",
      "[Epoch 14/200] [Batch 530/815] [D loss: -3.691522] [G loss: -30.488327]\n",
      "[Epoch 14/200] [Batch 535/815] [D loss: -5.915459] [G loss: -13.704015]\n",
      "[Epoch 14/200] [Batch 540/815] [D loss: -5.965884] [G loss: -16.390881]\n",
      "[Epoch 14/200] [Batch 545/815] [D loss: -5.850389] [G loss: -16.667103]\n",
      "[Epoch 14/200] [Batch 550/815] [D loss: -5.187646] [G loss: -23.927736]\n",
      "[Epoch 14/200] [Batch 555/815] [D loss: -5.077332] [G loss: -12.537449]\n",
      "[Epoch 14/200] [Batch 560/815] [D loss: -5.201143] [G loss: -15.481158]\n",
      "[Epoch 14/200] [Batch 565/815] [D loss: -4.262065] [G loss: -16.812788]\n",
      "[Epoch 14/200] [Batch 570/815] [D loss: -5.634217] [G loss: -13.783274]\n",
      "[Epoch 14/200] [Batch 575/815] [D loss: -5.863069] [G loss: -23.846090]\n",
      "[Epoch 14/200] [Batch 580/815] [D loss: -6.406317] [G loss: -15.790636]\n",
      "[Epoch 14/200] [Batch 585/815] [D loss: -4.645282] [G loss: -25.296318]\n",
      "[Epoch 14/200] [Batch 590/815] [D loss: -6.363427] [G loss: -11.734948]\n",
      "[Epoch 14/200] [Batch 595/815] [D loss: -4.402790] [G loss: -20.586590]\n",
      "[Epoch 14/200] [Batch 600/815] [D loss: -5.416727] [G loss: -20.850075]\n",
      "[Epoch 14/200] [Batch 605/815] [D loss: -5.724093] [G loss: -23.307413]\n",
      "[Epoch 14/200] [Batch 610/815] [D loss: -6.096011] [G loss: -15.313016]\n",
      "[Epoch 14/200] [Batch 615/815] [D loss: -6.378097] [G loss: -14.475398]\n",
      "[Epoch 14/200] [Batch 620/815] [D loss: -6.395723] [G loss: -19.433104]\n",
      "[Epoch 14/200] [Batch 625/815] [D loss: -5.938396] [G loss: -15.128990]\n",
      "[Epoch 14/200] [Batch 630/815] [D loss: -4.794332] [G loss: -31.670622]\n",
      "[Epoch 14/200] [Batch 635/815] [D loss: -5.071129] [G loss: -20.197941]\n",
      "[Epoch 14/200] [Batch 640/815] [D loss: -5.621273] [G loss: -17.059441]\n",
      "[Epoch 14/200] [Batch 645/815] [D loss: -6.273674] [G loss: -13.541277]\n",
      "[Epoch 14/200] [Batch 650/815] [D loss: -4.920490] [G loss: -27.840599]\n",
      "[Epoch 14/200] [Batch 655/815] [D loss: -5.269402] [G loss: -19.546068]\n",
      "[Epoch 14/200] [Batch 660/815] [D loss: -5.067102] [G loss: -14.258968]\n",
      "[Epoch 14/200] [Batch 665/815] [D loss: -5.556344] [G loss: -10.806302]\n",
      "[Epoch 14/200] [Batch 670/815] [D loss: -4.123076] [G loss: -29.842123]\n",
      "[Epoch 14/200] [Batch 675/815] [D loss: -4.997639] [G loss: -16.564081]\n",
      "[Epoch 14/200] [Batch 680/815] [D loss: -5.280975] [G loss: -18.542688]\n",
      "[Epoch 14/200] [Batch 685/815] [D loss: -5.453629] [G loss: -17.521761]\n",
      "[Epoch 14/200] [Batch 690/815] [D loss: -5.265092] [G loss: -16.663822]\n",
      "[Epoch 14/200] [Batch 695/815] [D loss: -6.128001] [G loss: -13.478541]\n",
      "[Epoch 14/200] [Batch 700/815] [D loss: -5.715552] [G loss: -9.986406]\n",
      "[Epoch 14/200] [Batch 705/815] [D loss: -4.491769] [G loss: -34.907539]\n",
      "[Epoch 14/200] [Batch 710/815] [D loss: -5.181082] [G loss: -20.150455]\n",
      "[Epoch 14/200] [Batch 715/815] [D loss: -5.672894] [G loss: -13.952524]\n",
      "[Epoch 14/200] [Batch 720/815] [D loss: -5.376759] [G loss: -21.988634]\n",
      "[Epoch 14/200] [Batch 725/815] [D loss: -5.741310] [G loss: -19.616201]\n",
      "[Epoch 14/200] [Batch 730/815] [D loss: -4.699947] [G loss: -14.934643]\n",
      "[Epoch 14/200] [Batch 735/815] [D loss: -5.336176] [G loss: -13.756102]\n",
      "[Epoch 14/200] [Batch 740/815] [D loss: -5.172666] [G loss: -23.597151]\n",
      "[Epoch 14/200] [Batch 745/815] [D loss: -6.033044] [G loss: -12.696090]\n",
      "[Epoch 14/200] [Batch 750/815] [D loss: -5.546990] [G loss: -18.213835]\n",
      "[Epoch 14/200] [Batch 755/815] [D loss: -4.341024] [G loss: -26.631876]\n",
      "[Epoch 14/200] [Batch 760/815] [D loss: -5.686401] [G loss: -14.416245]\n",
      "[Epoch 14/200] [Batch 765/815] [D loss: -5.794230] [G loss: -19.844595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/200] [Batch 770/815] [D loss: -6.137253] [G loss: -17.163326]\n",
      "[Epoch 14/200] [Batch 775/815] [D loss: -5.533875] [G loss: -13.959763]\n",
      "[Epoch 14/200] [Batch 780/815] [D loss: -5.391912] [G loss: -14.427142]\n",
      "[Epoch 14/200] [Batch 785/815] [D loss: -6.333045] [G loss: -15.779631]\n",
      "[Epoch 14/200] [Batch 790/815] [D loss: -4.884900] [G loss: -21.081354]\n",
      "[Epoch 14/200] [Batch 795/815] [D loss: -6.129394] [G loss: -13.559140]\n",
      "[Epoch 14/200] [Batch 800/815] [D loss: -5.372067] [G loss: -26.619646]\n",
      "[Epoch 14/200] [Batch 805/815] [D loss: -6.124346] [G loss: -15.719943]\n",
      "[Epoch 14/200] [Batch 810/815] [D loss: -5.601040] [G loss: -19.709000]\n",
      "[Epoch 15/200] [Batch 0/815] [D loss: -5.643607] [G loss: -17.768822]\n",
      "[Epoch 15/200] [Batch 5/815] [D loss: -5.192897] [G loss: -15.850562]\n",
      "[Epoch 15/200] [Batch 10/815] [D loss: -5.889826] [G loss: -15.171195]\n",
      "[Epoch 15/200] [Batch 15/815] [D loss: -5.360828] [G loss: -17.965130]\n",
      "[Epoch 15/200] [Batch 20/815] [D loss: -4.485939] [G loss: -24.849833]\n",
      "[Epoch 15/200] [Batch 25/815] [D loss: -3.531303] [G loss: -25.161318]\n",
      "[Epoch 15/200] [Batch 30/815] [D loss: -6.119998] [G loss: -10.537590]\n",
      "[Epoch 15/200] [Batch 35/815] [D loss: -4.993643] [G loss: -26.080942]\n",
      "[Epoch 15/200] [Batch 40/815] [D loss: -5.533215] [G loss: -13.615361]\n",
      "[Epoch 15/200] [Batch 45/815] [D loss: -5.289859] [G loss: -12.376095]\n",
      "[Epoch 15/200] [Batch 50/815] [D loss: -7.057511] [G loss: -13.347230]\n",
      "[Epoch 15/200] [Batch 55/815] [D loss: -6.695460] [G loss: -15.003214]\n",
      "[Epoch 15/200] [Batch 60/815] [D loss: -5.159315] [G loss: -12.917952]\n",
      "[Epoch 15/200] [Batch 65/815] [D loss: -5.560489] [G loss: -23.262802]\n",
      "[Epoch 15/200] [Batch 70/815] [D loss: -4.940671] [G loss: -28.936363]\n",
      "[Epoch 15/200] [Batch 75/815] [D loss: -5.833179] [G loss: -16.993832]\n",
      "[Epoch 15/200] [Batch 80/815] [D loss: -5.413953] [G loss: -16.139709]\n",
      "[Epoch 15/200] [Batch 85/815] [D loss: -5.813577] [G loss: -12.632962]\n",
      "[Epoch 15/200] [Batch 90/815] [D loss: -5.899312] [G loss: -16.930809]\n",
      "[Epoch 15/200] [Batch 95/815] [D loss: -4.592222] [G loss: -14.079687]\n",
      "[Epoch 15/200] [Batch 100/815] [D loss: -6.563833] [G loss: -15.862293]\n",
      "[Epoch 15/200] [Batch 105/815] [D loss: -4.817853] [G loss: -18.881910]\n",
      "[Epoch 15/200] [Batch 110/815] [D loss: -5.645524] [G loss: -17.019108]\n",
      "[Epoch 15/200] [Batch 115/815] [D loss: -5.473475] [G loss: -20.379408]\n",
      "[Epoch 15/200] [Batch 120/815] [D loss: -5.422624] [G loss: -16.569038]\n",
      "[Epoch 15/200] [Batch 125/815] [D loss: -4.803453] [G loss: -25.678911]\n",
      "[Epoch 15/200] [Batch 130/815] [D loss: -5.125045] [G loss: -20.523403]\n",
      "[Epoch 15/200] [Batch 135/815] [D loss: -4.549665] [G loss: -25.798597]\n",
      "[Epoch 15/200] [Batch 140/815] [D loss: -5.329539] [G loss: -11.512875]\n",
      "[Epoch 15/200] [Batch 145/815] [D loss: -5.870124] [G loss: -13.750747]\n",
      "[Epoch 15/200] [Batch 150/815] [D loss: -5.231588] [G loss: -25.490377]\n",
      "[Epoch 15/200] [Batch 155/815] [D loss: -5.606555] [G loss: -18.802017]\n",
      "[Epoch 15/200] [Batch 160/815] [D loss: -5.627966] [G loss: -16.786201]\n",
      "[Epoch 15/200] [Batch 165/815] [D loss: -5.793811] [G loss: -22.082561]\n",
      "[Epoch 15/200] [Batch 170/815] [D loss: -4.725499] [G loss: -17.465109]\n",
      "[Epoch 15/200] [Batch 175/815] [D loss: -6.916014] [G loss: -12.465558]\n",
      "[Epoch 15/200] [Batch 180/815] [D loss: -5.310911] [G loss: -20.120979]\n",
      "[Epoch 15/200] [Batch 185/815] [D loss: -4.804775] [G loss: -24.567497]\n",
      "[Epoch 15/200] [Batch 190/815] [D loss: -5.358405] [G loss: -14.510676]\n",
      "[Epoch 15/200] [Batch 195/815] [D loss: -7.043649] [G loss: -13.598648]\n",
      "[Epoch 15/200] [Batch 200/815] [D loss: -5.385250] [G loss: -20.415863]\n",
      "[Epoch 15/200] [Batch 205/815] [D loss: -5.225272] [G loss: -18.724705]\n",
      "[Epoch 15/200] [Batch 210/815] [D loss: -5.931050] [G loss: -11.996170]\n",
      "[Epoch 15/200] [Batch 215/815] [D loss: -5.365443] [G loss: -15.272878]\n",
      "[Epoch 15/200] [Batch 220/815] [D loss: -5.489393] [G loss: -22.748417]\n",
      "[Epoch 15/200] [Batch 225/815] [D loss: -5.575720] [G loss: -27.988539]\n",
      "[Epoch 15/200] [Batch 230/815] [D loss: -6.108386] [G loss: -12.430426]\n",
      "[Epoch 15/200] [Batch 235/815] [D loss: -5.126272] [G loss: -18.668182]\n",
      "[Epoch 15/200] [Batch 240/815] [D loss: -5.790569] [G loss: -14.874134]\n",
      "[Epoch 15/200] [Batch 245/815] [D loss: -5.301092] [G loss: -16.948128]\n",
      "[Epoch 15/200] [Batch 250/815] [D loss: -5.464184] [G loss: -23.556274]\n",
      "[Epoch 15/200] [Batch 255/815] [D loss: -5.348573] [G loss: -14.052597]\n",
      "[Epoch 15/200] [Batch 260/815] [D loss: -5.094108] [G loss: -22.058973]\n",
      "[Epoch 15/200] [Batch 265/815] [D loss: -6.231593] [G loss: -13.422441]\n",
      "[Epoch 15/200] [Batch 270/815] [D loss: -5.918760] [G loss: -17.351692]\n",
      "[Epoch 15/200] [Batch 275/815] [D loss: -5.816730] [G loss: -16.796396]\n",
      "[Epoch 15/200] [Batch 280/815] [D loss: -5.536304] [G loss: -22.069162]\n",
      "[Epoch 15/200] [Batch 285/815] [D loss: -5.081359] [G loss: -19.138536]\n",
      "[Epoch 15/200] [Batch 290/815] [D loss: -5.543283] [G loss: -20.366371]\n",
      "[Epoch 15/200] [Batch 295/815] [D loss: -5.323282] [G loss: -16.816996]\n",
      "[Epoch 15/200] [Batch 300/815] [D loss: -5.348592] [G loss: -21.968309]\n",
      "[Epoch 15/200] [Batch 305/815] [D loss: -5.879233] [G loss: -18.489904]\n",
      "[Epoch 15/200] [Batch 310/815] [D loss: -6.170072] [G loss: -15.155511]\n",
      "[Epoch 15/200] [Batch 315/815] [D loss: -5.029939] [G loss: -21.064606]\n",
      "[Epoch 15/200] [Batch 320/815] [D loss: -5.971496] [G loss: -13.124312]\n",
      "[Epoch 15/200] [Batch 325/815] [D loss: -4.977935] [G loss: -24.509668]\n",
      "[Epoch 15/200] [Batch 330/815] [D loss: -5.392418] [G loss: -21.162556]\n",
      "[Epoch 15/200] [Batch 335/815] [D loss: -7.165944] [G loss: -11.133774]\n",
      "[Epoch 15/200] [Batch 340/815] [D loss: -5.774087] [G loss: -15.224520]\n",
      "[Epoch 15/200] [Batch 345/815] [D loss: -6.241804] [G loss: -15.295393]\n",
      "[Epoch 15/200] [Batch 350/815] [D loss: -5.953033] [G loss: -15.427068]\n",
      "[Epoch 15/200] [Batch 355/815] [D loss: -5.115576] [G loss: -30.931620]\n",
      "[Epoch 15/200] [Batch 360/815] [D loss: -5.285681] [G loss: -13.289907]\n",
      "[Epoch 15/200] [Batch 365/815] [D loss: -4.200766] [G loss: -22.924212]\n",
      "[Epoch 15/200] [Batch 370/815] [D loss: -5.028200] [G loss: -15.786094]\n",
      "[Epoch 15/200] [Batch 375/815] [D loss: -5.143479] [G loss: -13.947550]\n",
      "[Epoch 15/200] [Batch 380/815] [D loss: -6.074303] [G loss: -16.293810]\n",
      "[Epoch 15/200] [Batch 385/815] [D loss: -5.280809] [G loss: -15.709388]\n",
      "[Epoch 15/200] [Batch 390/815] [D loss: -5.303571] [G loss: -16.037266]\n",
      "[Epoch 15/200] [Batch 395/815] [D loss: -5.803602] [G loss: -15.911589]\n",
      "[Epoch 15/200] [Batch 400/815] [D loss: -5.377507] [G loss: -21.270117]\n",
      "[Epoch 15/200] [Batch 405/815] [D loss: -5.243865] [G loss: -15.504783]\n",
      "[Epoch 15/200] [Batch 410/815] [D loss: -6.015402] [G loss: -15.032581]\n",
      "[Epoch 15/200] [Batch 415/815] [D loss: -6.812657] [G loss: -19.482975]\n",
      "[Epoch 15/200] [Batch 420/815] [D loss: -6.380897] [G loss: -14.037218]\n",
      "[Epoch 15/200] [Batch 425/815] [D loss: -5.801435] [G loss: -33.162247]\n",
      "[Epoch 15/200] [Batch 430/815] [D loss: -4.738033] [G loss: -15.234787]\n",
      "[Epoch 15/200] [Batch 435/815] [D loss: -5.167402] [G loss: -28.580069]\n",
      "[Epoch 15/200] [Batch 440/815] [D loss: -5.212690] [G loss: -18.667488]\n",
      "[Epoch 15/200] [Batch 445/815] [D loss: -5.511667] [G loss: -12.111627]\n",
      "[Epoch 15/200] [Batch 450/815] [D loss: -4.826562] [G loss: -22.041573]\n",
      "[Epoch 15/200] [Batch 455/815] [D loss: -5.445769] [G loss: -13.214478]\n",
      "[Epoch 15/200] [Batch 460/815] [D loss: -5.162069] [G loss: -25.088173]\n",
      "[Epoch 15/200] [Batch 465/815] [D loss: -5.613186] [G loss: -12.861609]\n",
      "[Epoch 15/200] [Batch 470/815] [D loss: -5.890666] [G loss: -18.555317]\n",
      "[Epoch 15/200] [Batch 475/815] [D loss: -6.007447] [G loss: -23.529009]\n",
      "[Epoch 15/200] [Batch 480/815] [D loss: -6.453613] [G loss: -14.960659]\n",
      "[Epoch 15/200] [Batch 485/815] [D loss: -6.384711] [G loss: -14.401329]\n",
      "[Epoch 15/200] [Batch 490/815] [D loss: -5.197208] [G loss: -20.713858]\n",
      "[Epoch 15/200] [Batch 495/815] [D loss: -5.081697] [G loss: -20.033173]\n",
      "[Epoch 15/200] [Batch 500/815] [D loss: -4.980803] [G loss: -22.767460]\n",
      "[Epoch 15/200] [Batch 505/815] [D loss: -6.026818] [G loss: -13.850859]\n",
      "[Epoch 15/200] [Batch 510/815] [D loss: -5.925006] [G loss: -16.976229]\n",
      "[Epoch 15/200] [Batch 515/815] [D loss: -5.265007] [G loss: -19.955877]\n",
      "[Epoch 15/200] [Batch 520/815] [D loss: -6.167015] [G loss: -22.857540]\n",
      "[Epoch 15/200] [Batch 525/815] [D loss: -5.340569] [G loss: -17.389385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/200] [Batch 530/815] [D loss: -5.514998] [G loss: -13.284404]\n",
      "[Epoch 15/200] [Batch 535/815] [D loss: -5.333850] [G loss: -15.971549]\n",
      "[Epoch 15/200] [Batch 540/815] [D loss: -6.278171] [G loss: -17.213247]\n",
      "[Epoch 15/200] [Batch 545/815] [D loss: -4.752590] [G loss: -29.852257]\n",
      "[Epoch 15/200] [Batch 550/815] [D loss: -4.420588] [G loss: -26.159119]\n",
      "[Epoch 15/200] [Batch 555/815] [D loss: -5.189960] [G loss: -22.168474]\n",
      "[Epoch 15/200] [Batch 560/815] [D loss: -5.182109] [G loss: -12.298503]\n",
      "[Epoch 15/200] [Batch 565/815] [D loss: -5.589886] [G loss: -13.765456]\n",
      "[Epoch 15/200] [Batch 570/815] [D loss: -6.745176] [G loss: -17.108118]\n",
      "[Epoch 15/200] [Batch 575/815] [D loss: -6.835792] [G loss: -13.317241]\n",
      "[Epoch 15/200] [Batch 580/815] [D loss: -5.716955] [G loss: -20.841028]\n",
      "[Epoch 15/200] [Batch 585/815] [D loss: -5.207364] [G loss: -20.207411]\n",
      "[Epoch 15/200] [Batch 590/815] [D loss: -5.733248] [G loss: -12.085303]\n",
      "[Epoch 15/200] [Batch 595/815] [D loss: -5.495652] [G loss: -15.416060]\n",
      "[Epoch 15/200] [Batch 600/815] [D loss: -4.754536] [G loss: -26.517300]\n",
      "[Epoch 15/200] [Batch 605/815] [D loss: -5.916333] [G loss: -21.077375]\n",
      "[Epoch 15/200] [Batch 610/815] [D loss: -5.266896] [G loss: -14.009803]\n",
      "[Epoch 15/200] [Batch 615/815] [D loss: -4.894201] [G loss: -24.313467]\n",
      "[Epoch 15/200] [Batch 620/815] [D loss: -5.131182] [G loss: -19.924679]\n",
      "[Epoch 15/200] [Batch 625/815] [D loss: -5.157881] [G loss: -15.402573]\n",
      "[Epoch 15/200] [Batch 630/815] [D loss: -5.166047] [G loss: -20.559370]\n",
      "[Epoch 15/200] [Batch 635/815] [D loss: -5.415316] [G loss: -18.466948]\n",
      "[Epoch 15/200] [Batch 640/815] [D loss: -5.535500] [G loss: -16.960608]\n",
      "[Epoch 15/200] [Batch 645/815] [D loss: -5.270058] [G loss: -15.815209]\n",
      "[Epoch 15/200] [Batch 650/815] [D loss: -4.952607] [G loss: -18.053118]\n",
      "[Epoch 15/200] [Batch 655/815] [D loss: -4.536078] [G loss: -16.956198]\n",
      "[Epoch 15/200] [Batch 660/815] [D loss: -4.804029] [G loss: -22.740496]\n",
      "[Epoch 15/200] [Batch 665/815] [D loss: -5.828174] [G loss: -16.666479]\n",
      "[Epoch 15/200] [Batch 670/815] [D loss: -6.582494] [G loss: -15.478278]\n",
      "[Epoch 15/200] [Batch 675/815] [D loss: -5.034345] [G loss: -17.805309]\n",
      "[Epoch 15/200] [Batch 680/815] [D loss: -4.850482] [G loss: -33.538712]\n",
      "[Epoch 15/200] [Batch 685/815] [D loss: -6.278869] [G loss: -10.884666]\n",
      "[Epoch 15/200] [Batch 690/815] [D loss: -5.637583] [G loss: -14.892430]\n",
      "[Epoch 15/200] [Batch 695/815] [D loss: -5.260056] [G loss: -19.593248]\n",
      "[Epoch 15/200] [Batch 700/815] [D loss: -4.301810] [G loss: -19.489489]\n",
      "[Epoch 15/200] [Batch 705/815] [D loss: -6.226610] [G loss: -21.170942]\n",
      "[Epoch 15/200] [Batch 710/815] [D loss: -5.586944] [G loss: -14.782225]\n",
      "[Epoch 15/200] [Batch 715/815] [D loss: -5.513803] [G loss: -14.853037]\n",
      "[Epoch 15/200] [Batch 720/815] [D loss: -2.945547] [G loss: -22.860800]\n",
      "[Epoch 15/200] [Batch 725/815] [D loss: -4.612321] [G loss: -18.521458]\n",
      "[Epoch 15/200] [Batch 730/815] [D loss: -5.575998] [G loss: -13.329752]\n",
      "[Epoch 15/200] [Batch 735/815] [D loss: -6.339679] [G loss: -15.462178]\n",
      "[Epoch 15/200] [Batch 740/815] [D loss: -5.126163] [G loss: -16.426508]\n",
      "[Epoch 15/200] [Batch 745/815] [D loss: -5.712321] [G loss: -26.112202]\n",
      "[Epoch 15/200] [Batch 750/815] [D loss: -6.036900] [G loss: -18.913235]\n",
      "[Epoch 15/200] [Batch 755/815] [D loss: -6.159203] [G loss: -14.130912]\n",
      "[Epoch 15/200] [Batch 760/815] [D loss: -4.656807] [G loss: -29.509750]\n",
      "[Epoch 15/200] [Batch 765/815] [D loss: -6.413552] [G loss: -13.419615]\n",
      "[Epoch 15/200] [Batch 770/815] [D loss: -5.817805] [G loss: -12.935374]\n",
      "[Epoch 15/200] [Batch 775/815] [D loss: -6.573372] [G loss: -17.286842]\n",
      "[Epoch 15/200] [Batch 780/815] [D loss: -5.219255] [G loss: -17.187059]\n",
      "[Epoch 15/200] [Batch 785/815] [D loss: -5.994531] [G loss: -15.187775]\n",
      "[Epoch 15/200] [Batch 790/815] [D loss: -5.342761] [G loss: -20.334242]\n",
      "[Epoch 15/200] [Batch 795/815] [D loss: -5.957334] [G loss: -11.821672]\n",
      "[Epoch 15/200] [Batch 800/815] [D loss: -4.553609] [G loss: -19.318007]\n",
      "[Epoch 15/200] [Batch 805/815] [D loss: -6.264135] [G loss: -20.524868]\n",
      "[Epoch 15/200] [Batch 810/815] [D loss: -4.790593] [G loss: -13.389336]\n",
      "[Epoch 16/200] [Batch 0/815] [D loss: -3.586090] [G loss: -23.720606]\n",
      "[Epoch 16/200] [Batch 5/815] [D loss: -5.176847] [G loss: -12.709438]\n",
      "[Epoch 16/200] [Batch 10/815] [D loss: -5.611497] [G loss: -17.883682]\n",
      "[Epoch 16/200] [Batch 15/815] [D loss: -4.535034] [G loss: -21.799257]\n",
      "[Epoch 16/200] [Batch 20/815] [D loss: -4.652365] [G loss: -16.840111]\n",
      "[Epoch 16/200] [Batch 25/815] [D loss: -6.349782] [G loss: -19.164452]\n",
      "[Epoch 16/200] [Batch 30/815] [D loss: -5.885114] [G loss: -15.475626]\n",
      "[Epoch 16/200] [Batch 35/815] [D loss: -5.756405] [G loss: -12.327586]\n",
      "[Epoch 16/200] [Batch 40/815] [D loss: -6.107337] [G loss: -17.153217]\n",
      "[Epoch 16/200] [Batch 45/815] [D loss: -4.790087] [G loss: -25.449825]\n",
      "[Epoch 16/200] [Batch 50/815] [D loss: -5.767083] [G loss: -15.057938]\n",
      "[Epoch 16/200] [Batch 55/815] [D loss: -4.992974] [G loss: -23.419054]\n",
      "[Epoch 16/200] [Batch 60/815] [D loss: -6.035265] [G loss: -14.107186]\n",
      "[Epoch 16/200] [Batch 65/815] [D loss: -5.790145] [G loss: -12.724376]\n",
      "[Epoch 16/200] [Batch 70/815] [D loss: -5.972936] [G loss: -15.810822]\n",
      "[Epoch 16/200] [Batch 75/815] [D loss: -5.000886] [G loss: -19.142088]\n",
      "[Epoch 16/200] [Batch 80/815] [D loss: -4.618445] [G loss: -25.134756]\n",
      "[Epoch 16/200] [Batch 85/815] [D loss: -6.220018] [G loss: -20.537319]\n",
      "[Epoch 16/200] [Batch 90/815] [D loss: -5.423222] [G loss: -13.755922]\n",
      "[Epoch 16/200] [Batch 95/815] [D loss: -5.344158] [G loss: -22.617706]\n",
      "[Epoch 16/200] [Batch 100/815] [D loss: -5.881208] [G loss: -12.347905]\n",
      "[Epoch 16/200] [Batch 105/815] [D loss: -4.950883] [G loss: -18.984438]\n",
      "[Epoch 16/200] [Batch 110/815] [D loss: -4.882464] [G loss: -25.129948]\n",
      "[Epoch 16/200] [Batch 115/815] [D loss: -4.875528] [G loss: -20.062222]\n",
      "[Epoch 16/200] [Batch 120/815] [D loss: -4.790807] [G loss: -15.956885]\n",
      "[Epoch 16/200] [Batch 125/815] [D loss: -5.264337] [G loss: -22.374949]\n",
      "[Epoch 16/200] [Batch 130/815] [D loss: -5.361191] [G loss: -20.638592]\n",
      "[Epoch 16/200] [Batch 135/815] [D loss: -4.371018] [G loss: -16.085234]\n",
      "[Epoch 16/200] [Batch 140/815] [D loss: -5.937922] [G loss: -14.508839]\n",
      "[Epoch 16/200] [Batch 145/815] [D loss: -5.843393] [G loss: -15.920852]\n",
      "[Epoch 16/200] [Batch 150/815] [D loss: -6.048348] [G loss: -20.090784]\n",
      "[Epoch 16/200] [Batch 155/815] [D loss: -4.892204] [G loss: -15.933072]\n",
      "[Epoch 16/200] [Batch 160/815] [D loss: -6.064302] [G loss: -19.131258]\n",
      "[Epoch 16/200] [Batch 165/815] [D loss: -5.617782] [G loss: -23.997883]\n",
      "[Epoch 16/200] [Batch 170/815] [D loss: -5.283051] [G loss: -20.000013]\n",
      "[Epoch 16/200] [Batch 175/815] [D loss: -5.258080] [G loss: -19.140608]\n",
      "[Epoch 16/200] [Batch 180/815] [D loss: -4.829138] [G loss: -23.828518]\n",
      "[Epoch 16/200] [Batch 185/815] [D loss: -5.257055] [G loss: -19.495789]\n",
      "[Epoch 16/200] [Batch 190/815] [D loss: -5.090379] [G loss: -14.083150]\n",
      "[Epoch 16/200] [Batch 195/815] [D loss: -4.972761] [G loss: -24.250841]\n",
      "[Epoch 16/200] [Batch 200/815] [D loss: -5.546974] [G loss: -14.116107]\n",
      "[Epoch 16/200] [Batch 205/815] [D loss: -5.618554] [G loss: -19.061285]\n",
      "[Epoch 16/200] [Batch 210/815] [D loss: -6.290602] [G loss: -18.187042]\n",
      "[Epoch 16/200] [Batch 215/815] [D loss: -6.123687] [G loss: -19.117216]\n",
      "[Epoch 16/200] [Batch 220/815] [D loss: -6.697866] [G loss: -15.780934]\n",
      "[Epoch 16/200] [Batch 225/815] [D loss: -5.009078] [G loss: -18.968868]\n",
      "[Epoch 16/200] [Batch 230/815] [D loss: -4.784574] [G loss: -28.353485]\n",
      "[Epoch 16/200] [Batch 235/815] [D loss: -4.843497] [G loss: -14.366021]\n",
      "[Epoch 16/200] [Batch 240/815] [D loss: -6.165261] [G loss: -23.247465]\n",
      "[Epoch 16/200] [Batch 245/815] [D loss: -4.759477] [G loss: -18.260172]\n",
      "[Epoch 16/200] [Batch 250/815] [D loss: -6.660810] [G loss: -13.873060]\n",
      "[Epoch 16/200] [Batch 255/815] [D loss: -5.976392] [G loss: -13.779781]\n",
      "[Epoch 16/200] [Batch 260/815] [D loss: -5.237255] [G loss: -17.233000]\n",
      "[Epoch 16/200] [Batch 265/815] [D loss: -4.710500] [G loss: -17.956371]\n",
      "[Epoch 16/200] [Batch 270/815] [D loss: -5.542785] [G loss: -24.901306]\n",
      "[Epoch 16/200] [Batch 275/815] [D loss: -4.736252] [G loss: -18.588129]\n",
      "[Epoch 16/200] [Batch 280/815] [D loss: -4.997233] [G loss: -17.543880]\n",
      "[Epoch 16/200] [Batch 285/815] [D loss: -5.035860] [G loss: -17.822792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/200] [Batch 290/815] [D loss: -5.974002] [G loss: -20.359734]\n",
      "[Epoch 16/200] [Batch 295/815] [D loss: -5.169615] [G loss: -14.011586]\n",
      "[Epoch 16/200] [Batch 300/815] [D loss: -5.312009] [G loss: -14.994915]\n",
      "[Epoch 16/200] [Batch 305/815] [D loss: -5.404318] [G loss: -22.150661]\n",
      "[Epoch 16/200] [Batch 310/815] [D loss: -5.172597] [G loss: -17.284466]\n",
      "[Epoch 16/200] [Batch 315/815] [D loss: -6.478464] [G loss: -13.522379]\n",
      "[Epoch 16/200] [Batch 320/815] [D loss: -5.608766] [G loss: -15.318234]\n",
      "[Epoch 16/200] [Batch 325/815] [D loss: -5.003006] [G loss: -21.949177]\n",
      "[Epoch 16/200] [Batch 330/815] [D loss: -4.824384] [G loss: -18.888426]\n",
      "[Epoch 16/200] [Batch 335/815] [D loss: -5.228038] [G loss: -16.396557]\n",
      "[Epoch 16/200] [Batch 340/815] [D loss: -5.864892] [G loss: -17.518700]\n",
      "[Epoch 16/200] [Batch 345/815] [D loss: -4.795249] [G loss: -19.561785]\n",
      "[Epoch 16/200] [Batch 350/815] [D loss: -5.915900] [G loss: -22.004751]\n",
      "[Epoch 16/200] [Batch 355/815] [D loss: -6.036451] [G loss: -12.195478]\n",
      "[Epoch 16/200] [Batch 360/815] [D loss: -5.342736] [G loss: -19.742243]\n",
      "[Epoch 16/200] [Batch 365/815] [D loss: -4.626639] [G loss: -23.491884]\n",
      "[Epoch 16/200] [Batch 370/815] [D loss: -6.706440] [G loss: -13.594131]\n",
      "[Epoch 16/200] [Batch 375/815] [D loss: -4.833337] [G loss: -19.577135]\n",
      "[Epoch 16/200] [Batch 380/815] [D loss: -5.175340] [G loss: -17.786177]\n",
      "[Epoch 16/200] [Batch 385/815] [D loss: -5.221441] [G loss: -24.099846]\n",
      "[Epoch 16/200] [Batch 390/815] [D loss: -5.112167] [G loss: -17.632729]\n",
      "[Epoch 16/200] [Batch 395/815] [D loss: -6.150342] [G loss: -15.848948]\n",
      "[Epoch 16/200] [Batch 400/815] [D loss: -4.394137] [G loss: -26.943399]\n",
      "[Epoch 16/200] [Batch 405/815] [D loss: -6.010018] [G loss: -13.574704]\n",
      "[Epoch 16/200] [Batch 410/815] [D loss: -5.691663] [G loss: -17.154856]\n",
      "[Epoch 16/200] [Batch 415/815] [D loss: -5.278180] [G loss: -22.661482]\n",
      "[Epoch 16/200] [Batch 420/815] [D loss: -6.059478] [G loss: -19.116674]\n",
      "[Epoch 16/200] [Batch 425/815] [D loss: -4.955319] [G loss: -18.269112]\n",
      "[Epoch 16/200] [Batch 430/815] [D loss: -5.999704] [G loss: -29.675209]\n",
      "[Epoch 16/200] [Batch 435/815] [D loss: -5.873985] [G loss: -14.789187]\n",
      "[Epoch 16/200] [Batch 440/815] [D loss: -5.214746] [G loss: -15.565500]\n",
      "[Epoch 16/200] [Batch 445/815] [D loss: -4.805548] [G loss: -20.526114]\n",
      "[Epoch 16/200] [Batch 450/815] [D loss: -5.448142] [G loss: -14.724126]\n",
      "[Epoch 16/200] [Batch 455/815] [D loss: -5.529394] [G loss: -12.432251]\n",
      "[Epoch 16/200] [Batch 460/815] [D loss: -5.314441] [G loss: -16.744104]\n",
      "[Epoch 16/200] [Batch 465/815] [D loss: -5.452008] [G loss: -12.186398]\n",
      "[Epoch 16/200] [Batch 470/815] [D loss: -5.390431] [G loss: -21.075470]\n",
      "[Epoch 16/200] [Batch 475/815] [D loss: -4.784654] [G loss: -16.098608]\n",
      "[Epoch 16/200] [Batch 480/815] [D loss: -5.947340] [G loss: -12.952859]\n",
      "[Epoch 16/200] [Batch 485/815] [D loss: -4.866253] [G loss: -38.903538]\n",
      "[Epoch 16/200] [Batch 490/815] [D loss: -4.989938] [G loss: -21.627972]\n",
      "[Epoch 16/200] [Batch 495/815] [D loss: -4.526846] [G loss: -19.694946]\n",
      "[Epoch 16/200] [Batch 500/815] [D loss: -6.144354] [G loss: -15.396568]\n",
      "[Epoch 16/200] [Batch 505/815] [D loss: -5.651058] [G loss: -22.338614]\n",
      "[Epoch 16/200] [Batch 510/815] [D loss: -4.555785] [G loss: -22.046953]\n",
      "[Epoch 16/200] [Batch 515/815] [D loss: -5.498858] [G loss: -15.349875]\n",
      "[Epoch 16/200] [Batch 520/815] [D loss: -5.211002] [G loss: -16.479425]\n",
      "[Epoch 16/200] [Batch 525/815] [D loss: -5.541685] [G loss: -17.312469]\n",
      "[Epoch 16/200] [Batch 530/815] [D loss: -6.109386] [G loss: -12.928606]\n",
      "[Epoch 16/200] [Batch 535/815] [D loss: -5.007375] [G loss: -15.645869]\n",
      "[Epoch 16/200] [Batch 540/815] [D loss: -4.108864] [G loss: -36.803719]\n",
      "[Epoch 16/200] [Batch 545/815] [D loss: -5.822719] [G loss: -16.997139]\n",
      "[Epoch 16/200] [Batch 550/815] [D loss: -5.629071] [G loss: -14.315396]\n",
      "[Epoch 16/200] [Batch 555/815] [D loss: -6.182027] [G loss: -11.878788]\n",
      "[Epoch 16/200] [Batch 560/815] [D loss: -4.688173] [G loss: -27.613876]\n",
      "[Epoch 16/200] [Batch 565/815] [D loss: -4.868132] [G loss: -16.896317]\n",
      "[Epoch 16/200] [Batch 570/815] [D loss: -5.310555] [G loss: -12.276151]\n",
      "[Epoch 16/200] [Batch 575/815] [D loss: -5.295997] [G loss: -21.383762]\n",
      "[Epoch 16/200] [Batch 580/815] [D loss: -4.533982] [G loss: -35.291492]\n",
      "[Epoch 16/200] [Batch 585/815] [D loss: -4.994444] [G loss: -19.236511]\n",
      "[Epoch 16/200] [Batch 590/815] [D loss: -5.319282] [G loss: -15.291293]\n",
      "[Epoch 16/200] [Batch 595/815] [D loss: -6.188515] [G loss: -12.333170]\n",
      "[Epoch 16/200] [Batch 600/815] [D loss: -4.568350] [G loss: -23.216101]\n",
      "[Epoch 16/200] [Batch 605/815] [D loss: -5.625261] [G loss: -14.067946]\n",
      "[Epoch 16/200] [Batch 610/815] [D loss: -5.662670] [G loss: -12.192838]\n",
      "[Epoch 16/200] [Batch 615/815] [D loss: -5.125329] [G loss: -11.479815]\n",
      "[Epoch 16/200] [Batch 620/815] [D loss: -5.238628] [G loss: -25.463400]\n",
      "[Epoch 16/200] [Batch 625/815] [D loss: -4.921513] [G loss: -19.683027]\n",
      "[Epoch 16/200] [Batch 630/815] [D loss: -5.104434] [G loss: -15.965480]\n",
      "[Epoch 16/200] [Batch 635/815] [D loss: -5.503751] [G loss: -25.059744]\n",
      "[Epoch 16/200] [Batch 640/815] [D loss: -5.456218] [G loss: -15.491992]\n",
      "[Epoch 16/200] [Batch 645/815] [D loss: -5.516150] [G loss: -18.125580]\n",
      "[Epoch 16/200] [Batch 650/815] [D loss: -3.451127] [G loss: -30.201456]\n",
      "[Epoch 16/200] [Batch 655/815] [D loss: -5.585418] [G loss: -10.517262]\n",
      "[Epoch 16/200] [Batch 660/815] [D loss: -5.444874] [G loss: -14.603586]\n",
      "[Epoch 16/200] [Batch 665/815] [D loss: -5.842039] [G loss: -17.021574]\n",
      "[Epoch 16/200] [Batch 670/815] [D loss: -4.895551] [G loss: -30.377197]\n",
      "[Epoch 16/200] [Batch 675/815] [D loss: -4.297110] [G loss: -13.780599]\n",
      "[Epoch 16/200] [Batch 680/815] [D loss: -6.773745] [G loss: -14.349008]\n",
      "[Epoch 16/200] [Batch 685/815] [D loss: -5.777414] [G loss: -13.924867]\n",
      "[Epoch 16/200] [Batch 690/815] [D loss: -4.631301] [G loss: -20.912390]\n",
      "[Epoch 16/200] [Batch 695/815] [D loss: -5.010677] [G loss: -17.864056]\n",
      "[Epoch 16/200] [Batch 700/815] [D loss: -5.901432] [G loss: -14.025190]\n",
      "[Epoch 16/200] [Batch 705/815] [D loss: -5.085312] [G loss: -17.200575]\n",
      "[Epoch 16/200] [Batch 710/815] [D loss: -6.586184] [G loss: -12.486142]\n",
      "[Epoch 16/200] [Batch 715/815] [D loss: -4.947170] [G loss: -18.294174]\n",
      "[Epoch 16/200] [Batch 720/815] [D loss: -5.738925] [G loss: -30.156603]\n",
      "[Epoch 16/200] [Batch 725/815] [D loss: -4.954856] [G loss: -23.133671]\n",
      "[Epoch 16/200] [Batch 730/815] [D loss: -4.927738] [G loss: -19.187283]\n",
      "[Epoch 16/200] [Batch 735/815] [D loss: -5.378088] [G loss: -17.477856]\n",
      "[Epoch 16/200] [Batch 740/815] [D loss: -5.659319] [G loss: -16.614862]\n",
      "[Epoch 16/200] [Batch 745/815] [D loss: -5.049339] [G loss: -22.646179]\n",
      "[Epoch 16/200] [Batch 750/815] [D loss: -5.413487] [G loss: -17.213678]\n",
      "[Epoch 16/200] [Batch 755/815] [D loss: -5.342671] [G loss: -15.234415]\n",
      "[Epoch 16/200] [Batch 760/815] [D loss: -5.566335] [G loss: -17.240164]\n",
      "[Epoch 16/200] [Batch 765/815] [D loss: -5.753007] [G loss: -18.253538]\n",
      "[Epoch 16/200] [Batch 770/815] [D loss: -5.613197] [G loss: -19.570229]\n",
      "[Epoch 16/200] [Batch 775/815] [D loss: -4.899723] [G loss: -25.047651]\n",
      "[Epoch 16/200] [Batch 780/815] [D loss: -5.713298] [G loss: -11.401371]\n",
      "[Epoch 16/200] [Batch 785/815] [D loss: -6.275140] [G loss: -11.535993]\n",
      "[Epoch 16/200] [Batch 790/815] [D loss: -6.205692] [G loss: -11.970181]\n",
      "[Epoch 16/200] [Batch 795/815] [D loss: -5.874180] [G loss: -13.431414]\n",
      "[Epoch 16/200] [Batch 800/815] [D loss: -5.694674] [G loss: -19.988506]\n",
      "[Epoch 16/200] [Batch 805/815] [D loss: -5.739711] [G loss: -21.652828]\n",
      "[Epoch 16/200] [Batch 810/815] [D loss: -5.867596] [G loss: -13.799635]\n",
      "[Epoch 17/200] [Batch 0/815] [D loss: -4.508802] [G loss: -27.232258]\n",
      "[Epoch 17/200] [Batch 5/815] [D loss: -6.303807] [G loss: -16.670897]\n",
      "[Epoch 17/200] [Batch 10/815] [D loss: -6.065492] [G loss: -20.148113]\n",
      "[Epoch 17/200] [Batch 15/815] [D loss: -6.469816] [G loss: -13.297633]\n",
      "[Epoch 17/200] [Batch 20/815] [D loss: -4.949562] [G loss: -25.021830]\n",
      "[Epoch 17/200] [Batch 25/815] [D loss: -5.247076] [G loss: -15.763290]\n",
      "[Epoch 17/200] [Batch 30/815] [D loss: -6.088924] [G loss: -15.031442]\n",
      "[Epoch 17/200] [Batch 35/815] [D loss: -6.072838] [G loss: -17.819126]\n",
      "[Epoch 17/200] [Batch 40/815] [D loss: -5.376163] [G loss: -14.781670]\n",
      "[Epoch 17/200] [Batch 45/815] [D loss: -5.990519] [G loss: -17.438650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 50/815] [D loss: -5.890247] [G loss: -15.842316]\n",
      "[Epoch 17/200] [Batch 55/815] [D loss: -5.803301] [G loss: -14.410214]\n",
      "[Epoch 17/200] [Batch 60/815] [D loss: -6.731543] [G loss: -12.565250]\n",
      "[Epoch 17/200] [Batch 65/815] [D loss: -5.337253] [G loss: -15.215691]\n",
      "[Epoch 17/200] [Batch 70/815] [D loss: -4.020464] [G loss: -30.136087]\n",
      "[Epoch 17/200] [Batch 75/815] [D loss: -5.364677] [G loss: -14.883923]\n",
      "[Epoch 17/200] [Batch 80/815] [D loss: -5.350446] [G loss: -16.275660]\n",
      "[Epoch 17/200] [Batch 85/815] [D loss: -5.650558] [G loss: -16.619680]\n",
      "[Epoch 17/200] [Batch 90/815] [D loss: -4.786639] [G loss: -19.087261]\n",
      "[Epoch 17/200] [Batch 95/815] [D loss: -5.119912] [G loss: -17.737637]\n",
      "[Epoch 17/200] [Batch 100/815] [D loss: -5.063974] [G loss: -16.536011]\n",
      "[Epoch 17/200] [Batch 105/815] [D loss: -5.161375] [G loss: -22.522074]\n",
      "[Epoch 17/200] [Batch 110/815] [D loss: -6.778167] [G loss: -14.888864]\n",
      "[Epoch 17/200] [Batch 115/815] [D loss: -5.617906] [G loss: -17.808945]\n",
      "[Epoch 17/200] [Batch 120/815] [D loss: -5.350244] [G loss: -24.504772]\n",
      "[Epoch 17/200] [Batch 125/815] [D loss: -5.006062] [G loss: -16.879835]\n",
      "[Epoch 17/200] [Batch 130/815] [D loss: -4.658982] [G loss: -22.998774]\n",
      "[Epoch 17/200] [Batch 135/815] [D loss: -6.080449] [G loss: -12.494215]\n",
      "[Epoch 17/200] [Batch 140/815] [D loss: -5.213167] [G loss: -17.841736]\n",
      "[Epoch 17/200] [Batch 145/815] [D loss: -5.684287] [G loss: -12.900009]\n",
      "[Epoch 17/200] [Batch 150/815] [D loss: -5.827796] [G loss: -18.361382]\n",
      "[Epoch 17/200] [Batch 155/815] [D loss: -5.468575] [G loss: -26.449606]\n",
      "[Epoch 17/200] [Batch 160/815] [D loss: -5.626840] [G loss: -15.367479]\n",
      "[Epoch 17/200] [Batch 165/815] [D loss: -4.838466] [G loss: -25.107500]\n",
      "[Epoch 17/200] [Batch 170/815] [D loss: -6.230036] [G loss: -16.900106]\n",
      "[Epoch 17/200] [Batch 175/815] [D loss: -5.500028] [G loss: -19.000975]\n",
      "[Epoch 17/200] [Batch 180/815] [D loss: -5.890924] [G loss: -16.827528]\n",
      "[Epoch 17/200] [Batch 185/815] [D loss: -5.471628] [G loss: -19.689020]\n",
      "[Epoch 17/200] [Batch 190/815] [D loss: -5.850279] [G loss: -14.128211]\n",
      "[Epoch 17/200] [Batch 195/815] [D loss: -6.437799] [G loss: -12.800958]\n",
      "[Epoch 17/200] [Batch 200/815] [D loss: -5.368808] [G loss: -19.540714]\n",
      "[Epoch 17/200] [Batch 205/815] [D loss: -5.599743] [G loss: -20.573681]\n",
      "[Epoch 17/200] [Batch 210/815] [D loss: -4.214477] [G loss: -36.043800]\n",
      "[Epoch 17/200] [Batch 215/815] [D loss: -5.722521] [G loss: -21.767866]\n",
      "[Epoch 17/200] [Batch 220/815] [D loss: -5.378332] [G loss: -22.510376]\n",
      "[Epoch 17/200] [Batch 225/815] [D loss: -5.761365] [G loss: -14.987281]\n",
      "[Epoch 17/200] [Batch 230/815] [D loss: -4.917562] [G loss: -16.796852]\n",
      "[Epoch 17/200] [Batch 235/815] [D loss: -5.155112] [G loss: -17.201097]\n",
      "[Epoch 17/200] [Batch 240/815] [D loss: -6.561630] [G loss: -13.168494]\n",
      "[Epoch 17/200] [Batch 245/815] [D loss: -5.625947] [G loss: -13.508984]\n",
      "[Epoch 17/200] [Batch 250/815] [D loss: -5.254374] [G loss: -16.787579]\n",
      "[Epoch 17/200] [Batch 255/815] [D loss: -5.232601] [G loss: -20.623041]\n",
      "[Epoch 17/200] [Batch 260/815] [D loss: -5.558394] [G loss: -13.984985]\n",
      "[Epoch 17/200] [Batch 265/815] [D loss: -5.364016] [G loss: -18.338058]\n",
      "[Epoch 17/200] [Batch 270/815] [D loss: -4.572718] [G loss: -16.545435]\n",
      "[Epoch 17/200] [Batch 275/815] [D loss: -5.365397] [G loss: -14.799526]\n",
      "[Epoch 17/200] [Batch 280/815] [D loss: -6.145532] [G loss: -12.223734]\n",
      "[Epoch 17/200] [Batch 285/815] [D loss: -4.735154] [G loss: -20.209303]\n",
      "[Epoch 17/200] [Batch 290/815] [D loss: -5.295311] [G loss: -15.219550]\n",
      "[Epoch 17/200] [Batch 295/815] [D loss: -5.075056] [G loss: -24.051418]\n",
      "[Epoch 17/200] [Batch 300/815] [D loss: -5.896572] [G loss: -14.522296]\n",
      "[Epoch 17/200] [Batch 305/815] [D loss: -6.352456] [G loss: -15.360369]\n",
      "[Epoch 17/200] [Batch 310/815] [D loss: -5.252826] [G loss: -12.501850]\n",
      "[Epoch 17/200] [Batch 315/815] [D loss: -5.392549] [G loss: -13.248058]\n",
      "[Epoch 17/200] [Batch 320/815] [D loss: -6.261174] [G loss: -21.167168]\n",
      "[Epoch 17/200] [Batch 325/815] [D loss: -5.505461] [G loss: -22.052830]\n",
      "[Epoch 17/200] [Batch 330/815] [D loss: -4.956549] [G loss: -14.500438]\n",
      "[Epoch 17/200] [Batch 335/815] [D loss: -5.378504] [G loss: -20.956696]\n",
      "[Epoch 17/200] [Batch 340/815] [D loss: -5.822308] [G loss: -14.632690]\n",
      "[Epoch 17/200] [Batch 345/815] [D loss: -6.133883] [G loss: -14.456268]\n",
      "[Epoch 17/200] [Batch 350/815] [D loss: -4.965243] [G loss: -24.352753]\n",
      "[Epoch 17/200] [Batch 355/815] [D loss: -5.254597] [G loss: -28.671898]\n",
      "[Epoch 17/200] [Batch 360/815] [D loss: -4.796677] [G loss: -17.449789]\n",
      "[Epoch 17/200] [Batch 365/815] [D loss: -5.275609] [G loss: -14.429003]\n",
      "[Epoch 17/200] [Batch 370/815] [D loss: -4.001403] [G loss: -27.592638]\n",
      "[Epoch 17/200] [Batch 375/815] [D loss: -5.431734] [G loss: -13.260213]\n",
      "[Epoch 17/200] [Batch 380/815] [D loss: -4.569252] [G loss: -28.871073]\n",
      "[Epoch 17/200] [Batch 385/815] [D loss: -3.809349] [G loss: -20.388205]\n",
      "[Epoch 17/200] [Batch 390/815] [D loss: -6.209131] [G loss: -11.380837]\n",
      "[Epoch 17/200] [Batch 395/815] [D loss: -5.800728] [G loss: -18.926144]\n",
      "[Epoch 17/200] [Batch 400/815] [D loss: -4.976729] [G loss: -22.393206]\n",
      "[Epoch 17/200] [Batch 405/815] [D loss: -3.409915] [G loss: -19.537083]\n",
      "[Epoch 17/200] [Batch 410/815] [D loss: -4.619827] [G loss: -19.586847]\n",
      "[Epoch 17/200] [Batch 415/815] [D loss: -4.845041] [G loss: -29.388027]\n",
      "[Epoch 17/200] [Batch 420/815] [D loss: -4.834929] [G loss: -15.432240]\n",
      "[Epoch 17/200] [Batch 425/815] [D loss: -5.444618] [G loss: -18.824917]\n",
      "[Epoch 17/200] [Batch 430/815] [D loss: -5.100860] [G loss: -16.474407]\n",
      "[Epoch 17/200] [Batch 435/815] [D loss: -6.468646] [G loss: -12.508694]\n",
      "[Epoch 17/200] [Batch 440/815] [D loss: -5.388721] [G loss: -17.495296]\n",
      "[Epoch 17/200] [Batch 445/815] [D loss: -5.806012] [G loss: -18.800070]\n",
      "[Epoch 17/200] [Batch 450/815] [D loss: -4.343322] [G loss: -33.893520]\n",
      "[Epoch 17/200] [Batch 455/815] [D loss: -5.973247] [G loss: -16.267998]\n",
      "[Epoch 17/200] [Batch 460/815] [D loss: -5.423287] [G loss: -21.390768]\n",
      "[Epoch 17/200] [Batch 465/815] [D loss: -5.583118] [G loss: -16.426235]\n",
      "[Epoch 17/200] [Batch 470/815] [D loss: -5.559076] [G loss: -14.659333]\n",
      "[Epoch 17/200] [Batch 475/815] [D loss: -6.162066] [G loss: -18.402199]\n",
      "[Epoch 17/200] [Batch 480/815] [D loss: -4.734540] [G loss: -24.319506]\n",
      "[Epoch 17/200] [Batch 485/815] [D loss: -4.638374] [G loss: -21.923063]\n",
      "[Epoch 17/200] [Batch 490/815] [D loss: -5.747178] [G loss: -12.138135]\n",
      "[Epoch 17/200] [Batch 495/815] [D loss: -5.923082] [G loss: -17.094507]\n",
      "[Epoch 17/200] [Batch 500/815] [D loss: -5.229256] [G loss: -20.064394]\n",
      "[Epoch 17/200] [Batch 505/815] [D loss: -4.828664] [G loss: -21.472685]\n",
      "[Epoch 17/200] [Batch 510/815] [D loss: -5.141311] [G loss: -15.331544]\n",
      "[Epoch 17/200] [Batch 515/815] [D loss: -5.422495] [G loss: -13.869217]\n",
      "[Epoch 17/200] [Batch 520/815] [D loss: -5.269940] [G loss: -16.540974]\n",
      "[Epoch 17/200] [Batch 525/815] [D loss: -4.905369] [G loss: -33.255856]\n",
      "[Epoch 17/200] [Batch 530/815] [D loss: -5.062207] [G loss: -19.726988]\n",
      "[Epoch 17/200] [Batch 535/815] [D loss: -5.336603] [G loss: -13.642509]\n",
      "[Epoch 17/200] [Batch 540/815] [D loss: -6.240939] [G loss: -15.671714]\n",
      "[Epoch 17/200] [Batch 545/815] [D loss: -5.369691] [G loss: -23.659277]\n",
      "[Epoch 17/200] [Batch 550/815] [D loss: -3.947115] [G loss: -24.158989]\n",
      "[Epoch 17/200] [Batch 555/815] [D loss: -4.488671] [G loss: -18.333179]\n",
      "[Epoch 17/200] [Batch 560/815] [D loss: -5.251240] [G loss: -13.558738]\n",
      "[Epoch 17/200] [Batch 565/815] [D loss: -5.487889] [G loss: -18.095362]\n",
      "[Epoch 17/200] [Batch 570/815] [D loss: -5.932379] [G loss: -14.809302]\n",
      "[Epoch 17/200] [Batch 575/815] [D loss: -5.012987] [G loss: -18.998655]\n",
      "[Epoch 17/200] [Batch 580/815] [D loss: -4.343489] [G loss: -23.441624]\n",
      "[Epoch 17/200] [Batch 585/815] [D loss: -4.900734] [G loss: -29.112532]\n",
      "[Epoch 17/200] [Batch 590/815] [D loss: -5.494013] [G loss: -15.253784]\n",
      "[Epoch 17/200] [Batch 595/815] [D loss: -5.507668] [G loss: -16.080576]\n",
      "[Epoch 17/200] [Batch 600/815] [D loss: -6.228287] [G loss: -18.311352]\n",
      "[Epoch 17/200] [Batch 605/815] [D loss: -5.180878] [G loss: -15.318941]\n",
      "[Epoch 17/200] [Batch 610/815] [D loss: -5.200097] [G loss: -18.826490]\n",
      "[Epoch 17/200] [Batch 615/815] [D loss: -5.784714] [G loss: -13.056545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/200] [Batch 620/815] [D loss: -5.596074] [G loss: -19.824961]\n",
      "[Epoch 17/200] [Batch 625/815] [D loss: -6.113561] [G loss: -16.474810]\n",
      "[Epoch 17/200] [Batch 630/815] [D loss: -5.998625] [G loss: -13.191191]\n",
      "[Epoch 17/200] [Batch 635/815] [D loss: -3.973364] [G loss: -24.240274]\n",
      "[Epoch 17/200] [Batch 640/815] [D loss: -5.110605] [G loss: -18.786430]\n",
      "[Epoch 17/200] [Batch 645/815] [D loss: -5.670734] [G loss: -13.007142]\n",
      "[Epoch 17/200] [Batch 650/815] [D loss: -4.749209] [G loss: -18.256237]\n",
      "[Epoch 17/200] [Batch 655/815] [D loss: -5.628743] [G loss: -17.020555]\n",
      "[Epoch 17/200] [Batch 660/815] [D loss: -5.934007] [G loss: -15.874090]\n",
      "[Epoch 17/200] [Batch 665/815] [D loss: -5.239160] [G loss: -22.844938]\n",
      "[Epoch 17/200] [Batch 670/815] [D loss: -6.570071] [G loss: -12.162521]\n",
      "[Epoch 17/200] [Batch 675/815] [D loss: -5.104398] [G loss: -20.766470]\n",
      "[Epoch 17/200] [Batch 680/815] [D loss: -5.288681] [G loss: -22.408983]\n",
      "[Epoch 17/200] [Batch 685/815] [D loss: -5.238461] [G loss: -17.539362]\n",
      "[Epoch 17/200] [Batch 690/815] [D loss: -5.162331] [G loss: -14.519538]\n",
      "[Epoch 17/200] [Batch 695/815] [D loss: -5.072028] [G loss: -29.579844]\n",
      "[Epoch 17/200] [Batch 700/815] [D loss: -5.472402] [G loss: -19.108948]\n",
      "[Epoch 17/200] [Batch 705/815] [D loss: -6.406332] [G loss: -11.603055]\n",
      "[Epoch 17/200] [Batch 710/815] [D loss: -5.542035] [G loss: -21.148228]\n",
      "[Epoch 17/200] [Batch 715/815] [D loss: -5.908612] [G loss: -17.433756]\n",
      "[Epoch 17/200] [Batch 720/815] [D loss: -5.069145] [G loss: -23.372297]\n",
      "[Epoch 17/200] [Batch 725/815] [D loss: -6.265495] [G loss: -12.614092]\n",
      "[Epoch 17/200] [Batch 730/815] [D loss: -5.346304] [G loss: -15.698000]\n",
      "[Epoch 17/200] [Batch 735/815] [D loss: -6.105405] [G loss: -16.372803]\n",
      "[Epoch 17/200] [Batch 740/815] [D loss: -5.953375] [G loss: -14.424938]\n",
      "[Epoch 17/200] [Batch 745/815] [D loss: -5.326095] [G loss: -20.168987]\n",
      "[Epoch 17/200] [Batch 750/815] [D loss: -4.847007] [G loss: -20.783752]\n",
      "[Epoch 17/200] [Batch 755/815] [D loss: -5.417879] [G loss: -21.631884]\n",
      "[Epoch 17/200] [Batch 760/815] [D loss: -5.008348] [G loss: -15.092379]\n",
      "[Epoch 17/200] [Batch 765/815] [D loss: -4.497434] [G loss: -21.508825]\n",
      "[Epoch 17/200] [Batch 770/815] [D loss: -5.364260] [G loss: -13.909777]\n",
      "[Epoch 17/200] [Batch 775/815] [D loss: -6.915667] [G loss: -16.428581]\n",
      "[Epoch 17/200] [Batch 780/815] [D loss: -7.020528] [G loss: -11.576614]\n",
      "[Epoch 17/200] [Batch 785/815] [D loss: -5.408934] [G loss: -13.297313]\n",
      "[Epoch 17/200] [Batch 790/815] [D loss: -5.865750] [G loss: -19.041155]\n",
      "[Epoch 17/200] [Batch 795/815] [D loss: -5.233552] [G loss: -19.025610]\n",
      "[Epoch 17/200] [Batch 800/815] [D loss: -5.165295] [G loss: -22.120478]\n",
      "[Epoch 17/200] [Batch 805/815] [D loss: -5.284390] [G loss: -16.472616]\n",
      "[Epoch 17/200] [Batch 810/815] [D loss: -5.127629] [G loss: -20.122223]\n",
      "[Epoch 18/200] [Batch 0/815] [D loss: -4.587110] [G loss: -21.752710]\n",
      "[Epoch 18/200] [Batch 5/815] [D loss: -5.109277] [G loss: -17.890415]\n",
      "[Epoch 18/200] [Batch 10/815] [D loss: -5.154704] [G loss: -18.898523]\n",
      "[Epoch 18/200] [Batch 15/815] [D loss: -6.003846] [G loss: -16.459486]\n",
      "[Epoch 18/200] [Batch 20/815] [D loss: -5.605839] [G loss: -13.851642]\n",
      "[Epoch 18/200] [Batch 25/815] [D loss: -5.733439] [G loss: -21.898512]\n",
      "[Epoch 18/200] [Batch 30/815] [D loss: -5.924767] [G loss: -19.106342]\n",
      "[Epoch 18/200] [Batch 35/815] [D loss: -4.937850] [G loss: -20.268469]\n",
      "[Epoch 18/200] [Batch 40/815] [D loss: -4.993678] [G loss: -27.327171]\n",
      "[Epoch 18/200] [Batch 45/815] [D loss: -5.544945] [G loss: -18.873383]\n",
      "[Epoch 18/200] [Batch 50/815] [D loss: -5.516858] [G loss: -16.255896]\n",
      "[Epoch 18/200] [Batch 55/815] [D loss: -6.704382] [G loss: -15.387190]\n",
      "[Epoch 18/200] [Batch 60/815] [D loss: -6.011439] [G loss: -13.303363]\n",
      "[Epoch 18/200] [Batch 65/815] [D loss: -4.581884] [G loss: -19.374302]\n",
      "[Epoch 18/200] [Batch 70/815] [D loss: -6.345121] [G loss: -14.055171]\n",
      "[Epoch 18/200] [Batch 75/815] [D loss: -5.716171] [G loss: -21.276628]\n",
      "[Epoch 18/200] [Batch 80/815] [D loss: -6.686505] [G loss: -17.615116]\n",
      "[Epoch 18/200] [Batch 85/815] [D loss: -6.172748] [G loss: -15.977627]\n",
      "[Epoch 18/200] [Batch 90/815] [D loss: -5.232912] [G loss: -17.772491]\n",
      "[Epoch 18/200] [Batch 95/815] [D loss: -5.158216] [G loss: -16.030745]\n",
      "[Epoch 18/200] [Batch 100/815] [D loss: -6.174092] [G loss: -16.007521]\n",
      "[Epoch 18/200] [Batch 105/815] [D loss: -5.505996] [G loss: -19.119738]\n",
      "[Epoch 18/200] [Batch 110/815] [D loss: -5.177675] [G loss: -20.100918]\n",
      "[Epoch 18/200] [Batch 115/815] [D loss: -5.342014] [G loss: -15.655803]\n",
      "[Epoch 18/200] [Batch 120/815] [D loss: -5.549836] [G loss: -18.615906]\n",
      "[Epoch 18/200] [Batch 125/815] [D loss: -5.100903] [G loss: -18.680815]\n",
      "[Epoch 18/200] [Batch 130/815] [D loss: -5.751656] [G loss: -14.599063]\n",
      "[Epoch 18/200] [Batch 135/815] [D loss: -3.708694] [G loss: -31.486290]\n",
      "[Epoch 18/200] [Batch 140/815] [D loss: -5.398420] [G loss: -14.594709]\n",
      "[Epoch 18/200] [Batch 145/815] [D loss: -6.534465] [G loss: -10.142397]\n",
      "[Epoch 18/200] [Batch 150/815] [D loss: -5.612669] [G loss: -18.896349]\n",
      "[Epoch 18/200] [Batch 155/815] [D loss: -5.285511] [G loss: -18.609587]\n",
      "[Epoch 18/200] [Batch 160/815] [D loss: -4.999498] [G loss: -36.207359]\n",
      "[Epoch 18/200] [Batch 165/815] [D loss: -4.339005] [G loss: -21.434038]\n",
      "[Epoch 18/200] [Batch 170/815] [D loss: -4.945121] [G loss: -19.562185]\n",
      "[Epoch 18/200] [Batch 175/815] [D loss: -5.326062] [G loss: -15.515078]\n",
      "[Epoch 18/200] [Batch 180/815] [D loss: -4.873518] [G loss: -18.317295]\n",
      "[Epoch 18/200] [Batch 185/815] [D loss: -4.855801] [G loss: -15.194590]\n",
      "[Epoch 18/200] [Batch 190/815] [D loss: -5.736644] [G loss: -18.137329]\n",
      "[Epoch 18/200] [Batch 195/815] [D loss: -5.102438] [G loss: -22.254778]\n",
      "[Epoch 18/200] [Batch 200/815] [D loss: -5.176515] [G loss: -15.519121]\n",
      "[Epoch 18/200] [Batch 205/815] [D loss: -6.006926] [G loss: -15.121841]\n",
      "[Epoch 18/200] [Batch 210/815] [D loss: -5.592224] [G loss: -16.435957]\n",
      "[Epoch 18/200] [Batch 215/815] [D loss: -5.349096] [G loss: -15.497063]\n",
      "[Epoch 18/200] [Batch 220/815] [D loss: -4.780097] [G loss: -19.736952]\n",
      "[Epoch 18/200] [Batch 225/815] [D loss: -5.614410] [G loss: -22.292379]\n",
      "[Epoch 18/200] [Batch 230/815] [D loss: -4.676320] [G loss: -15.012668]\n",
      "[Epoch 18/200] [Batch 235/815] [D loss: -4.496900] [G loss: -17.256292]\n",
      "[Epoch 18/200] [Batch 240/815] [D loss: -4.829884] [G loss: -17.477100]\n",
      "[Epoch 18/200] [Batch 245/815] [D loss: -6.507469] [G loss: -13.172015]\n",
      "[Epoch 18/200] [Batch 250/815] [D loss: -5.414219] [G loss: -16.851994]\n",
      "[Epoch 18/200] [Batch 255/815] [D loss: -5.258485] [G loss: -19.783455]\n",
      "[Epoch 18/200] [Batch 260/815] [D loss: -5.183505] [G loss: -13.271847]\n",
      "[Epoch 18/200] [Batch 265/815] [D loss: -5.968186] [G loss: -14.147410]\n",
      "[Epoch 18/200] [Batch 270/815] [D loss: -4.760611] [G loss: -18.650337]\n",
      "[Epoch 18/200] [Batch 275/815] [D loss: -5.357806] [G loss: -18.012896]\n",
      "[Epoch 18/200] [Batch 280/815] [D loss: -4.992748] [G loss: -20.915352]\n",
      "[Epoch 18/200] [Batch 285/815] [D loss: -6.127809] [G loss: -11.904389]\n",
      "[Epoch 18/200] [Batch 290/815] [D loss: -5.928132] [G loss: -18.618223]\n",
      "[Epoch 18/200] [Batch 295/815] [D loss: -5.589688] [G loss: -24.514011]\n",
      "[Epoch 18/200] [Batch 300/815] [D loss: -5.409024] [G loss: -18.059294]\n",
      "[Epoch 18/200] [Batch 305/815] [D loss: -5.885686] [G loss: -18.262651]\n",
      "[Epoch 18/200] [Batch 310/815] [D loss: -5.973979] [G loss: -17.421598]\n",
      "[Epoch 18/200] [Batch 315/815] [D loss: -5.029020] [G loss: -21.463739]\n",
      "[Epoch 18/200] [Batch 320/815] [D loss: -5.101144] [G loss: -16.272923]\n",
      "[Epoch 18/200] [Batch 325/815] [D loss: -5.259665] [G loss: -17.235668]\n",
      "[Epoch 18/200] [Batch 330/815] [D loss: -5.873890] [G loss: -22.115578]\n",
      "[Epoch 18/200] [Batch 335/815] [D loss: -5.193772] [G loss: -16.177486]\n",
      "[Epoch 18/200] [Batch 340/815] [D loss: -5.799809] [G loss: -18.958952]\n",
      "[Epoch 18/200] [Batch 345/815] [D loss: -7.147572] [G loss: -14.149598]\n",
      "[Epoch 18/200] [Batch 350/815] [D loss: -5.122190] [G loss: -22.504045]\n",
      "[Epoch 18/200] [Batch 355/815] [D loss: -6.019796] [G loss: -16.480509]\n",
      "[Epoch 18/200] [Batch 360/815] [D loss: -6.140898] [G loss: -16.548395]\n",
      "[Epoch 18/200] [Batch 365/815] [D loss: -5.982683] [G loss: -17.856993]\n",
      "[Epoch 18/200] [Batch 370/815] [D loss: -6.106380] [G loss: -19.063389]\n",
      "[Epoch 18/200] [Batch 375/815] [D loss: -5.047655] [G loss: -25.303896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 380/815] [D loss: -6.117192] [G loss: -13.181751]\n",
      "[Epoch 18/200] [Batch 385/815] [D loss: -6.216655] [G loss: -25.356594]\n",
      "[Epoch 18/200] [Batch 390/815] [D loss: -6.607970] [G loss: -15.401987]\n",
      "[Epoch 18/200] [Batch 395/815] [D loss: -5.264766] [G loss: -19.231026]\n",
      "[Epoch 18/200] [Batch 400/815] [D loss: -5.197404] [G loss: -24.621012]\n",
      "[Epoch 18/200] [Batch 405/815] [D loss: -5.745779] [G loss: -14.986821]\n",
      "[Epoch 18/200] [Batch 410/815] [D loss: -5.127706] [G loss: -19.771685]\n",
      "[Epoch 18/200] [Batch 415/815] [D loss: -6.072070] [G loss: -19.228039]\n",
      "[Epoch 18/200] [Batch 420/815] [D loss: -5.830858] [G loss: -15.411557]\n",
      "[Epoch 18/200] [Batch 425/815] [D loss: -5.946080] [G loss: -18.026047]\n",
      "[Epoch 18/200] [Batch 430/815] [D loss: -5.646894] [G loss: -16.313074]\n",
      "[Epoch 18/200] [Batch 435/815] [D loss: -4.719562] [G loss: -22.486719]\n",
      "[Epoch 18/200] [Batch 440/815] [D loss: -5.801992] [G loss: -16.109726]\n",
      "[Epoch 18/200] [Batch 445/815] [D loss: -2.482814] [G loss: -24.809273]\n",
      "[Epoch 18/200] [Batch 450/815] [D loss: -4.739624] [G loss: -17.739313]\n",
      "[Epoch 18/200] [Batch 455/815] [D loss: -6.100282] [G loss: -20.250830]\n",
      "[Epoch 18/200] [Batch 460/815] [D loss: -4.629180] [G loss: -42.281517]\n",
      "[Epoch 18/200] [Batch 465/815] [D loss: -4.176979] [G loss: -31.940136]\n",
      "[Epoch 18/200] [Batch 470/815] [D loss: -4.383971] [G loss: -28.243021]\n",
      "[Epoch 18/200] [Batch 475/815] [D loss: -4.165341] [G loss: -24.878046]\n",
      "[Epoch 18/200] [Batch 480/815] [D loss: -4.268343] [G loss: -25.350248]\n",
      "[Epoch 18/200] [Batch 485/815] [D loss: -5.046259] [G loss: -15.831335]\n",
      "[Epoch 18/200] [Batch 490/815] [D loss: -5.515926] [G loss: -13.627284]\n",
      "[Epoch 18/200] [Batch 495/815] [D loss: -4.866572] [G loss: -13.805769]\n",
      "[Epoch 18/200] [Batch 500/815] [D loss: -5.731847] [G loss: -12.321485]\n",
      "[Epoch 18/200] [Batch 505/815] [D loss: -6.234555] [G loss: -13.299902]\n",
      "[Epoch 18/200] [Batch 510/815] [D loss: -5.077759] [G loss: -15.451867]\n",
      "[Epoch 18/200] [Batch 515/815] [D loss: -4.639668] [G loss: -30.945669]\n",
      "[Epoch 18/200] [Batch 520/815] [D loss: -4.851563] [G loss: -17.319794]\n",
      "[Epoch 18/200] [Batch 525/815] [D loss: -5.831047] [G loss: -14.516150]\n",
      "[Epoch 18/200] [Batch 530/815] [D loss: -4.832249] [G loss: -19.816694]\n",
      "[Epoch 18/200] [Batch 535/815] [D loss: -5.907974] [G loss: -18.065796]\n",
      "[Epoch 18/200] [Batch 540/815] [D loss: -4.556935] [G loss: -26.716112]\n",
      "[Epoch 18/200] [Batch 545/815] [D loss: -5.500206] [G loss: -15.158257]\n",
      "[Epoch 18/200] [Batch 550/815] [D loss: -5.195540] [G loss: -15.724397]\n",
      "[Epoch 18/200] [Batch 555/815] [D loss: -5.393730] [G loss: -14.302478]\n",
      "[Epoch 18/200] [Batch 560/815] [D loss: -5.732131] [G loss: -15.948344]\n",
      "[Epoch 18/200] [Batch 565/815] [D loss: -6.378988] [G loss: -18.785442]\n",
      "[Epoch 18/200] [Batch 570/815] [D loss: -6.597296] [G loss: -15.438330]\n",
      "[Epoch 18/200] [Batch 575/815] [D loss: -6.144385] [G loss: -14.307073]\n",
      "[Epoch 18/200] [Batch 580/815] [D loss: -5.369184] [G loss: -11.682945]\n",
      "[Epoch 18/200] [Batch 585/815] [D loss: -5.454946] [G loss: -15.939490]\n",
      "[Epoch 18/200] [Batch 590/815] [D loss: -4.690337] [G loss: -23.662756]\n",
      "[Epoch 18/200] [Batch 595/815] [D loss: -6.023602] [G loss: -14.211209]\n",
      "[Epoch 18/200] [Batch 600/815] [D loss: -5.638648] [G loss: -17.343781]\n",
      "[Epoch 18/200] [Batch 605/815] [D loss: -5.723676] [G loss: -14.137319]\n",
      "[Epoch 18/200] [Batch 610/815] [D loss: -5.990384] [G loss: -14.823465]\n",
      "[Epoch 18/200] [Batch 615/815] [D loss: -6.186791] [G loss: -14.783443]\n",
      "[Epoch 18/200] [Batch 620/815] [D loss: -5.006886] [G loss: -18.599318]\n",
      "[Epoch 18/200] [Batch 625/815] [D loss: -5.325385] [G loss: -22.575541]\n",
      "[Epoch 18/200] [Batch 630/815] [D loss: -5.946989] [G loss: -12.189915]\n",
      "[Epoch 18/200] [Batch 635/815] [D loss: -6.144356] [G loss: -14.953707]\n",
      "[Epoch 18/200] [Batch 640/815] [D loss: -5.714288] [G loss: -28.498537]\n",
      "[Epoch 18/200] [Batch 645/815] [D loss: -5.181361] [G loss: -18.739563]\n",
      "[Epoch 18/200] [Batch 650/815] [D loss: -5.523942] [G loss: -16.093914]\n",
      "[Epoch 18/200] [Batch 655/815] [D loss: -5.421974] [G loss: -16.785334]\n",
      "[Epoch 18/200] [Batch 660/815] [D loss: -5.793176] [G loss: -18.715567]\n",
      "[Epoch 18/200] [Batch 665/815] [D loss: -6.005235] [G loss: -13.440384]\n",
      "[Epoch 18/200] [Batch 670/815] [D loss: -5.319633] [G loss: -19.833717]\n",
      "[Epoch 18/200] [Batch 675/815] [D loss: -5.668994] [G loss: -12.309563]\n",
      "[Epoch 18/200] [Batch 680/815] [D loss: -6.115105] [G loss: -14.666589]\n",
      "[Epoch 18/200] [Batch 685/815] [D loss: -4.839784] [G loss: -20.649744]\n",
      "[Epoch 18/200] [Batch 690/815] [D loss: -4.435428] [G loss: -30.421686]\n",
      "[Epoch 18/200] [Batch 695/815] [D loss: -5.495600] [G loss: -16.767336]\n",
      "[Epoch 18/200] [Batch 700/815] [D loss: -4.426234] [G loss: -19.437157]\n",
      "[Epoch 18/200] [Batch 705/815] [D loss: -3.125634] [G loss: -33.295650]\n",
      "[Epoch 18/200] [Batch 710/815] [D loss: -5.664740] [G loss: -17.090584]\n",
      "[Epoch 18/200] [Batch 715/815] [D loss: -6.471392] [G loss: -15.555705]\n",
      "[Epoch 18/200] [Batch 720/815] [D loss: -6.223843] [G loss: -17.560696]\n",
      "[Epoch 18/200] [Batch 725/815] [D loss: -5.047695] [G loss: -14.458040]\n",
      "[Epoch 18/200] [Batch 730/815] [D loss: -5.780571] [G loss: -13.672599]\n",
      "[Epoch 18/200] [Batch 735/815] [D loss: -4.826543] [G loss: -31.022020]\n",
      "[Epoch 18/200] [Batch 740/815] [D loss: -5.086535] [G loss: -16.278528]\n",
      "[Epoch 18/200] [Batch 745/815] [D loss: -5.157073] [G loss: -24.339243]\n",
      "[Epoch 18/200] [Batch 750/815] [D loss: -5.642150] [G loss: -14.166083]\n",
      "[Epoch 18/200] [Batch 755/815] [D loss: -6.471437] [G loss: -15.506989]\n",
      "[Epoch 18/200] [Batch 760/815] [D loss: -6.274274] [G loss: -16.790945]\n",
      "[Epoch 18/200] [Batch 765/815] [D loss: -5.453336] [G loss: -16.431608]\n",
      "[Epoch 18/200] [Batch 770/815] [D loss: -5.131716] [G loss: -16.937256]\n",
      "[Epoch 18/200] [Batch 775/815] [D loss: -5.584254] [G loss: -15.021295]\n",
      "[Epoch 18/200] [Batch 780/815] [D loss: -5.716059] [G loss: -16.574823]\n",
      "[Epoch 18/200] [Batch 785/815] [D loss: -5.653427] [G loss: -19.730373]\n",
      "[Epoch 18/200] [Batch 790/815] [D loss: -5.160404] [G loss: -14.667285]\n",
      "[Epoch 18/200] [Batch 795/815] [D loss: -5.743847] [G loss: -13.695959]\n",
      "[Epoch 18/200] [Batch 800/815] [D loss: -5.014153] [G loss: -18.631317]\n",
      "[Epoch 18/200] [Batch 805/815] [D loss: -5.699524] [G loss: -16.883070]\n",
      "[Epoch 18/200] [Batch 810/815] [D loss: -5.661950] [G loss: -11.646342]\n",
      "[Epoch 19/200] [Batch 0/815] [D loss: -4.562959] [G loss: -24.492300]\n",
      "[Epoch 19/200] [Batch 5/815] [D loss: -5.787612] [G loss: -14.249264]\n",
      "[Epoch 19/200] [Batch 10/815] [D loss: -4.921515] [G loss: -19.773829]\n",
      "[Epoch 19/200] [Batch 15/815] [D loss: -5.101952] [G loss: -14.974274]\n",
      "[Epoch 19/200] [Batch 20/815] [D loss: -6.643644] [G loss: -13.816460]\n",
      "[Epoch 19/200] [Batch 25/815] [D loss: -7.342547] [G loss: -13.479002]\n",
      "[Epoch 19/200] [Batch 30/815] [D loss: -4.952197] [G loss: -16.465117]\n",
      "[Epoch 19/200] [Batch 35/815] [D loss: -5.298127] [G loss: -23.363150]\n",
      "[Epoch 19/200] [Batch 40/815] [D loss: -5.209877] [G loss: -17.466421]\n",
      "[Epoch 19/200] [Batch 45/815] [D loss: -5.204906] [G loss: -13.548123]\n",
      "[Epoch 19/200] [Batch 50/815] [D loss: -6.108774] [G loss: -26.710773]\n",
      "[Epoch 19/200] [Batch 55/815] [D loss: -5.629046] [G loss: -17.539402]\n",
      "[Epoch 19/200] [Batch 60/815] [D loss: -5.509638] [G loss: -17.051062]\n",
      "[Epoch 19/200] [Batch 65/815] [D loss: -5.500684] [G loss: -13.010262]\n",
      "[Epoch 19/200] [Batch 70/815] [D loss: -5.603498] [G loss: -17.346827]\n",
      "[Epoch 19/200] [Batch 75/815] [D loss: -6.124369] [G loss: -11.470067]\n",
      "[Epoch 19/200] [Batch 80/815] [D loss: -5.203924] [G loss: -20.157770]\n",
      "[Epoch 19/200] [Batch 85/815] [D loss: -5.853248] [G loss: -13.515635]\n",
      "[Epoch 19/200] [Batch 90/815] [D loss: -7.016382] [G loss: -15.890370]\n",
      "[Epoch 19/200] [Batch 95/815] [D loss: -7.868064] [G loss: -13.363720]\n",
      "[Epoch 19/200] [Batch 100/815] [D loss: -6.634651] [G loss: -15.001229]\n",
      "[Epoch 19/200] [Batch 105/815] [D loss: -5.934079] [G loss: -12.803074]\n",
      "[Epoch 19/200] [Batch 110/815] [D loss: -6.280907] [G loss: -16.265955]\n",
      "[Epoch 19/200] [Batch 115/815] [D loss: -6.108765] [G loss: -12.009953]\n",
      "[Epoch 19/200] [Batch 120/815] [D loss: -4.864836] [G loss: -22.487783]\n",
      "[Epoch 19/200] [Batch 125/815] [D loss: -5.873489] [G loss: -15.288546]\n",
      "[Epoch 19/200] [Batch 130/815] [D loss: -5.099566] [G loss: -13.246031]\n",
      "[Epoch 19/200] [Batch 135/815] [D loss: -4.925430] [G loss: -17.257128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 140/815] [D loss: -6.295141] [G loss: -15.062346]\n",
      "[Epoch 19/200] [Batch 145/815] [D loss: -5.266321] [G loss: -18.967859]\n",
      "[Epoch 19/200] [Batch 150/815] [D loss: -5.551198] [G loss: -15.960273]\n",
      "[Epoch 19/200] [Batch 155/815] [D loss: -5.713019] [G loss: -24.196951]\n",
      "[Epoch 19/200] [Batch 160/815] [D loss: -5.087792] [G loss: -16.170612]\n",
      "[Epoch 19/200] [Batch 165/815] [D loss: -5.819303] [G loss: -23.577297]\n",
      "[Epoch 19/200] [Batch 170/815] [D loss: -6.481251] [G loss: -13.051396]\n",
      "[Epoch 19/200] [Batch 175/815] [D loss: -6.175012] [G loss: -15.228431]\n",
      "[Epoch 19/200] [Batch 180/815] [D loss: -4.703583] [G loss: -18.526989]\n",
      "[Epoch 19/200] [Batch 185/815] [D loss: -4.389179] [G loss: -29.686554]\n",
      "[Epoch 19/200] [Batch 190/815] [D loss: -5.120086] [G loss: -13.780809]\n",
      "[Epoch 19/200] [Batch 195/815] [D loss: -4.802000] [G loss: -21.197218]\n",
      "[Epoch 19/200] [Batch 200/815] [D loss: -5.417422] [G loss: -16.286642]\n",
      "[Epoch 19/200] [Batch 205/815] [D loss: -6.014199] [G loss: -12.680634]\n",
      "[Epoch 19/200] [Batch 210/815] [D loss: -5.268593] [G loss: -19.878590]\n",
      "[Epoch 19/200] [Batch 215/815] [D loss: -6.251995] [G loss: -13.957664]\n",
      "[Epoch 19/200] [Batch 220/815] [D loss: -5.292253] [G loss: -17.227192]\n",
      "[Epoch 19/200] [Batch 225/815] [D loss: -5.563009] [G loss: -18.481836]\n",
      "[Epoch 19/200] [Batch 230/815] [D loss: -7.121342] [G loss: -11.467954]\n",
      "[Epoch 19/200] [Batch 235/815] [D loss: -5.954534] [G loss: -12.790781]\n",
      "[Epoch 19/200] [Batch 240/815] [D loss: -5.440349] [G loss: -19.057817]\n",
      "[Epoch 19/200] [Batch 245/815] [D loss: -5.222406] [G loss: -15.931310]\n",
      "[Epoch 19/200] [Batch 250/815] [D loss: -5.003940] [G loss: -20.437422]\n",
      "[Epoch 19/200] [Batch 255/815] [D loss: -5.187463] [G loss: -20.178883]\n",
      "[Epoch 19/200] [Batch 260/815] [D loss: -4.610957] [G loss: -15.573243]\n",
      "[Epoch 19/200] [Batch 265/815] [D loss: -4.825009] [G loss: -22.001396]\n",
      "[Epoch 19/200] [Batch 270/815] [D loss: -5.875419] [G loss: -12.907602]\n",
      "[Epoch 19/200] [Batch 275/815] [D loss: -5.615293] [G loss: -15.920247]\n",
      "[Epoch 19/200] [Batch 280/815] [D loss: -5.134374] [G loss: -21.874985]\n",
      "[Epoch 19/200] [Batch 285/815] [D loss: -5.355979] [G loss: -15.701004]\n",
      "[Epoch 19/200] [Batch 290/815] [D loss: -5.661419] [G loss: -13.907821]\n",
      "[Epoch 19/200] [Batch 295/815] [D loss: -5.825584] [G loss: -18.776188]\n",
      "[Epoch 19/200] [Batch 300/815] [D loss: -5.396704] [G loss: -12.454465]\n",
      "[Epoch 19/200] [Batch 305/815] [D loss: -6.498860] [G loss: -20.438507]\n",
      "[Epoch 19/200] [Batch 310/815] [D loss: -5.097207] [G loss: -17.668251]\n",
      "[Epoch 19/200] [Batch 315/815] [D loss: -5.970731] [G loss: -17.168339]\n",
      "[Epoch 19/200] [Batch 320/815] [D loss: -6.015457] [G loss: -23.770849]\n",
      "[Epoch 19/200] [Batch 325/815] [D loss: -3.048504] [G loss: -31.909311]\n",
      "[Epoch 19/200] [Batch 330/815] [D loss: -5.665862] [G loss: -14.504805]\n",
      "[Epoch 19/200] [Batch 335/815] [D loss: -4.670567] [G loss: -18.722965]\n",
      "[Epoch 19/200] [Batch 340/815] [D loss: -5.013416] [G loss: -17.141966]\n",
      "[Epoch 19/200] [Batch 345/815] [D loss: -6.819225] [G loss: -21.082066]\n",
      "[Epoch 19/200] [Batch 350/815] [D loss: -5.217888] [G loss: -27.272192]\n",
      "[Epoch 19/200] [Batch 355/815] [D loss: -5.534845] [G loss: -20.791901]\n",
      "[Epoch 19/200] [Batch 360/815] [D loss: -5.423794] [G loss: -15.606964]\n",
      "[Epoch 19/200] [Batch 365/815] [D loss: -4.968552] [G loss: -16.250257]\n",
      "[Epoch 19/200] [Batch 370/815] [D loss: -5.596388] [G loss: -30.420462]\n",
      "[Epoch 19/200] [Batch 375/815] [D loss: -4.912530] [G loss: -19.713995]\n",
      "[Epoch 19/200] [Batch 380/815] [D loss: -4.743182] [G loss: -20.063442]\n",
      "[Epoch 19/200] [Batch 385/815] [D loss: -4.875722] [G loss: -20.297606]\n",
      "[Epoch 19/200] [Batch 390/815] [D loss: -4.960901] [G loss: -18.550148]\n",
      "[Epoch 19/200] [Batch 395/815] [D loss: -5.423739] [G loss: -18.673161]\n",
      "[Epoch 19/200] [Batch 400/815] [D loss: -5.793863] [G loss: -11.995625]\n",
      "[Epoch 19/200] [Batch 405/815] [D loss: -4.362043] [G loss: -21.768789]\n",
      "[Epoch 19/200] [Batch 410/815] [D loss: -5.652315] [G loss: -17.323704]\n",
      "[Epoch 19/200] [Batch 415/815] [D loss: -7.195609] [G loss: -17.547701]\n",
      "[Epoch 19/200] [Batch 420/815] [D loss: -5.398117] [G loss: -21.277643]\n",
      "[Epoch 19/200] [Batch 425/815] [D loss: -6.216581] [G loss: -15.134829]\n",
      "[Epoch 19/200] [Batch 430/815] [D loss: -5.429788] [G loss: -18.226547]\n",
      "[Epoch 19/200] [Batch 435/815] [D loss: -4.617735] [G loss: -18.038795]\n",
      "[Epoch 19/200] [Batch 440/815] [D loss: -4.707419] [G loss: -34.984669]\n",
      "[Epoch 19/200] [Batch 445/815] [D loss: -4.555410] [G loss: -21.189220]\n",
      "[Epoch 19/200] [Batch 450/815] [D loss: -5.681015] [G loss: -13.671620]\n",
      "[Epoch 19/200] [Batch 455/815] [D loss: -5.197031] [G loss: -16.295210]\n",
      "[Epoch 19/200] [Batch 460/815] [D loss: -6.907300] [G loss: -12.308714]\n",
      "[Epoch 19/200] [Batch 465/815] [D loss: -5.518554] [G loss: -18.117701]\n",
      "[Epoch 19/200] [Batch 470/815] [D loss: -5.757886] [G loss: -16.982178]\n",
      "[Epoch 19/200] [Batch 475/815] [D loss: -5.916625] [G loss: -14.403356]\n",
      "[Epoch 19/200] [Batch 480/815] [D loss: -4.623744] [G loss: -29.905609]\n",
      "[Epoch 19/200] [Batch 485/815] [D loss: -5.733903] [G loss: -18.185364]\n",
      "[Epoch 19/200] [Batch 490/815] [D loss: -5.983091] [G loss: -11.571817]\n",
      "[Epoch 19/200] [Batch 495/815] [D loss: -5.669998] [G loss: -17.112198]\n",
      "[Epoch 19/200] [Batch 500/815] [D loss: -5.407237] [G loss: -16.665537]\n",
      "[Epoch 19/200] [Batch 505/815] [D loss: -4.648778] [G loss: -16.527851]\n",
      "[Epoch 19/200] [Batch 510/815] [D loss: -5.111928] [G loss: -18.447018]\n",
      "[Epoch 19/200] [Batch 515/815] [D loss: -4.794420] [G loss: -20.180029]\n",
      "[Epoch 19/200] [Batch 520/815] [D loss: -6.291049] [G loss: -15.819468]\n",
      "[Epoch 19/200] [Batch 525/815] [D loss: -5.172083] [G loss: -16.801849]\n",
      "[Epoch 19/200] [Batch 530/815] [D loss: -5.406917] [G loss: -16.856840]\n",
      "[Epoch 19/200] [Batch 535/815] [D loss: -6.243298] [G loss: -19.711809]\n",
      "[Epoch 19/200] [Batch 540/815] [D loss: -5.270048] [G loss: -13.487998]\n",
      "[Epoch 19/200] [Batch 545/815] [D loss: -5.170251] [G loss: -15.391355]\n",
      "[Epoch 19/200] [Batch 550/815] [D loss: -5.205272] [G loss: -16.523315]\n",
      "[Epoch 19/200] [Batch 555/815] [D loss: -6.163674] [G loss: -11.652004]\n",
      "[Epoch 19/200] [Batch 560/815] [D loss: -6.128596] [G loss: -12.557285]\n",
      "[Epoch 19/200] [Batch 565/815] [D loss: -5.601661] [G loss: -13.539769]\n",
      "[Epoch 19/200] [Batch 570/815] [D loss: -6.055785] [G loss: -13.974859]\n",
      "[Epoch 19/200] [Batch 575/815] [D loss: -5.544338] [G loss: -23.868565]\n",
      "[Epoch 19/200] [Batch 580/815] [D loss: -4.953828] [G loss: -15.138639]\n",
      "[Epoch 19/200] [Batch 585/815] [D loss: -5.964249] [G loss: -11.753797]\n",
      "[Epoch 19/200] [Batch 590/815] [D loss: -4.433069] [G loss: -26.320166]\n",
      "[Epoch 19/200] [Batch 595/815] [D loss: -6.256224] [G loss: -13.473210]\n",
      "[Epoch 19/200] [Batch 600/815] [D loss: -5.565918] [G loss: -17.455614]\n",
      "[Epoch 19/200] [Batch 605/815] [D loss: -6.383222] [G loss: -12.568900]\n",
      "[Epoch 19/200] [Batch 610/815] [D loss: -5.001098] [G loss: -22.333536]\n",
      "[Epoch 19/200] [Batch 615/815] [D loss: -3.983533] [G loss: -22.310341]\n",
      "[Epoch 19/200] [Batch 620/815] [D loss: -5.733510] [G loss: -14.117162]\n",
      "[Epoch 19/200] [Batch 625/815] [D loss: -5.585272] [G loss: -15.478352]\n",
      "[Epoch 19/200] [Batch 630/815] [D loss: -6.712232] [G loss: -13.273943]\n",
      "[Epoch 19/200] [Batch 635/815] [D loss: -5.705706] [G loss: -17.358728]\n",
      "[Epoch 19/200] [Batch 640/815] [D loss: -6.462152] [G loss: -11.809361]\n",
      "[Epoch 19/200] [Batch 645/815] [D loss: -5.033652] [G loss: -17.882517]\n",
      "[Epoch 19/200] [Batch 650/815] [D loss: -4.911674] [G loss: -18.651352]\n",
      "[Epoch 19/200] [Batch 655/815] [D loss: -4.496280] [G loss: -17.699308]\n",
      "[Epoch 19/200] [Batch 660/815] [D loss: -4.763484] [G loss: -24.718290]\n",
      "[Epoch 19/200] [Batch 665/815] [D loss: -5.947909] [G loss: -20.476954]\n",
      "[Epoch 19/200] [Batch 670/815] [D loss: -5.966054] [G loss: -16.276764]\n",
      "[Epoch 19/200] [Batch 675/815] [D loss: -5.907000] [G loss: -11.909534]\n",
      "[Epoch 19/200] [Batch 680/815] [D loss: -3.695866] [G loss: -34.579952]\n",
      "[Epoch 19/200] [Batch 685/815] [D loss: -5.584644] [G loss: -17.641623]\n",
      "[Epoch 19/200] [Batch 690/815] [D loss: -5.807842] [G loss: -21.524189]\n",
      "[Epoch 19/200] [Batch 695/815] [D loss: -5.257127] [G loss: -15.397664]\n",
      "[Epoch 19/200] [Batch 700/815] [D loss: -4.603196] [G loss: -18.107759]\n",
      "[Epoch 19/200] [Batch 705/815] [D loss: -5.372846] [G loss: -11.227863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/200] [Batch 710/815] [D loss: -3.218226] [G loss: -26.027052]\n",
      "[Epoch 19/200] [Batch 715/815] [D loss: -5.317853] [G loss: -13.704456]\n",
      "[Epoch 19/200] [Batch 720/815] [D loss: -6.592959] [G loss: -12.530114]\n",
      "[Epoch 19/200] [Batch 725/815] [D loss: -5.318717] [G loss: -15.688821]\n",
      "[Epoch 19/200] [Batch 730/815] [D loss: -5.451741] [G loss: -18.760921]\n",
      "[Epoch 19/200] [Batch 735/815] [D loss: -5.593407] [G loss: -20.921762]\n",
      "[Epoch 19/200] [Batch 740/815] [D loss: -5.943789] [G loss: -14.319794]\n",
      "[Epoch 19/200] [Batch 745/815] [D loss: -4.668866] [G loss: -25.263834]\n",
      "[Epoch 19/200] [Batch 750/815] [D loss: -5.447939] [G loss: -16.421295]\n",
      "[Epoch 19/200] [Batch 755/815] [D loss: -4.760406] [G loss: -22.079065]\n",
      "[Epoch 19/200] [Batch 760/815] [D loss: -4.966136] [G loss: -22.797707]\n",
      "[Epoch 19/200] [Batch 765/815] [D loss: -5.583415] [G loss: -19.346600]\n",
      "[Epoch 19/200] [Batch 770/815] [D loss: -5.081219] [G loss: -18.160967]\n",
      "[Epoch 19/200] [Batch 775/815] [D loss: -5.726184] [G loss: -18.244127]\n",
      "[Epoch 19/200] [Batch 780/815] [D loss: -3.975135] [G loss: -15.435037]\n",
      "[Epoch 19/200] [Batch 785/815] [D loss: -5.278430] [G loss: -15.772634]\n",
      "[Epoch 19/200] [Batch 790/815] [D loss: -5.400542] [G loss: -15.824062]\n",
      "[Epoch 19/200] [Batch 795/815] [D loss: -6.671921] [G loss: -11.068209]\n",
      "[Epoch 19/200] [Batch 800/815] [D loss: -5.079156] [G loss: -26.247013]\n",
      "[Epoch 19/200] [Batch 805/815] [D loss: -5.170813] [G loss: -14.283085]\n",
      "[Epoch 19/200] [Batch 810/815] [D loss: -5.537019] [G loss: -13.589500]\n",
      "[Epoch 20/200] [Batch 0/815] [D loss: -4.766706] [G loss: -17.142056]\n",
      "[Epoch 20/200] [Batch 5/815] [D loss: -5.264340] [G loss: -22.073267]\n",
      "[Epoch 20/200] [Batch 10/815] [D loss: -6.054998] [G loss: -12.272132]\n",
      "[Epoch 20/200] [Batch 15/815] [D loss: -5.877142] [G loss: -17.985460]\n",
      "[Epoch 20/200] [Batch 20/815] [D loss: -5.174491] [G loss: -18.499773]\n",
      "[Epoch 20/200] [Batch 25/815] [D loss: -4.446870] [G loss: -16.632124]\n",
      "[Epoch 20/200] [Batch 30/815] [D loss: -5.445338] [G loss: -18.149626]\n",
      "[Epoch 20/200] [Batch 35/815] [D loss: -5.015478] [G loss: -25.931583]\n",
      "[Epoch 20/200] [Batch 40/815] [D loss: -4.367929] [G loss: -28.672049]\n",
      "[Epoch 20/200] [Batch 45/815] [D loss: -5.357583] [G loss: -16.603447]\n",
      "[Epoch 20/200] [Batch 50/815] [D loss: -5.126971] [G loss: -19.551527]\n",
      "[Epoch 20/200] [Batch 55/815] [D loss: -4.868548] [G loss: -22.633188]\n",
      "[Epoch 20/200] [Batch 60/815] [D loss: -5.445801] [G loss: -15.980528]\n",
      "[Epoch 20/200] [Batch 65/815] [D loss: -4.999125] [G loss: -25.988989]\n",
      "[Epoch 20/200] [Batch 70/815] [D loss: -5.779044] [G loss: -13.298865]\n",
      "[Epoch 20/200] [Batch 75/815] [D loss: -5.625973] [G loss: -12.152322]\n",
      "[Epoch 20/200] [Batch 80/815] [D loss: -4.871742] [G loss: -15.375996]\n",
      "[Epoch 20/200] [Batch 85/815] [D loss: -5.662384] [G loss: -18.945404]\n",
      "[Epoch 20/200] [Batch 90/815] [D loss: -6.457853] [G loss: -19.475891]\n",
      "[Epoch 20/200] [Batch 95/815] [D loss: -5.159701] [G loss: -19.828501]\n",
      "[Epoch 20/200] [Batch 100/815] [D loss: -6.115374] [G loss: -9.730292]\n",
      "[Epoch 20/200] [Batch 105/815] [D loss: -6.457013] [G loss: -15.995054]\n",
      "[Epoch 20/200] [Batch 110/815] [D loss: -5.230260] [G loss: -33.743801]\n",
      "[Epoch 20/200] [Batch 115/815] [D loss: -4.552282] [G loss: -11.717832]\n",
      "[Epoch 20/200] [Batch 120/815] [D loss: -5.763951] [G loss: -13.206526]\n",
      "[Epoch 20/200] [Batch 125/815] [D loss: -5.205547] [G loss: -16.962023]\n",
      "[Epoch 20/200] [Batch 130/815] [D loss: -5.841676] [G loss: -19.999611]\n",
      "[Epoch 20/200] [Batch 135/815] [D loss: -5.632739] [G loss: -16.489544]\n",
      "[Epoch 20/200] [Batch 140/815] [D loss: -5.343229] [G loss: -21.660570]\n",
      "[Epoch 20/200] [Batch 145/815] [D loss: -5.137852] [G loss: -15.780394]\n",
      "[Epoch 20/200] [Batch 150/815] [D loss: -5.763128] [G loss: -19.724728]\n",
      "[Epoch 20/200] [Batch 155/815] [D loss: -6.134490] [G loss: -12.838863]\n",
      "[Epoch 20/200] [Batch 160/815] [D loss: -5.641955] [G loss: -13.075985]\n",
      "[Epoch 20/200] [Batch 165/815] [D loss: -6.155549] [G loss: -15.293954]\n",
      "[Epoch 20/200] [Batch 170/815] [D loss: -5.568731] [G loss: -18.615950]\n",
      "[Epoch 20/200] [Batch 175/815] [D loss: -6.005406] [G loss: -21.951473]\n",
      "[Epoch 20/200] [Batch 180/815] [D loss: -4.935748] [G loss: -19.336761]\n",
      "[Epoch 20/200] [Batch 185/815] [D loss: -6.379322] [G loss: -9.847148]\n",
      "[Epoch 20/200] [Batch 190/815] [D loss: -4.825861] [G loss: -16.933807]\n",
      "[Epoch 20/200] [Batch 195/815] [D loss: -5.506691] [G loss: -12.755042]\n",
      "[Epoch 20/200] [Batch 200/815] [D loss: -4.547124] [G loss: -28.920326]\n",
      "[Epoch 20/200] [Batch 205/815] [D loss: -5.247504] [G loss: -19.242641]\n",
      "[Epoch 20/200] [Batch 210/815] [D loss: -4.570478] [G loss: -20.704975]\n",
      "[Epoch 20/200] [Batch 215/815] [D loss: -5.587449] [G loss: -14.099289]\n",
      "[Epoch 20/200] [Batch 220/815] [D loss: -5.080556] [G loss: -14.434344]\n",
      "[Epoch 20/200] [Batch 225/815] [D loss: -6.513948] [G loss: -15.692611]\n",
      "[Epoch 20/200] [Batch 230/815] [D loss: -5.444892] [G loss: -13.882552]\n",
      "[Epoch 20/200] [Batch 235/815] [D loss: -5.868695] [G loss: -12.568291]\n",
      "[Epoch 20/200] [Batch 240/815] [D loss: -5.615170] [G loss: -15.170134]\n",
      "[Epoch 20/200] [Batch 245/815] [D loss: -4.385785] [G loss: -22.421965]\n",
      "[Epoch 20/200] [Batch 250/815] [D loss: -4.856905] [G loss: -16.851397]\n",
      "[Epoch 20/200] [Batch 255/815] [D loss: -5.917503] [G loss: -14.821356]\n",
      "[Epoch 20/200] [Batch 260/815] [D loss: -5.076219] [G loss: -12.936577]\n",
      "[Epoch 20/200] [Batch 265/815] [D loss: -4.984461] [G loss: -25.600842]\n",
      "[Epoch 20/200] [Batch 270/815] [D loss: -5.149631] [G loss: -13.440937]\n",
      "[Epoch 20/200] [Batch 275/815] [D loss: -5.527200] [G loss: -20.547747]\n",
      "[Epoch 20/200] [Batch 280/815] [D loss: -5.333794] [G loss: -23.121742]\n",
      "[Epoch 20/200] [Batch 285/815] [D loss: -5.566432] [G loss: -20.796101]\n",
      "[Epoch 20/200] [Batch 290/815] [D loss: -4.809104] [G loss: -17.104553]\n",
      "[Epoch 20/200] [Batch 295/815] [D loss: -5.145229] [G loss: -14.513420]\n",
      "[Epoch 20/200] [Batch 300/815] [D loss: -5.355791] [G loss: -16.613689]\n",
      "[Epoch 20/200] [Batch 305/815] [D loss: -5.797507] [G loss: -16.977777]\n",
      "[Epoch 20/200] [Batch 310/815] [D loss: -5.016325] [G loss: -18.364384]\n",
      "[Epoch 20/200] [Batch 315/815] [D loss: -6.027742] [G loss: -14.653875]\n",
      "[Epoch 20/200] [Batch 320/815] [D loss: -4.879704] [G loss: -31.214542]\n",
      "[Epoch 20/200] [Batch 325/815] [D loss: -5.332828] [G loss: -12.675036]\n",
      "[Epoch 20/200] [Batch 330/815] [D loss: -5.460971] [G loss: -27.453545]\n",
      "[Epoch 20/200] [Batch 335/815] [D loss: -4.639557] [G loss: -20.247944]\n",
      "[Epoch 20/200] [Batch 340/815] [D loss: -5.131980] [G loss: -16.510605]\n",
      "[Epoch 20/200] [Batch 345/815] [D loss: -5.484717] [G loss: -15.738937]\n",
      "[Epoch 20/200] [Batch 350/815] [D loss: -4.909135] [G loss: -24.211670]\n",
      "[Epoch 20/200] [Batch 355/815] [D loss: -5.847540] [G loss: -14.436307]\n",
      "[Epoch 20/200] [Batch 360/815] [D loss: -5.578238] [G loss: -12.744637]\n",
      "[Epoch 20/200] [Batch 365/815] [D loss: -4.235634] [G loss: -20.676479]\n",
      "[Epoch 20/200] [Batch 370/815] [D loss: -5.642245] [G loss: -16.968107]\n",
      "[Epoch 20/200] [Batch 375/815] [D loss: -6.053110] [G loss: -13.452672]\n",
      "[Epoch 20/200] [Batch 380/815] [D loss: -5.198078] [G loss: -21.731253]\n",
      "[Epoch 20/200] [Batch 385/815] [D loss: -6.666697] [G loss: -12.067356]\n",
      "[Epoch 20/200] [Batch 390/815] [D loss: -6.621756] [G loss: -11.380628]\n",
      "[Epoch 20/200] [Batch 395/815] [D loss: -5.910784] [G loss: -23.979120]\n",
      "[Epoch 20/200] [Batch 400/815] [D loss: -5.350045] [G loss: -19.457113]\n",
      "[Epoch 20/200] [Batch 405/815] [D loss: -5.818237] [G loss: -16.698717]\n",
      "[Epoch 20/200] [Batch 410/815] [D loss: -6.450610] [G loss: -13.174322]\n",
      "[Epoch 20/200] [Batch 415/815] [D loss: -5.456686] [G loss: -12.567623]\n",
      "[Epoch 20/200] [Batch 420/815] [D loss: -5.050236] [G loss: -14.012444]\n",
      "[Epoch 20/200] [Batch 425/815] [D loss: -6.412791] [G loss: -12.145330]\n",
      "[Epoch 20/200] [Batch 430/815] [D loss: -4.515298] [G loss: -26.115055]\n",
      "[Epoch 20/200] [Batch 435/815] [D loss: -5.787133] [G loss: -17.466600]\n",
      "[Epoch 20/200] [Batch 440/815] [D loss: -4.689122] [G loss: -17.566221]\n",
      "[Epoch 20/200] [Batch 445/815] [D loss: -6.038405] [G loss: -15.994230]\n",
      "[Epoch 20/200] [Batch 450/815] [D loss: -6.247117] [G loss: -13.393316]\n",
      "[Epoch 20/200] [Batch 455/815] [D loss: -5.173403] [G loss: -15.991567]\n",
      "[Epoch 20/200] [Batch 460/815] [D loss: -5.927411] [G loss: -14.796487]\n",
      "[Epoch 20/200] [Batch 465/815] [D loss: -6.240886] [G loss: -15.453703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/200] [Batch 470/815] [D loss: -5.651774] [G loss: -21.612797]\n",
      "[Epoch 20/200] [Batch 475/815] [D loss: -5.978694] [G loss: -12.657916]\n",
      "[Epoch 20/200] [Batch 480/815] [D loss: -5.737535] [G loss: -14.218268]\n",
      "[Epoch 20/200] [Batch 485/815] [D loss: -4.918769] [G loss: -22.382710]\n",
      "[Epoch 20/200] [Batch 490/815] [D loss: -5.355941] [G loss: -15.185888]\n",
      "[Epoch 20/200] [Batch 495/815] [D loss: -5.799568] [G loss: -13.450346]\n",
      "[Epoch 20/200] [Batch 500/815] [D loss: -5.626341] [G loss: -14.147092]\n",
      "[Epoch 20/200] [Batch 505/815] [D loss: -6.348553] [G loss: -13.932526]\n",
      "[Epoch 20/200] [Batch 510/815] [D loss: -5.776395] [G loss: -16.122986]\n",
      "[Epoch 20/200] [Batch 515/815] [D loss: -5.664659] [G loss: -16.616510]\n",
      "[Epoch 20/200] [Batch 520/815] [D loss: -5.700538] [G loss: -18.252224]\n",
      "[Epoch 20/200] [Batch 525/815] [D loss: -5.435332] [G loss: -23.372334]\n",
      "[Epoch 20/200] [Batch 530/815] [D loss: -5.164158] [G loss: -12.155042]\n",
      "[Epoch 20/200] [Batch 535/815] [D loss: -5.585241] [G loss: -12.542412]\n",
      "[Epoch 20/200] [Batch 540/815] [D loss: -5.498013] [G loss: -13.670103]\n",
      "[Epoch 20/200] [Batch 545/815] [D loss: -6.259254] [G loss: -13.646132]\n",
      "[Epoch 20/200] [Batch 550/815] [D loss: -4.664772] [G loss: -30.160269]\n",
      "[Epoch 20/200] [Batch 555/815] [D loss: -5.141105] [G loss: -18.018808]\n",
      "[Epoch 20/200] [Batch 560/815] [D loss: -6.209656] [G loss: -13.271081]\n",
      "[Epoch 20/200] [Batch 565/815] [D loss: -5.825075] [G loss: -14.418104]\n",
      "[Epoch 20/200] [Batch 570/815] [D loss: -4.868181] [G loss: -17.449127]\n",
      "[Epoch 20/200] [Batch 575/815] [D loss: -5.381436] [G loss: -14.391654]\n",
      "[Epoch 20/200] [Batch 580/815] [D loss: -5.532800] [G loss: -15.251993]\n",
      "[Epoch 20/200] [Batch 585/815] [D loss: -6.226352] [G loss: -12.075701]\n",
      "[Epoch 20/200] [Batch 590/815] [D loss: -6.532935] [G loss: -14.127747]\n",
      "[Epoch 20/200] [Batch 595/815] [D loss: -5.396485] [G loss: -20.305431]\n",
      "[Epoch 20/200] [Batch 600/815] [D loss: -5.713281] [G loss: -26.148451]\n",
      "[Epoch 20/200] [Batch 605/815] [D loss: -5.045164] [G loss: -20.332777]\n",
      "[Epoch 20/200] [Batch 610/815] [D loss: -5.855344] [G loss: -9.674352]\n",
      "[Epoch 20/200] [Batch 615/815] [D loss: -6.463792] [G loss: -18.412100]\n",
      "[Epoch 20/200] [Batch 620/815] [D loss: -5.706521] [G loss: -15.300220]\n",
      "[Epoch 20/200] [Batch 625/815] [D loss: -5.032456] [G loss: -23.211969]\n",
      "[Epoch 20/200] [Batch 630/815] [D loss: -6.184305] [G loss: -12.958830]\n",
      "[Epoch 20/200] [Batch 635/815] [D loss: -5.038135] [G loss: -22.154427]\n",
      "[Epoch 20/200] [Batch 640/815] [D loss: -5.305131] [G loss: -12.312004]\n",
      "[Epoch 20/200] [Batch 645/815] [D loss: -6.614429] [G loss: -13.219592]\n",
      "[Epoch 20/200] [Batch 650/815] [D loss: -6.515388] [G loss: -13.429437]\n",
      "[Epoch 20/200] [Batch 655/815] [D loss: -4.814722] [G loss: -29.081930]\n",
      "[Epoch 20/200] [Batch 660/815] [D loss: -5.558289] [G loss: -16.050877]\n",
      "[Epoch 20/200] [Batch 665/815] [D loss: -5.804941] [G loss: -15.987712]\n",
      "[Epoch 20/200] [Batch 670/815] [D loss: -6.032511] [G loss: -15.300764]\n",
      "[Epoch 20/200] [Batch 675/815] [D loss: -6.112633] [G loss: -26.445213]\n",
      "[Epoch 20/200] [Batch 680/815] [D loss: -5.112842] [G loss: -19.830458]\n",
      "[Epoch 20/200] [Batch 685/815] [D loss: -5.462091] [G loss: -19.697296]\n",
      "[Epoch 20/200] [Batch 690/815] [D loss: -6.652762] [G loss: -10.492880]\n",
      "[Epoch 20/200] [Batch 695/815] [D loss: -5.286948] [G loss: -14.253242]\n",
      "[Epoch 20/200] [Batch 700/815] [D loss: -5.678155] [G loss: -16.156664]\n",
      "[Epoch 20/200] [Batch 705/815] [D loss: -4.958178] [G loss: -17.776392]\n",
      "[Epoch 20/200] [Batch 710/815] [D loss: -5.749354] [G loss: -12.734388]\n",
      "[Epoch 20/200] [Batch 715/815] [D loss: -5.687693] [G loss: -13.760491]\n",
      "[Epoch 20/200] [Batch 720/815] [D loss: -6.406598] [G loss: -17.065332]\n",
      "[Epoch 20/200] [Batch 725/815] [D loss: -5.512776] [G loss: -16.730616]\n",
      "[Epoch 20/200] [Batch 730/815] [D loss: -5.231276] [G loss: -17.137638]\n",
      "[Epoch 20/200] [Batch 735/815] [D loss: -4.773292] [G loss: -26.852505]\n",
      "[Epoch 20/200] [Batch 740/815] [D loss: -5.889344] [G loss: -15.239022]\n",
      "[Epoch 20/200] [Batch 745/815] [D loss: -5.163543] [G loss: -19.165289]\n",
      "[Epoch 20/200] [Batch 750/815] [D loss: -5.755135] [G loss: -10.763664]\n",
      "[Epoch 20/200] [Batch 755/815] [D loss: -4.901692] [G loss: -12.676196]\n",
      "[Epoch 20/200] [Batch 760/815] [D loss: -4.989356] [G loss: -13.661652]\n",
      "[Epoch 20/200] [Batch 765/815] [D loss: -5.863163] [G loss: -14.332031]\n",
      "[Epoch 20/200] [Batch 770/815] [D loss: -5.809648] [G loss: -16.868692]\n",
      "[Epoch 20/200] [Batch 775/815] [D loss: -4.992528] [G loss: -18.419203]\n",
      "[Epoch 20/200] [Batch 780/815] [D loss: -5.264447] [G loss: -12.937178]\n",
      "[Epoch 20/200] [Batch 785/815] [D loss: -6.746796] [G loss: -18.464390]\n",
      "[Epoch 20/200] [Batch 790/815] [D loss: -3.799803] [G loss: -20.208782]\n",
      "[Epoch 20/200] [Batch 795/815] [D loss: -4.918214] [G loss: -16.382206]\n",
      "[Epoch 20/200] [Batch 800/815] [D loss: -5.881658] [G loss: -13.074524]\n",
      "[Epoch 20/200] [Batch 805/815] [D loss: -4.799824] [G loss: -24.154432]\n",
      "[Epoch 20/200] [Batch 810/815] [D loss: -5.022455] [G loss: -14.094480]\n",
      "[Epoch 21/200] [Batch 0/815] [D loss: -4.901097] [G loss: -22.599955]\n",
      "[Epoch 21/200] [Batch 5/815] [D loss: -5.066127] [G loss: -16.427603]\n",
      "[Epoch 21/200] [Batch 10/815] [D loss: -5.603966] [G loss: -12.184937]\n",
      "[Epoch 21/200] [Batch 15/815] [D loss: -5.421793] [G loss: -15.309494]\n",
      "[Epoch 21/200] [Batch 20/815] [D loss: -5.367840] [G loss: -20.603432]\n",
      "[Epoch 21/200] [Batch 25/815] [D loss: -5.313597] [G loss: -18.951397]\n",
      "[Epoch 21/200] [Batch 30/815] [D loss: -5.075969] [G loss: -14.884217]\n",
      "[Epoch 21/200] [Batch 35/815] [D loss: -4.853551] [G loss: -19.981030]\n",
      "[Epoch 21/200] [Batch 40/815] [D loss: -5.383145] [G loss: -16.634190]\n",
      "[Epoch 21/200] [Batch 45/815] [D loss: -4.938955] [G loss: -21.356762]\n",
      "[Epoch 21/200] [Batch 50/815] [D loss: -5.498669] [G loss: -20.226973]\n",
      "[Epoch 21/200] [Batch 55/815] [D loss: -4.975545] [G loss: -16.061899]\n",
      "[Epoch 21/200] [Batch 60/815] [D loss: -5.881536] [G loss: -13.687783]\n",
      "[Epoch 21/200] [Batch 65/815] [D loss: -7.078714] [G loss: -14.491517]\n",
      "[Epoch 21/200] [Batch 70/815] [D loss: -4.949914] [G loss: -21.822451]\n",
      "[Epoch 21/200] [Batch 75/815] [D loss: -6.341509] [G loss: -13.480877]\n",
      "[Epoch 21/200] [Batch 80/815] [D loss: -5.967103] [G loss: -18.304050]\n",
      "[Epoch 21/200] [Batch 85/815] [D loss: -5.936756] [G loss: -16.111938]\n",
      "[Epoch 21/200] [Batch 90/815] [D loss: -5.860032] [G loss: -16.995380]\n",
      "[Epoch 21/200] [Batch 95/815] [D loss: -5.266126] [G loss: -19.409472]\n",
      "[Epoch 21/200] [Batch 100/815] [D loss: -5.934453] [G loss: -15.123707]\n",
      "[Epoch 21/200] [Batch 105/815] [D loss: -5.360114] [G loss: -16.733601]\n",
      "[Epoch 21/200] [Batch 110/815] [D loss: -5.491150] [G loss: -21.355751]\n",
      "[Epoch 21/200] [Batch 115/815] [D loss: -5.055232] [G loss: -27.540937]\n",
      "[Epoch 21/200] [Batch 120/815] [D loss: -5.238709] [G loss: -14.600115]\n",
      "[Epoch 21/200] [Batch 125/815] [D loss: -5.549062] [G loss: -16.110167]\n",
      "[Epoch 21/200] [Batch 130/815] [D loss: -5.572741] [G loss: -23.622477]\n",
      "[Epoch 21/200] [Batch 135/815] [D loss: -4.717836] [G loss: -25.157455]\n",
      "[Epoch 21/200] [Batch 140/815] [D loss: -5.574867] [G loss: -16.066605]\n",
      "[Epoch 21/200] [Batch 145/815] [D loss: -5.540852] [G loss: -15.719969]\n",
      "[Epoch 21/200] [Batch 150/815] [D loss: -5.003649] [G loss: -22.248041]\n",
      "[Epoch 21/200] [Batch 155/815] [D loss: -5.409300] [G loss: -17.722862]\n",
      "[Epoch 21/200] [Batch 160/815] [D loss: -4.740435] [G loss: -30.892218]\n",
      "[Epoch 21/200] [Batch 165/815] [D loss: -6.296900] [G loss: -17.770176]\n",
      "[Epoch 21/200] [Batch 170/815] [D loss: -5.094042] [G loss: -17.649956]\n",
      "[Epoch 21/200] [Batch 175/815] [D loss: -6.988831] [G loss: -13.569850]\n",
      "[Epoch 21/200] [Batch 180/815] [D loss: -5.329935] [G loss: -15.362715]\n",
      "[Epoch 21/200] [Batch 185/815] [D loss: -5.594104] [G loss: -18.336935]\n",
      "[Epoch 21/200] [Batch 190/815] [D loss: -5.432555] [G loss: -28.346148]\n",
      "[Epoch 21/200] [Batch 195/815] [D loss: -5.108839] [G loss: -21.386232]\n",
      "[Epoch 21/200] [Batch 200/815] [D loss: -5.081667] [G loss: -18.343103]\n",
      "[Epoch 21/200] [Batch 205/815] [D loss: -5.747317] [G loss: -23.637508]\n",
      "[Epoch 21/200] [Batch 210/815] [D loss: -5.853147] [G loss: -17.410421]\n",
      "[Epoch 21/200] [Batch 215/815] [D loss: -5.247284] [G loss: -18.303905]\n",
      "[Epoch 21/200] [Batch 220/815] [D loss: -5.528408] [G loss: -23.346909]\n",
      "[Epoch 21/200] [Batch 225/815] [D loss: -5.806807] [G loss: -14.070073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 230/815] [D loss: -5.960214] [G loss: -12.904739]\n",
      "[Epoch 21/200] [Batch 235/815] [D loss: -5.633610] [G loss: -20.660038]\n",
      "[Epoch 21/200] [Batch 240/815] [D loss: -4.950915] [G loss: -18.209574]\n",
      "[Epoch 21/200] [Batch 245/815] [D loss: -5.088932] [G loss: -18.101845]\n",
      "[Epoch 21/200] [Batch 250/815] [D loss: -5.968928] [G loss: -15.300821]\n",
      "[Epoch 21/200] [Batch 255/815] [D loss: -6.643927] [G loss: -14.549805]\n",
      "[Epoch 21/200] [Batch 260/815] [D loss: -5.862337] [G loss: -18.890406]\n",
      "[Epoch 21/200] [Batch 265/815] [D loss: -5.369754] [G loss: -15.923957]\n",
      "[Epoch 21/200] [Batch 270/815] [D loss: -5.075815] [G loss: -20.380327]\n",
      "[Epoch 21/200] [Batch 275/815] [D loss: -5.258725] [G loss: -22.193865]\n",
      "[Epoch 21/200] [Batch 280/815] [D loss: -5.322567] [G loss: -17.344700]\n",
      "[Epoch 21/200] [Batch 285/815] [D loss: -5.701116] [G loss: -17.840471]\n",
      "[Epoch 21/200] [Batch 290/815] [D loss: -5.554647] [G loss: -14.512850]\n",
      "[Epoch 21/200] [Batch 295/815] [D loss: -5.926136] [G loss: -18.299513]\n",
      "[Epoch 21/200] [Batch 300/815] [D loss: -5.514139] [G loss: -18.287416]\n",
      "[Epoch 21/200] [Batch 305/815] [D loss: -5.210272] [G loss: -20.605024]\n",
      "[Epoch 21/200] [Batch 310/815] [D loss: -6.208052] [G loss: -18.697233]\n",
      "[Epoch 21/200] [Batch 315/815] [D loss: -6.130410] [G loss: -14.829601]\n",
      "[Epoch 21/200] [Batch 320/815] [D loss: -4.490125] [G loss: -19.999876]\n",
      "[Epoch 21/200] [Batch 325/815] [D loss: -5.441901] [G loss: -17.430656]\n",
      "[Epoch 21/200] [Batch 330/815] [D loss: -4.513761] [G loss: -25.283670]\n",
      "[Epoch 21/200] [Batch 335/815] [D loss: -5.237141] [G loss: -14.113626]\n",
      "[Epoch 21/200] [Batch 340/815] [D loss: -3.364387] [G loss: -27.173702]\n",
      "[Epoch 21/200] [Batch 345/815] [D loss: -5.379784] [G loss: -16.726629]\n",
      "[Epoch 21/200] [Batch 350/815] [D loss: -6.219346] [G loss: -16.239017]\n",
      "[Epoch 21/200] [Batch 355/815] [D loss: -4.990137] [G loss: -19.873890]\n",
      "[Epoch 21/200] [Batch 360/815] [D loss: -6.826848] [G loss: -11.487880]\n",
      "[Epoch 21/200] [Batch 365/815] [D loss: -4.282722] [G loss: -24.513895]\n",
      "[Epoch 21/200] [Batch 370/815] [D loss: -5.180439] [G loss: -14.441845]\n",
      "[Epoch 21/200] [Batch 375/815] [D loss: -4.973979] [G loss: -14.815325]\n",
      "[Epoch 21/200] [Batch 380/815] [D loss: -5.608152] [G loss: -15.569447]\n",
      "[Epoch 21/200] [Batch 385/815] [D loss: -6.080357] [G loss: -17.582304]\n",
      "[Epoch 21/200] [Batch 390/815] [D loss: -5.115622] [G loss: -19.433012]\n",
      "[Epoch 21/200] [Batch 395/815] [D loss: -5.083195] [G loss: -18.361202]\n",
      "[Epoch 21/200] [Batch 400/815] [D loss: -5.253194] [G loss: -15.628564]\n",
      "[Epoch 21/200] [Batch 405/815] [D loss: -5.464011] [G loss: -14.985841]\n",
      "[Epoch 21/200] [Batch 410/815] [D loss: -5.356777] [G loss: -19.625549]\n",
      "[Epoch 21/200] [Batch 415/815] [D loss: -5.016386] [G loss: -25.577038]\n",
      "[Epoch 21/200] [Batch 420/815] [D loss: -5.178448] [G loss: -14.709077]\n",
      "[Epoch 21/200] [Batch 425/815] [D loss: -5.906136] [G loss: -11.661752]\n",
      "[Epoch 21/200] [Batch 430/815] [D loss: -4.853426] [G loss: -16.311005]\n",
      "[Epoch 21/200] [Batch 435/815] [D loss: -5.847879] [G loss: -17.958754]\n",
      "[Epoch 21/200] [Batch 440/815] [D loss: -5.099871] [G loss: -17.260357]\n",
      "[Epoch 21/200] [Batch 445/815] [D loss: -5.826613] [G loss: -21.065849]\n",
      "[Epoch 21/200] [Batch 450/815] [D loss: -5.182443] [G loss: -23.249519]\n",
      "[Epoch 21/200] [Batch 455/815] [D loss: -5.186870] [G loss: -14.122816]\n",
      "[Epoch 21/200] [Batch 460/815] [D loss: -5.267412] [G loss: -30.980730]\n",
      "[Epoch 21/200] [Batch 465/815] [D loss: -4.950340] [G loss: -27.368578]\n",
      "[Epoch 21/200] [Batch 470/815] [D loss: -6.312303] [G loss: -14.282802]\n",
      "[Epoch 21/200] [Batch 475/815] [D loss: -4.379111] [G loss: -16.252131]\n",
      "[Epoch 21/200] [Batch 480/815] [D loss: -5.090081] [G loss: -14.665728]\n",
      "[Epoch 21/200] [Batch 485/815] [D loss: -6.559819] [G loss: -14.780701]\n",
      "[Epoch 21/200] [Batch 490/815] [D loss: -5.021402] [G loss: -20.447863]\n",
      "[Epoch 21/200] [Batch 495/815] [D loss: -5.288249] [G loss: -17.375944]\n",
      "[Epoch 21/200] [Batch 500/815] [D loss: -5.615107] [G loss: -16.618567]\n",
      "[Epoch 21/200] [Batch 505/815] [D loss: -5.847607] [G loss: -13.485255]\n",
      "[Epoch 21/200] [Batch 510/815] [D loss: -5.227943] [G loss: -23.650721]\n",
      "[Epoch 21/200] [Batch 515/815] [D loss: -5.370950] [G loss: -18.055107]\n",
      "[Epoch 21/200] [Batch 520/815] [D loss: -5.488644] [G loss: -15.493423]\n",
      "[Epoch 21/200] [Batch 525/815] [D loss: -4.594466] [G loss: -19.915508]\n",
      "[Epoch 21/200] [Batch 530/815] [D loss: -5.879025] [G loss: -16.788185]\n",
      "[Epoch 21/200] [Batch 535/815] [D loss: -5.688494] [G loss: -17.687614]\n",
      "[Epoch 21/200] [Batch 540/815] [D loss: -4.277954] [G loss: -30.239132]\n",
      "[Epoch 21/200] [Batch 545/815] [D loss: -5.988995] [G loss: -15.261769]\n",
      "[Epoch 21/200] [Batch 550/815] [D loss: -4.916759] [G loss: -14.985357]\n",
      "[Epoch 21/200] [Batch 555/815] [D loss: -4.274101] [G loss: -26.335121]\n",
      "[Epoch 21/200] [Batch 560/815] [D loss: -5.178067] [G loss: -15.634824]\n",
      "[Epoch 21/200] [Batch 565/815] [D loss: -5.627471] [G loss: -17.828072]\n",
      "[Epoch 21/200] [Batch 570/815] [D loss: -5.354172] [G loss: -17.120274]\n",
      "[Epoch 21/200] [Batch 575/815] [D loss: -5.597252] [G loss: -10.233372]\n",
      "[Epoch 21/200] [Batch 580/815] [D loss: -5.397274] [G loss: -13.526870]\n",
      "[Epoch 21/200] [Batch 585/815] [D loss: -5.200181] [G loss: -21.184494]\n",
      "[Epoch 21/200] [Batch 590/815] [D loss: -4.380933] [G loss: -35.223934]\n",
      "[Epoch 21/200] [Batch 595/815] [D loss: -5.737429] [G loss: -20.240978]\n",
      "[Epoch 21/200] [Batch 600/815] [D loss: -5.228117] [G loss: -18.587328]\n",
      "[Epoch 21/200] [Batch 605/815] [D loss: -5.663733] [G loss: -14.410389]\n",
      "[Epoch 21/200] [Batch 610/815] [D loss: -4.805676] [G loss: -17.357260]\n",
      "[Epoch 21/200] [Batch 615/815] [D loss: -5.578583] [G loss: -17.135672]\n",
      "[Epoch 21/200] [Batch 620/815] [D loss: -4.394475] [G loss: -18.796381]\n",
      "[Epoch 21/200] [Batch 625/815] [D loss: -3.913584] [G loss: -25.776991]\n",
      "[Epoch 21/200] [Batch 630/815] [D loss: -6.204759] [G loss: -18.906063]\n",
      "[Epoch 21/200] [Batch 635/815] [D loss: -5.781106] [G loss: -14.258450]\n",
      "[Epoch 21/200] [Batch 640/815] [D loss: -5.300685] [G loss: -15.507042]\n",
      "[Epoch 21/200] [Batch 645/815] [D loss: -5.185933] [G loss: -18.216494]\n",
      "[Epoch 21/200] [Batch 650/815] [D loss: -6.019074] [G loss: -15.631859]\n",
      "[Epoch 21/200] [Batch 655/815] [D loss: -5.280496] [G loss: -17.407534]\n",
      "[Epoch 21/200] [Batch 660/815] [D loss: -6.513904] [G loss: -16.394669]\n",
      "[Epoch 21/200] [Batch 665/815] [D loss: -5.896809] [G loss: -16.824842]\n",
      "[Epoch 21/200] [Batch 670/815] [D loss: -5.910764] [G loss: -20.579460]\n",
      "[Epoch 21/200] [Batch 675/815] [D loss: -6.271420] [G loss: -15.050756]\n",
      "[Epoch 21/200] [Batch 680/815] [D loss: -4.195161] [G loss: -30.229496]\n",
      "[Epoch 21/200] [Batch 685/815] [D loss: -5.103296] [G loss: -21.040674]\n",
      "[Epoch 21/200] [Batch 690/815] [D loss: -5.612726] [G loss: -14.009131]\n",
      "[Epoch 21/200] [Batch 695/815] [D loss: -5.179509] [G loss: -17.049700]\n",
      "[Epoch 21/200] [Batch 700/815] [D loss: -5.304673] [G loss: -21.466640]\n",
      "[Epoch 21/200] [Batch 705/815] [D loss: -6.034976] [G loss: -15.810026]\n",
      "[Epoch 21/200] [Batch 710/815] [D loss: -5.367898] [G loss: -16.789766]\n",
      "[Epoch 21/200] [Batch 715/815] [D loss: -4.753438] [G loss: -32.496464]\n",
      "[Epoch 21/200] [Batch 720/815] [D loss: -5.504038] [G loss: -19.928976]\n",
      "[Epoch 21/200] [Batch 725/815] [D loss: -6.124671] [G loss: -13.718076]\n",
      "[Epoch 21/200] [Batch 730/815] [D loss: -4.856440] [G loss: -26.612844]\n",
      "[Epoch 21/200] [Batch 735/815] [D loss: -5.256003] [G loss: -14.452931]\n",
      "[Epoch 21/200] [Batch 740/815] [D loss: -5.937043] [G loss: -14.114888]\n",
      "[Epoch 21/200] [Batch 745/815] [D loss: -5.719607] [G loss: -14.557539]\n",
      "[Epoch 21/200] [Batch 750/815] [D loss: -5.238646] [G loss: -17.090284]\n",
      "[Epoch 21/200] [Batch 755/815] [D loss: -5.207786] [G loss: -16.783869]\n",
      "[Epoch 21/200] [Batch 760/815] [D loss: -5.339772] [G loss: -26.860012]\n",
      "[Epoch 21/200] [Batch 765/815] [D loss: -5.502923] [G loss: -13.575964]\n",
      "[Epoch 21/200] [Batch 770/815] [D loss: -5.248046] [G loss: -22.532438]\n",
      "[Epoch 21/200] [Batch 775/815] [D loss: -6.082840] [G loss: -14.945504]\n",
      "[Epoch 21/200] [Batch 780/815] [D loss: -4.779873] [G loss: -29.736452]\n",
      "[Epoch 21/200] [Batch 785/815] [D loss: -5.101548] [G loss: -18.680641]\n",
      "[Epoch 21/200] [Batch 790/815] [D loss: -5.234297] [G loss: -23.026791]\n",
      "[Epoch 21/200] [Batch 795/815] [D loss: -5.304006] [G loss: -15.945698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 800/815] [D loss: -5.438838] [G loss: -15.468782]\n",
      "[Epoch 21/200] [Batch 805/815] [D loss: -6.407891] [G loss: -15.015821]\n",
      "[Epoch 21/200] [Batch 810/815] [D loss: -5.640358] [G loss: -17.081163]\n",
      "[Epoch 22/200] [Batch 0/815] [D loss: -4.857536] [G loss: -22.037565]\n",
      "[Epoch 22/200] [Batch 5/815] [D loss: -4.013313] [G loss: -21.635977]\n",
      "[Epoch 22/200] [Batch 10/815] [D loss: -4.770150] [G loss: -23.403393]\n",
      "[Epoch 22/200] [Batch 15/815] [D loss: -4.925762] [G loss: -13.050965]\n",
      "[Epoch 22/200] [Batch 20/815] [D loss: -5.184574] [G loss: -18.461193]\n",
      "[Epoch 22/200] [Batch 25/815] [D loss: -5.591146] [G loss: -14.527244]\n",
      "[Epoch 22/200] [Batch 30/815] [D loss: -5.092737] [G loss: -17.724247]\n",
      "[Epoch 22/200] [Batch 35/815] [D loss: -6.952991] [G loss: -18.848856]\n",
      "[Epoch 22/200] [Batch 40/815] [D loss: -5.802376] [G loss: -13.334293]\n",
      "[Epoch 22/200] [Batch 45/815] [D loss: -5.841332] [G loss: -14.324491]\n",
      "[Epoch 22/200] [Batch 50/815] [D loss: -4.877999] [G loss: -23.508535]\n",
      "[Epoch 22/200] [Batch 55/815] [D loss: -5.030735] [G loss: -17.271509]\n",
      "[Epoch 22/200] [Batch 60/815] [D loss: -5.668682] [G loss: -16.215088]\n",
      "[Epoch 22/200] [Batch 65/815] [D loss: -5.572130] [G loss: -16.089979]\n",
      "[Epoch 22/200] [Batch 70/815] [D loss: -5.542882] [G loss: -15.669121]\n",
      "[Epoch 22/200] [Batch 75/815] [D loss: -6.123690] [G loss: -16.918390]\n",
      "[Epoch 22/200] [Batch 80/815] [D loss: -6.424602] [G loss: -16.908028]\n",
      "[Epoch 22/200] [Batch 85/815] [D loss: -5.537397] [G loss: -12.991876]\n",
      "[Epoch 22/200] [Batch 90/815] [D loss: -5.119703] [G loss: -18.748018]\n",
      "[Epoch 22/200] [Batch 95/815] [D loss: -5.305678] [G loss: -18.880192]\n",
      "[Epoch 22/200] [Batch 100/815] [D loss: -4.593102] [G loss: -29.115341]\n",
      "[Epoch 22/200] [Batch 105/815] [D loss: -5.890507] [G loss: -14.189960]\n",
      "[Epoch 22/200] [Batch 110/815] [D loss: -6.617643] [G loss: -14.342821]\n",
      "[Epoch 22/200] [Batch 115/815] [D loss: -6.208065] [G loss: -19.462076]\n",
      "[Epoch 22/200] [Batch 120/815] [D loss: -4.489341] [G loss: -23.712900]\n",
      "[Epoch 22/200] [Batch 125/815] [D loss: -4.839563] [G loss: -22.356668]\n",
      "[Epoch 22/200] [Batch 130/815] [D loss: -3.836894] [G loss: -23.840893]\n",
      "[Epoch 22/200] [Batch 135/815] [D loss: -4.603825] [G loss: -19.480324]\n",
      "[Epoch 22/200] [Batch 140/815] [D loss: -6.141437] [G loss: -19.733877]\n",
      "[Epoch 22/200] [Batch 145/815] [D loss: -5.805511] [G loss: -14.730038]\n",
      "[Epoch 22/200] [Batch 150/815] [D loss: -5.381364] [G loss: -16.481964]\n",
      "[Epoch 22/200] [Batch 155/815] [D loss: -5.254334] [G loss: -22.084381]\n",
      "[Epoch 22/200] [Batch 160/815] [D loss: -6.362556] [G loss: -15.327258]\n",
      "[Epoch 22/200] [Batch 165/815] [D loss: -5.571440] [G loss: -15.762072]\n",
      "[Epoch 22/200] [Batch 170/815] [D loss: -4.380138] [G loss: -23.873224]\n",
      "[Epoch 22/200] [Batch 175/815] [D loss: -5.549885] [G loss: -16.056683]\n",
      "[Epoch 22/200] [Batch 180/815] [D loss: -5.686299] [G loss: -21.865540]\n",
      "[Epoch 22/200] [Batch 185/815] [D loss: -5.741936] [G loss: -20.163740]\n",
      "[Epoch 22/200] [Batch 190/815] [D loss: -5.487808] [G loss: -19.614716]\n",
      "[Epoch 22/200] [Batch 195/815] [D loss: -5.456082] [G loss: -20.167606]\n",
      "[Epoch 22/200] [Batch 200/815] [D loss: -6.683111] [G loss: -15.901368]\n",
      "[Epoch 22/200] [Batch 205/815] [D loss: -4.890646] [G loss: -22.823006]\n",
      "[Epoch 22/200] [Batch 210/815] [D loss: -5.306392] [G loss: -16.725096]\n",
      "[Epoch 22/200] [Batch 215/815] [D loss: -5.533916] [G loss: -22.223118]\n",
      "[Epoch 22/200] [Batch 220/815] [D loss: -7.336719] [G loss: -10.613196]\n",
      "[Epoch 22/200] [Batch 225/815] [D loss: -5.385735] [G loss: -19.453831]\n",
      "[Epoch 22/200] [Batch 230/815] [D loss: -5.662641] [G loss: -15.269736]\n",
      "[Epoch 22/200] [Batch 235/815] [D loss: -4.923380] [G loss: -17.583445]\n",
      "[Epoch 22/200] [Batch 240/815] [D loss: -5.140193] [G loss: -26.890713]\n",
      "[Epoch 22/200] [Batch 245/815] [D loss: -5.450986] [G loss: -16.721819]\n",
      "[Epoch 22/200] [Batch 250/815] [D loss: -5.714829] [G loss: -18.695190]\n",
      "[Epoch 22/200] [Batch 255/815] [D loss: -4.894713] [G loss: -28.987726]\n",
      "[Epoch 22/200] [Batch 260/815] [D loss: -5.886568] [G loss: -13.361315]\n",
      "[Epoch 22/200] [Batch 265/815] [D loss: -5.398299] [G loss: -14.825344]\n",
      "[Epoch 22/200] [Batch 270/815] [D loss: -5.067986] [G loss: -29.673658]\n",
      "[Epoch 22/200] [Batch 275/815] [D loss: -5.004868] [G loss: -16.362436]\n",
      "[Epoch 22/200] [Batch 280/815] [D loss: -4.162966] [G loss: -29.889732]\n",
      "[Epoch 22/200] [Batch 285/815] [D loss: -4.297444] [G loss: -17.449240]\n",
      "[Epoch 22/200] [Batch 290/815] [D loss: -5.427212] [G loss: -18.073517]\n",
      "[Epoch 22/200] [Batch 295/815] [D loss: -5.267746] [G loss: -13.367203]\n",
      "[Epoch 22/200] [Batch 300/815] [D loss: -5.480044] [G loss: -16.827820]\n",
      "[Epoch 22/200] [Batch 305/815] [D loss: -3.648691] [G loss: -19.982094]\n",
      "[Epoch 22/200] [Batch 310/815] [D loss: -5.804197] [G loss: -14.598334]\n",
      "[Epoch 22/200] [Batch 315/815] [D loss: -5.526203] [G loss: -19.649706]\n",
      "[Epoch 22/200] [Batch 320/815] [D loss: -6.463303] [G loss: -20.625116]\n",
      "[Epoch 22/200] [Batch 325/815] [D loss: -5.441082] [G loss: -15.904388]\n",
      "[Epoch 22/200] [Batch 330/815] [D loss: -6.499124] [G loss: -12.965760]\n",
      "[Epoch 22/200] [Batch 335/815] [D loss: -5.436288] [G loss: -15.734695]\n",
      "[Epoch 22/200] [Batch 340/815] [D loss: -5.545151] [G loss: -15.312136]\n",
      "[Epoch 22/200] [Batch 345/815] [D loss: -5.233221] [G loss: -19.404943]\n",
      "[Epoch 22/200] [Batch 350/815] [D loss: -5.021745] [G loss: -18.559679]\n",
      "[Epoch 22/200] [Batch 355/815] [D loss: -5.759144] [G loss: -16.101070]\n",
      "[Epoch 22/200] [Batch 360/815] [D loss: -4.845072] [G loss: -24.615021]\n",
      "[Epoch 22/200] [Batch 365/815] [D loss: -6.594094] [G loss: -14.435826]\n",
      "[Epoch 22/200] [Batch 370/815] [D loss: -6.490081] [G loss: -11.015021]\n",
      "[Epoch 22/200] [Batch 375/815] [D loss: -5.039275] [G loss: -13.612904]\n",
      "[Epoch 22/200] [Batch 380/815] [D loss: -4.721591] [G loss: -20.148350]\n",
      "[Epoch 22/200] [Batch 385/815] [D loss: -5.509368] [G loss: -21.232058]\n",
      "[Epoch 22/200] [Batch 390/815] [D loss: -4.932779] [G loss: -26.304272]\n",
      "[Epoch 22/200] [Batch 395/815] [D loss: -5.220572] [G loss: -14.549844]\n",
      "[Epoch 22/200] [Batch 400/815] [D loss: -5.851543] [G loss: -16.963179]\n",
      "[Epoch 22/200] [Batch 405/815] [D loss: -5.929103] [G loss: -20.008652]\n",
      "[Epoch 22/200] [Batch 410/815] [D loss: -4.925100] [G loss: -16.650093]\n",
      "[Epoch 22/200] [Batch 415/815] [D loss: -4.891295] [G loss: -19.911081]\n",
      "[Epoch 22/200] [Batch 420/815] [D loss: -6.646280] [G loss: -10.730452]\n",
      "[Epoch 22/200] [Batch 425/815] [D loss: -5.633909] [G loss: -15.915980]\n",
      "[Epoch 22/200] [Batch 430/815] [D loss: -5.252046] [G loss: -19.874941]\n",
      "[Epoch 22/200] [Batch 435/815] [D loss: -6.061431] [G loss: -13.606838]\n",
      "[Epoch 22/200] [Batch 440/815] [D loss: -4.899923] [G loss: -24.265345]\n",
      "[Epoch 22/200] [Batch 445/815] [D loss: -5.034528] [G loss: -18.260448]\n",
      "[Epoch 22/200] [Batch 450/815] [D loss: -4.663658] [G loss: -19.557238]\n",
      "[Epoch 22/200] [Batch 455/815] [D loss: -5.344276] [G loss: -13.330031]\n",
      "[Epoch 22/200] [Batch 460/815] [D loss: -5.242485] [G loss: -16.846653]\n",
      "[Epoch 22/200] [Batch 465/815] [D loss: -5.724524] [G loss: -14.298259]\n",
      "[Epoch 22/200] [Batch 470/815] [D loss: -6.831398] [G loss: -20.874695]\n",
      "[Epoch 22/200] [Batch 475/815] [D loss: -6.416505] [G loss: -18.141600]\n",
      "[Epoch 22/200] [Batch 480/815] [D loss: -6.377916] [G loss: -15.329250]\n",
      "[Epoch 22/200] [Batch 485/815] [D loss: -6.167417] [G loss: -23.066643]\n",
      "[Epoch 22/200] [Batch 490/815] [D loss: -5.498850] [G loss: -12.617026]\n",
      "[Epoch 22/200] [Batch 495/815] [D loss: -5.726415] [G loss: -15.669887]\n",
      "[Epoch 22/200] [Batch 500/815] [D loss: -7.274093] [G loss: -15.683712]\n",
      "[Epoch 22/200] [Batch 505/815] [D loss: -5.525362] [G loss: -19.010820]\n",
      "[Epoch 22/200] [Batch 510/815] [D loss: -5.817991] [G loss: -11.602515]\n",
      "[Epoch 22/200] [Batch 515/815] [D loss: -5.897246] [G loss: -15.134580]\n",
      "[Epoch 22/200] [Batch 520/815] [D loss: -5.855862] [G loss: -18.094223]\n",
      "[Epoch 22/200] [Batch 525/815] [D loss: -5.425207] [G loss: -18.252178]\n",
      "[Epoch 22/200] [Batch 530/815] [D loss: -6.339696] [G loss: -11.626387]\n",
      "[Epoch 22/200] [Batch 535/815] [D loss: -4.494149] [G loss: -26.584675]\n",
      "[Epoch 22/200] [Batch 540/815] [D loss: -5.749644] [G loss: -16.852329]\n",
      "[Epoch 22/200] [Batch 545/815] [D loss: -4.949303] [G loss: -26.424990]\n",
      "[Epoch 22/200] [Batch 550/815] [D loss: -6.183343] [G loss: -14.329007]\n",
      "[Epoch 22/200] [Batch 555/815] [D loss: -4.244423] [G loss: -40.194538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/200] [Batch 560/815] [D loss: -4.792502] [G loss: -17.777403]\n",
      "[Epoch 22/200] [Batch 565/815] [D loss: -5.357608] [G loss: -17.736792]\n",
      "[Epoch 22/200] [Batch 570/815] [D loss: -5.679651] [G loss: -21.296736]\n",
      "[Epoch 22/200] [Batch 575/815] [D loss: -5.548481] [G loss: -10.936157]\n",
      "[Epoch 22/200] [Batch 580/815] [D loss: -4.550591] [G loss: -27.855610]\n",
      "[Epoch 22/200] [Batch 585/815] [D loss: -4.523858] [G loss: -18.312325]\n",
      "[Epoch 22/200] [Batch 590/815] [D loss: -5.114099] [G loss: -15.784842]\n",
      "[Epoch 22/200] [Batch 595/815] [D loss: -6.271438] [G loss: -13.601686]\n",
      "[Epoch 22/200] [Batch 600/815] [D loss: -4.951185] [G loss: -15.485799]\n",
      "[Epoch 22/200] [Batch 605/815] [D loss: -5.708110] [G loss: -12.852815]\n",
      "[Epoch 22/200] [Batch 610/815] [D loss: -4.640228] [G loss: -16.716490]\n",
      "[Epoch 22/200] [Batch 615/815] [D loss: -4.290450] [G loss: -25.691175]\n",
      "[Epoch 22/200] [Batch 620/815] [D loss: -4.590927] [G loss: -18.197966]\n",
      "[Epoch 22/200] [Batch 625/815] [D loss: -5.297795] [G loss: -13.379244]\n",
      "[Epoch 22/200] [Batch 630/815] [D loss: -5.641738] [G loss: -14.542112]\n",
      "[Epoch 22/200] [Batch 635/815] [D loss: -5.666124] [G loss: -16.581072]\n",
      "[Epoch 22/200] [Batch 640/815] [D loss: -4.496659] [G loss: -28.382843]\n",
      "[Epoch 22/200] [Batch 645/815] [D loss: -5.308229] [G loss: -20.821089]\n",
      "[Epoch 22/200] [Batch 650/815] [D loss: -6.317138] [G loss: -20.130684]\n",
      "[Epoch 22/200] [Batch 655/815] [D loss: -5.639143] [G loss: -13.094454]\n",
      "[Epoch 22/200] [Batch 660/815] [D loss: -5.436319] [G loss: -21.845196]\n",
      "[Epoch 22/200] [Batch 665/815] [D loss: -4.945261] [G loss: -17.504637]\n",
      "[Epoch 22/200] [Batch 670/815] [D loss: -5.653317] [G loss: -14.159747]\n",
      "[Epoch 22/200] [Batch 675/815] [D loss: -4.381340] [G loss: -23.770882]\n",
      "[Epoch 22/200] [Batch 680/815] [D loss: -5.120385] [G loss: -19.887701]\n",
      "[Epoch 22/200] [Batch 685/815] [D loss: -5.747771] [G loss: -14.500517]\n",
      "[Epoch 22/200] [Batch 690/815] [D loss: -4.870645] [G loss: -13.501854]\n",
      "[Epoch 22/200] [Batch 695/815] [D loss: -5.029563] [G loss: -19.282942]\n",
      "[Epoch 22/200] [Batch 700/815] [D loss: -3.810781] [G loss: -29.220860]\n",
      "[Epoch 22/200] [Batch 705/815] [D loss: -5.723316] [G loss: -16.414070]\n",
      "[Epoch 22/200] [Batch 710/815] [D loss: -6.181972] [G loss: -19.992207]\n",
      "[Epoch 22/200] [Batch 715/815] [D loss: -5.482403] [G loss: -14.372103]\n",
      "[Epoch 22/200] [Batch 720/815] [D loss: -5.851742] [G loss: -14.021900]\n",
      "[Epoch 22/200] [Batch 725/815] [D loss: -5.882899] [G loss: -15.582685]\n",
      "[Epoch 22/200] [Batch 730/815] [D loss: -5.536987] [G loss: -22.977730]\n",
      "[Epoch 22/200] [Batch 735/815] [D loss: -5.554005] [G loss: -15.395326]\n",
      "[Epoch 22/200] [Batch 740/815] [D loss: -5.732965] [G loss: -18.165876]\n",
      "[Epoch 22/200] [Batch 745/815] [D loss: -6.424766] [G loss: -16.051830]\n",
      "[Epoch 22/200] [Batch 750/815] [D loss: -6.052693] [G loss: -16.121666]\n",
      "[Epoch 22/200] [Batch 755/815] [D loss: -5.843822] [G loss: -14.944355]\n",
      "[Epoch 22/200] [Batch 760/815] [D loss: -5.094929] [G loss: -20.512934]\n",
      "[Epoch 22/200] [Batch 765/815] [D loss: -6.134588] [G loss: -15.129505]\n",
      "[Epoch 22/200] [Batch 770/815] [D loss: -4.865582] [G loss: -32.062141]\n",
      "[Epoch 22/200] [Batch 775/815] [D loss: -6.193122] [G loss: -22.490156]\n",
      "[Epoch 22/200] [Batch 780/815] [D loss: -4.605077] [G loss: -19.549952]\n",
      "[Epoch 22/200] [Batch 785/815] [D loss: -4.364926] [G loss: -19.668961]\n",
      "[Epoch 22/200] [Batch 790/815] [D loss: -6.266028] [G loss: -9.891798]\n",
      "[Epoch 22/200] [Batch 795/815] [D loss: -4.818946] [G loss: -26.896898]\n",
      "[Epoch 22/200] [Batch 800/815] [D loss: -5.526947] [G loss: -19.308664]\n",
      "[Epoch 22/200] [Batch 805/815] [D loss: -4.614399] [G loss: -19.417370]\n",
      "[Epoch 22/200] [Batch 810/815] [D loss: -4.124299] [G loss: -19.399509]\n",
      "[Epoch 23/200] [Batch 0/815] [D loss: -4.442857] [G loss: -22.525537]\n",
      "[Epoch 23/200] [Batch 5/815] [D loss: -5.415288] [G loss: -14.216137]\n",
      "[Epoch 23/200] [Batch 10/815] [D loss: -5.300735] [G loss: -20.259914]\n",
      "[Epoch 23/200] [Batch 15/815] [D loss: -4.040884] [G loss: -25.705658]\n",
      "[Epoch 23/200] [Batch 20/815] [D loss: -5.289697] [G loss: -14.745363]\n",
      "[Epoch 23/200] [Batch 25/815] [D loss: -5.331174] [G loss: -20.714712]\n",
      "[Epoch 23/200] [Batch 30/815] [D loss: -6.041586] [G loss: -15.397982]\n",
      "[Epoch 23/200] [Batch 35/815] [D loss: -5.325623] [G loss: -15.519349]\n",
      "[Epoch 23/200] [Batch 40/815] [D loss: -5.563136] [G loss: -16.151863]\n",
      "[Epoch 23/200] [Batch 45/815] [D loss: -4.777822] [G loss: -21.331964]\n",
      "[Epoch 23/200] [Batch 50/815] [D loss: -5.968126] [G loss: -12.919230]\n",
      "[Epoch 23/200] [Batch 55/815] [D loss: -5.784928] [G loss: -17.670801]\n",
      "[Epoch 23/200] [Batch 60/815] [D loss: -3.350591] [G loss: -20.666372]\n",
      "[Epoch 23/200] [Batch 65/815] [D loss: -5.416658] [G loss: -19.895504]\n",
      "[Epoch 23/200] [Batch 70/815] [D loss: -5.101625] [G loss: -23.185331]\n",
      "[Epoch 23/200] [Batch 75/815] [D loss: -5.393515] [G loss: -18.970556]\n",
      "[Epoch 23/200] [Batch 80/815] [D loss: -5.693814] [G loss: -17.286314]\n",
      "[Epoch 23/200] [Batch 85/815] [D loss: -5.209084] [G loss: -22.482197]\n",
      "[Epoch 23/200] [Batch 90/815] [D loss: -5.982768] [G loss: -14.627345]\n",
      "[Epoch 23/200] [Batch 95/815] [D loss: -5.677348] [G loss: -12.784156]\n",
      "[Epoch 23/200] [Batch 100/815] [D loss: -5.764586] [G loss: -15.507821]\n",
      "[Epoch 23/200] [Batch 105/815] [D loss: -5.795153] [G loss: -17.110460]\n",
      "[Epoch 23/200] [Batch 110/815] [D loss: -6.448091] [G loss: -16.081341]\n",
      "[Epoch 23/200] [Batch 115/815] [D loss: -5.222818] [G loss: -18.545425]\n",
      "[Epoch 23/200] [Batch 120/815] [D loss: -5.523662] [G loss: -15.604129]\n",
      "[Epoch 23/200] [Batch 125/815] [D loss: -4.775004] [G loss: -25.633877]\n",
      "[Epoch 23/200] [Batch 130/815] [D loss: -5.621188] [G loss: -22.506266]\n",
      "[Epoch 23/200] [Batch 135/815] [D loss: -5.787644] [G loss: -19.535906]\n",
      "[Epoch 23/200] [Batch 140/815] [D loss: -5.034025] [G loss: -17.263350]\n",
      "[Epoch 23/200] [Batch 145/815] [D loss: -6.035769] [G loss: -12.019065]\n",
      "[Epoch 23/200] [Batch 150/815] [D loss: -5.434587] [G loss: -24.075615]\n",
      "[Epoch 23/200] [Batch 155/815] [D loss: -5.317167] [G loss: -15.385595]\n",
      "[Epoch 23/200] [Batch 160/815] [D loss: -6.257321] [G loss: -16.554726]\n",
      "[Epoch 23/200] [Batch 165/815] [D loss: -4.329428] [G loss: -23.632437]\n",
      "[Epoch 23/200] [Batch 170/815] [D loss: -5.698285] [G loss: -14.611508]\n",
      "[Epoch 23/200] [Batch 175/815] [D loss: -6.180216] [G loss: -12.960114]\n",
      "[Epoch 23/200] [Batch 180/815] [D loss: -6.090499] [G loss: -16.145140]\n",
      "[Epoch 23/200] [Batch 185/815] [D loss: -5.954569] [G loss: -13.831078]\n",
      "[Epoch 23/200] [Batch 190/815] [D loss: -6.064039] [G loss: -12.615549]\n",
      "[Epoch 23/200] [Batch 195/815] [D loss: -4.838650] [G loss: -20.244255]\n",
      "[Epoch 23/200] [Batch 200/815] [D loss: -5.554220] [G loss: -17.083891]\n",
      "[Epoch 23/200] [Batch 205/815] [D loss: -4.903673] [G loss: -30.987350]\n",
      "[Epoch 23/200] [Batch 210/815] [D loss: -5.361422] [G loss: -18.638981]\n",
      "[Epoch 23/200] [Batch 215/815] [D loss: -5.082694] [G loss: -15.219123]\n",
      "[Epoch 23/200] [Batch 220/815] [D loss: -5.503820] [G loss: -13.716010]\n",
      "[Epoch 23/200] [Batch 225/815] [D loss: -4.561283] [G loss: -21.072529]\n",
      "[Epoch 23/200] [Batch 230/815] [D loss: -5.811262] [G loss: -15.477719]\n",
      "[Epoch 23/200] [Batch 235/815] [D loss: -5.490418] [G loss: -15.029563]\n",
      "[Epoch 23/200] [Batch 240/815] [D loss: -5.277673] [G loss: -26.599331]\n",
      "[Epoch 23/200] [Batch 245/815] [D loss: -5.332150] [G loss: -20.112070]\n",
      "[Epoch 23/200] [Batch 250/815] [D loss: -5.466150] [G loss: -15.532053]\n",
      "[Epoch 23/200] [Batch 255/815] [D loss: -5.438352] [G loss: -21.022892]\n",
      "[Epoch 23/200] [Batch 260/815] [D loss: -4.646530] [G loss: -19.220442]\n",
      "[Epoch 23/200] [Batch 265/815] [D loss: -3.330719] [G loss: -20.015589]\n",
      "[Epoch 23/200] [Batch 270/815] [D loss: -4.950939] [G loss: -22.984322]\n",
      "[Epoch 23/200] [Batch 275/815] [D loss: -5.404335] [G loss: -14.106984]\n",
      "[Epoch 23/200] [Batch 280/815] [D loss: -5.236718] [G loss: -13.852323]\n",
      "[Epoch 23/200] [Batch 285/815] [D loss: -5.472962] [G loss: -18.962240]\n",
      "[Epoch 23/200] [Batch 290/815] [D loss: -5.552344] [G loss: -15.046492]\n",
      "[Epoch 23/200] [Batch 295/815] [D loss: -6.181335] [G loss: -15.322189]\n",
      "[Epoch 23/200] [Batch 300/815] [D loss: -5.674510] [G loss: -15.272436]\n",
      "[Epoch 23/200] [Batch 305/815] [D loss: -4.916009] [G loss: -27.952871]\n",
      "[Epoch 23/200] [Batch 310/815] [D loss: -5.632684] [G loss: -16.439688]\n",
      "[Epoch 23/200] [Batch 315/815] [D loss: -5.573321] [G loss: -21.082930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/200] [Batch 320/815] [D loss: -5.465219] [G loss: -14.496416]\n",
      "[Epoch 23/200] [Batch 325/815] [D loss: -5.260272] [G loss: -25.691799]\n",
      "[Epoch 23/200] [Batch 330/815] [D loss: -5.027196] [G loss: -15.414821]\n",
      "[Epoch 23/200] [Batch 335/815] [D loss: -5.416794] [G loss: -14.018203]\n",
      "[Epoch 23/200] [Batch 340/815] [D loss: -7.040467] [G loss: -14.527547]\n",
      "[Epoch 23/200] [Batch 345/815] [D loss: -6.194490] [G loss: -16.032089]\n",
      "[Epoch 23/200] [Batch 350/815] [D loss: -5.040563] [G loss: -20.084900]\n",
      "[Epoch 23/200] [Batch 355/815] [D loss: -4.643407] [G loss: -27.123898]\n",
      "[Epoch 23/200] [Batch 360/815] [D loss: -5.685476] [G loss: -15.525868]\n",
      "[Epoch 23/200] [Batch 365/815] [D loss: -5.331993] [G loss: -15.218394]\n",
      "[Epoch 23/200] [Batch 370/815] [D loss: -4.217785] [G loss: -27.734028]\n",
      "[Epoch 23/200] [Batch 375/815] [D loss: -6.104823] [G loss: -12.909054]\n",
      "[Epoch 23/200] [Batch 380/815] [D loss: -5.677057] [G loss: -18.931154]\n",
      "[Epoch 23/200] [Batch 385/815] [D loss: -6.032331] [G loss: -16.672789]\n",
      "[Epoch 23/200] [Batch 390/815] [D loss: -5.620685] [G loss: -18.186075]\n",
      "[Epoch 23/200] [Batch 395/815] [D loss: -5.529358] [G loss: -16.682167]\n",
      "[Epoch 23/200] [Batch 400/815] [D loss: -5.106894] [G loss: -21.038454]\n",
      "[Epoch 23/200] [Batch 405/815] [D loss: -4.962584] [G loss: -15.588938]\n",
      "[Epoch 23/200] [Batch 410/815] [D loss: -5.733738] [G loss: -16.249031]\n",
      "[Epoch 23/200] [Batch 415/815] [D loss: -5.219951] [G loss: -15.201662]\n",
      "[Epoch 23/200] [Batch 420/815] [D loss: -4.844633] [G loss: -19.061790]\n",
      "[Epoch 23/200] [Batch 425/815] [D loss: -6.520599] [G loss: -13.519540]\n",
      "[Epoch 23/200] [Batch 430/815] [D loss: -5.346196] [G loss: -12.687179]\n",
      "[Epoch 23/200] [Batch 435/815] [D loss: -5.045344] [G loss: -18.355896]\n",
      "[Epoch 23/200] [Batch 440/815] [D loss: -4.855059] [G loss: -20.194971]\n",
      "[Epoch 23/200] [Batch 445/815] [D loss: -5.512518] [G loss: -10.984338]\n",
      "[Epoch 23/200] [Batch 450/815] [D loss: -5.294164] [G loss: -20.534777]\n",
      "[Epoch 23/200] [Batch 455/815] [D loss: -5.606339] [G loss: -17.985901]\n",
      "[Epoch 23/200] [Batch 460/815] [D loss: -6.077995] [G loss: -18.511881]\n",
      "[Epoch 23/200] [Batch 465/815] [D loss: -5.811752] [G loss: -17.286819]\n",
      "[Epoch 23/200] [Batch 470/815] [D loss: -5.838120] [G loss: -24.119751]\n",
      "[Epoch 23/200] [Batch 475/815] [D loss: -6.410137] [G loss: -12.270686]\n",
      "[Epoch 23/200] [Batch 480/815] [D loss: -4.904355] [G loss: -19.923510]\n",
      "[Epoch 23/200] [Batch 485/815] [D loss: -5.350432] [G loss: -13.660301]\n",
      "[Epoch 23/200] [Batch 490/815] [D loss: -5.251359] [G loss: -14.915234]\n",
      "[Epoch 23/200] [Batch 495/815] [D loss: -6.044207] [G loss: -17.828814]\n",
      "[Epoch 23/200] [Batch 500/815] [D loss: -5.702662] [G loss: -16.266167]\n",
      "[Epoch 23/200] [Batch 505/815] [D loss: -5.376139] [G loss: -22.409132]\n",
      "[Epoch 23/200] [Batch 510/815] [D loss: -5.320354] [G loss: -16.061598]\n",
      "[Epoch 23/200] [Batch 515/815] [D loss: -5.355102] [G loss: -17.889309]\n",
      "[Epoch 23/200] [Batch 520/815] [D loss: -6.540668] [G loss: -21.572697]\n",
      "[Epoch 23/200] [Batch 525/815] [D loss: -5.616466] [G loss: -15.147593]\n",
      "[Epoch 23/200] [Batch 530/815] [D loss: -6.419050] [G loss: -14.475032]\n",
      "[Epoch 23/200] [Batch 535/815] [D loss: -5.856972] [G loss: -18.873110]\n",
      "[Epoch 23/200] [Batch 540/815] [D loss: -4.499287] [G loss: -23.435694]\n",
      "[Epoch 23/200] [Batch 545/815] [D loss: -5.032873] [G loss: -20.105635]\n",
      "[Epoch 23/200] [Batch 550/815] [D loss: -5.586255] [G loss: -16.744753]\n",
      "[Epoch 23/200] [Batch 555/815] [D loss: -6.009748] [G loss: -13.885686]\n",
      "[Epoch 23/200] [Batch 560/815] [D loss: -5.207776] [G loss: -21.282818]\n",
      "[Epoch 23/200] [Batch 565/815] [D loss: -3.835887] [G loss: -33.939896]\n",
      "[Epoch 23/200] [Batch 570/815] [D loss: -4.755418] [G loss: -23.429356]\n",
      "[Epoch 23/200] [Batch 575/815] [D loss: -5.603894] [G loss: -12.207149]\n",
      "[Epoch 23/200] [Batch 580/815] [D loss: -6.382189] [G loss: -11.950331]\n",
      "[Epoch 23/200] [Batch 585/815] [D loss: -5.429606] [G loss: -15.426636]\n",
      "[Epoch 23/200] [Batch 590/815] [D loss: -5.308495] [G loss: -16.652952]\n",
      "[Epoch 23/200] [Batch 595/815] [D loss: -4.322811] [G loss: -19.486092]\n",
      "[Epoch 23/200] [Batch 600/815] [D loss: -5.620536] [G loss: -19.939220]\n",
      "[Epoch 23/200] [Batch 605/815] [D loss: -5.229331] [G loss: -16.855328]\n",
      "[Epoch 23/200] [Batch 610/815] [D loss: -6.459843] [G loss: -15.263338]\n",
      "[Epoch 23/200] [Batch 615/815] [D loss: -5.213569] [G loss: -16.172079]\n",
      "[Epoch 23/200] [Batch 620/815] [D loss: -3.939247] [G loss: -27.168669]\n",
      "[Epoch 23/200] [Batch 625/815] [D loss: -4.830732] [G loss: -14.499366]\n",
      "[Epoch 23/200] [Batch 630/815] [D loss: -6.296440] [G loss: -10.099277]\n",
      "[Epoch 23/200] [Batch 635/815] [D loss: -4.724800] [G loss: -23.782505]\n",
      "[Epoch 23/200] [Batch 640/815] [D loss: -4.914763] [G loss: -21.691114]\n",
      "[Epoch 23/200] [Batch 645/815] [D loss: -6.244191] [G loss: -12.165089]\n",
      "[Epoch 23/200] [Batch 650/815] [D loss: -5.733130] [G loss: -21.313864]\n",
      "[Epoch 23/200] [Batch 655/815] [D loss: -5.034870] [G loss: -17.831398]\n",
      "[Epoch 23/200] [Batch 660/815] [D loss: -5.404844] [G loss: -20.938095]\n",
      "[Epoch 23/200] [Batch 665/815] [D loss: -6.388423] [G loss: -13.842126]\n",
      "[Epoch 23/200] [Batch 670/815] [D loss: -6.246381] [G loss: -12.970257]\n",
      "[Epoch 23/200] [Batch 675/815] [D loss: -5.482411] [G loss: -17.418465]\n",
      "[Epoch 23/200] [Batch 680/815] [D loss: -5.235860] [G loss: -17.202627]\n",
      "[Epoch 23/200] [Batch 685/815] [D loss: -5.726547] [G loss: -17.926495]\n",
      "[Epoch 23/200] [Batch 690/815] [D loss: -5.483011] [G loss: -16.027161]\n",
      "[Epoch 23/200] [Batch 695/815] [D loss: -6.461722] [G loss: -16.812521]\n",
      "[Epoch 23/200] [Batch 700/815] [D loss: -5.411990] [G loss: -19.239819]\n",
      "[Epoch 23/200] [Batch 705/815] [D loss: -4.995016] [G loss: -18.255878]\n",
      "[Epoch 23/200] [Batch 710/815] [D loss: -5.233743] [G loss: -16.062891]\n",
      "[Epoch 23/200] [Batch 715/815] [D loss: -5.937214] [G loss: -16.291924]\n",
      "[Epoch 23/200] [Batch 720/815] [D loss: -5.609645] [G loss: -24.384417]\n",
      "[Epoch 23/200] [Batch 725/815] [D loss: -5.545178] [G loss: -15.498602]\n",
      "[Epoch 23/200] [Batch 730/815] [D loss: -4.163527] [G loss: -20.088135]\n",
      "[Epoch 23/200] [Batch 735/815] [D loss: -5.007652] [G loss: -15.398205]\n",
      "[Epoch 23/200] [Batch 740/815] [D loss: -4.934711] [G loss: -19.552551]\n",
      "[Epoch 23/200] [Batch 745/815] [D loss: -4.875562] [G loss: -19.501312]\n",
      "[Epoch 23/200] [Batch 750/815] [D loss: -5.547393] [G loss: -33.427120]\n",
      "[Epoch 23/200] [Batch 755/815] [D loss: -5.099553] [G loss: -16.196762]\n",
      "[Epoch 23/200] [Batch 760/815] [D loss: -5.669307] [G loss: -18.756809]\n",
      "[Epoch 23/200] [Batch 765/815] [D loss: -6.289850] [G loss: -12.236605]\n",
      "[Epoch 23/200] [Batch 770/815] [D loss: -4.958470] [G loss: -24.982885]\n",
      "[Epoch 23/200] [Batch 775/815] [D loss: -4.870444] [G loss: -20.508131]\n",
      "[Epoch 23/200] [Batch 780/815] [D loss: -5.695601] [G loss: -16.362820]\n",
      "[Epoch 23/200] [Batch 785/815] [D loss: -5.602013] [G loss: -16.132643]\n",
      "[Epoch 23/200] [Batch 790/815] [D loss: -5.273375] [G loss: -18.793419]\n",
      "[Epoch 23/200] [Batch 795/815] [D loss: -5.658176] [G loss: -22.676735]\n",
      "[Epoch 23/200] [Batch 800/815] [D loss: -6.089035] [G loss: -16.115551]\n",
      "[Epoch 23/200] [Batch 805/815] [D loss: -5.765262] [G loss: -18.043957]\n",
      "[Epoch 23/200] [Batch 810/815] [D loss: -5.307940] [G loss: -16.952354]\n",
      "[Epoch 24/200] [Batch 0/815] [D loss: -1.912684] [G loss: -18.598879]\n",
      "[Epoch 24/200] [Batch 5/815] [D loss: -5.604490] [G loss: -16.526506]\n",
      "[Epoch 24/200] [Batch 10/815] [D loss: -5.643347] [G loss: -18.193232]\n",
      "[Epoch 24/200] [Batch 15/815] [D loss: -5.981647] [G loss: -17.219429]\n",
      "[Epoch 24/200] [Batch 20/815] [D loss: -5.500057] [G loss: -23.870657]\n",
      "[Epoch 24/200] [Batch 25/815] [D loss: -5.239738] [G loss: -16.604786]\n",
      "[Epoch 24/200] [Batch 30/815] [D loss: -5.353466] [G loss: -18.490078]\n",
      "[Epoch 24/200] [Batch 35/815] [D loss: -5.160126] [G loss: -23.508553]\n",
      "[Epoch 24/200] [Batch 40/815] [D loss: -6.330137] [G loss: -16.848621]\n",
      "[Epoch 24/200] [Batch 45/815] [D loss: -5.019669] [G loss: -28.193932]\n",
      "[Epoch 24/200] [Batch 50/815] [D loss: -5.308865] [G loss: -15.857513]\n",
      "[Epoch 24/200] [Batch 55/815] [D loss: -5.793871] [G loss: -16.164387]\n",
      "[Epoch 24/200] [Batch 60/815] [D loss: -5.045676] [G loss: -16.059490]\n",
      "[Epoch 24/200] [Batch 65/815] [D loss: -6.121518] [G loss: -17.270279]\n",
      "[Epoch 24/200] [Batch 70/815] [D loss: -5.509352] [G loss: -12.208320]\n",
      "[Epoch 24/200] [Batch 75/815] [D loss: -5.674280] [G loss: -15.990681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 80/815] [D loss: -5.736144] [G loss: -13.674162]\n",
      "[Epoch 24/200] [Batch 85/815] [D loss: -5.668692] [G loss: -15.417385]\n",
      "[Epoch 24/200] [Batch 90/815] [D loss: -5.491690] [G loss: -18.679838]\n",
      "[Epoch 24/200] [Batch 95/815] [D loss: -5.378197] [G loss: -20.123749]\n",
      "[Epoch 24/200] [Batch 100/815] [D loss: -5.262973] [G loss: -20.344555]\n",
      "[Epoch 24/200] [Batch 105/815] [D loss: -6.391011] [G loss: -17.259932]\n",
      "[Epoch 24/200] [Batch 110/815] [D loss: -6.459971] [G loss: -12.969234]\n",
      "[Epoch 24/200] [Batch 115/815] [D loss: -3.870505] [G loss: -24.292603]\n",
      "[Epoch 24/200] [Batch 120/815] [D loss: -6.171345] [G loss: -13.590130]\n",
      "[Epoch 24/200] [Batch 125/815] [D loss: -5.966655] [G loss: -15.932622]\n",
      "[Epoch 24/200] [Batch 130/815] [D loss: -4.898588] [G loss: -29.784763]\n",
      "[Epoch 24/200] [Batch 135/815] [D loss: -5.514517] [G loss: -17.325377]\n",
      "[Epoch 24/200] [Batch 140/815] [D loss: -5.652320] [G loss: -16.724350]\n",
      "[Epoch 24/200] [Batch 145/815] [D loss: -5.260108] [G loss: -14.043481]\n",
      "[Epoch 24/200] [Batch 150/815] [D loss: -6.391545] [G loss: -15.571148]\n",
      "[Epoch 24/200] [Batch 155/815] [D loss: -4.836151] [G loss: -22.417978]\n",
      "[Epoch 24/200] [Batch 160/815] [D loss: -5.414577] [G loss: -15.641050]\n",
      "[Epoch 24/200] [Batch 165/815] [D loss: -5.303617] [G loss: -15.762700]\n",
      "[Epoch 24/200] [Batch 170/815] [D loss: -4.873442] [G loss: -20.114750]\n",
      "[Epoch 24/200] [Batch 175/815] [D loss: -6.157156] [G loss: -21.550436]\n",
      "[Epoch 24/200] [Batch 180/815] [D loss: -6.592996] [G loss: -22.519932]\n",
      "[Epoch 24/200] [Batch 185/815] [D loss: -5.558734] [G loss: -14.051336]\n",
      "[Epoch 24/200] [Batch 190/815] [D loss: -5.055734] [G loss: -18.932150]\n",
      "[Epoch 24/200] [Batch 195/815] [D loss: -6.216122] [G loss: -15.737601]\n",
      "[Epoch 24/200] [Batch 200/815] [D loss: -5.227954] [G loss: -22.622849]\n",
      "[Epoch 24/200] [Batch 205/815] [D loss: -5.660950] [G loss: -22.265129]\n",
      "[Epoch 24/200] [Batch 210/815] [D loss: -5.888109] [G loss: -16.331438]\n",
      "[Epoch 24/200] [Batch 215/815] [D loss: -4.569304] [G loss: -23.889465]\n",
      "[Epoch 24/200] [Batch 220/815] [D loss: -4.807713] [G loss: -20.675615]\n",
      "[Epoch 24/200] [Batch 225/815] [D loss: -5.226495] [G loss: -16.817875]\n",
      "[Epoch 24/200] [Batch 230/815] [D loss: -5.471887] [G loss: -15.639825]\n",
      "[Epoch 24/200] [Batch 235/815] [D loss: -6.435980] [G loss: -15.907027]\n",
      "[Epoch 24/200] [Batch 240/815] [D loss: -5.466082] [G loss: -14.786816]\n",
      "[Epoch 24/200] [Batch 245/815] [D loss: -5.566148] [G loss: -14.968750]\n",
      "[Epoch 24/200] [Batch 250/815] [D loss: -6.295446] [G loss: -13.764807]\n",
      "[Epoch 24/200] [Batch 255/815] [D loss: -4.354933] [G loss: -21.302336]\n",
      "[Epoch 24/200] [Batch 260/815] [D loss: -6.113581] [G loss: -13.060963]\n",
      "[Epoch 24/200] [Batch 265/815] [D loss: -5.625556] [G loss: -14.449098]\n",
      "[Epoch 24/200] [Batch 270/815] [D loss: -5.086030] [G loss: -21.398132]\n",
      "[Epoch 24/200] [Batch 275/815] [D loss: -6.091074] [G loss: -17.537941]\n",
      "[Epoch 24/200] [Batch 280/815] [D loss: -4.539270] [G loss: -23.973942]\n",
      "[Epoch 24/200] [Batch 285/815] [D loss: -6.314501] [G loss: -12.049260]\n",
      "[Epoch 24/200] [Batch 290/815] [D loss: -6.266676] [G loss: -19.966431]\n",
      "[Epoch 24/200] [Batch 295/815] [D loss: -5.479585] [G loss: -25.080862]\n",
      "[Epoch 24/200] [Batch 300/815] [D loss: -5.240176] [G loss: -16.672483]\n",
      "[Epoch 24/200] [Batch 305/815] [D loss: -5.667546] [G loss: -21.095001]\n",
      "[Epoch 24/200] [Batch 310/815] [D loss: -5.977610] [G loss: -14.224463]\n",
      "[Epoch 24/200] [Batch 315/815] [D loss: -5.618311] [G loss: -18.251829]\n",
      "[Epoch 24/200] [Batch 320/815] [D loss: -4.275226] [G loss: -24.558657]\n",
      "[Epoch 24/200] [Batch 325/815] [D loss: -5.401532] [G loss: -11.858047]\n",
      "[Epoch 24/200] [Batch 330/815] [D loss: -5.103945] [G loss: -17.392700]\n",
      "[Epoch 24/200] [Batch 335/815] [D loss: -6.543952] [G loss: -15.911731]\n",
      "[Epoch 24/200] [Batch 340/815] [D loss: -5.344752] [G loss: -16.167400]\n",
      "[Epoch 24/200] [Batch 345/815] [D loss: -5.465401] [G loss: -11.595296]\n",
      "[Epoch 24/200] [Batch 350/815] [D loss: -6.243797] [G loss: -15.289836]\n",
      "[Epoch 24/200] [Batch 355/815] [D loss: -6.206475] [G loss: -13.113164]\n",
      "[Epoch 24/200] [Batch 360/815] [D loss: -4.818395] [G loss: -14.952116]\n",
      "[Epoch 24/200] [Batch 365/815] [D loss: -5.225331] [G loss: -24.263916]\n",
      "[Epoch 24/200] [Batch 370/815] [D loss: -6.681929] [G loss: -13.297087]\n",
      "[Epoch 24/200] [Batch 375/815] [D loss: -4.429939] [G loss: -23.063652]\n",
      "[Epoch 24/200] [Batch 380/815] [D loss: -5.233387] [G loss: -13.937164]\n",
      "[Epoch 24/200] [Batch 385/815] [D loss: -4.759068] [G loss: -19.269613]\n",
      "[Epoch 24/200] [Batch 390/815] [D loss: -6.056222] [G loss: -16.075132]\n",
      "[Epoch 24/200] [Batch 395/815] [D loss: -5.310583] [G loss: -23.076714]\n",
      "[Epoch 24/200] [Batch 400/815] [D loss: -5.435229] [G loss: -34.390465]\n",
      "[Epoch 24/200] [Batch 405/815] [D loss: -4.568234] [G loss: -19.785730]\n",
      "[Epoch 24/200] [Batch 410/815] [D loss: -5.548802] [G loss: -16.379644]\n",
      "[Epoch 24/200] [Batch 415/815] [D loss: -5.245277] [G loss: -20.048340]\n",
      "[Epoch 24/200] [Batch 420/815] [D loss: -4.887907] [G loss: -22.698465]\n",
      "[Epoch 24/200] [Batch 425/815] [D loss: -4.587069] [G loss: -17.160046]\n",
      "[Epoch 24/200] [Batch 430/815] [D loss: -5.375208] [G loss: -16.122993]\n",
      "[Epoch 24/200] [Batch 435/815] [D loss: -5.518216] [G loss: -14.735994]\n",
      "[Epoch 24/200] [Batch 440/815] [D loss: -4.409793] [G loss: -28.356621]\n",
      "[Epoch 24/200] [Batch 445/815] [D loss: -5.034423] [G loss: -16.080095]\n",
      "[Epoch 24/200] [Batch 450/815] [D loss: -5.983994] [G loss: -13.791240]\n",
      "[Epoch 24/200] [Batch 455/815] [D loss: -5.580915] [G loss: -14.582713]\n",
      "[Epoch 24/200] [Batch 460/815] [D loss: -5.413886] [G loss: -17.967329]\n",
      "[Epoch 24/200] [Batch 465/815] [D loss: -5.161280] [G loss: -18.783607]\n",
      "[Epoch 24/200] [Batch 470/815] [D loss: -5.948820] [G loss: -17.030373]\n",
      "[Epoch 24/200] [Batch 475/815] [D loss: -5.648133] [G loss: -14.086277]\n",
      "[Epoch 24/200] [Batch 480/815] [D loss: -5.303687] [G loss: -19.583139]\n",
      "[Epoch 24/200] [Batch 485/815] [D loss: -5.578469] [G loss: -14.789312]\n",
      "[Epoch 24/200] [Batch 490/815] [D loss: -5.744859] [G loss: -20.437620]\n",
      "[Epoch 24/200] [Batch 495/815] [D loss: -6.983484] [G loss: -17.406555]\n",
      "[Epoch 24/200] [Batch 500/815] [D loss: -2.755355] [G loss: -20.273022]\n",
      "[Epoch 24/200] [Batch 505/815] [D loss: -5.328456] [G loss: -14.966022]\n",
      "[Epoch 24/200] [Batch 510/815] [D loss: -4.700924] [G loss: -24.364983]\n",
      "[Epoch 24/200] [Batch 515/815] [D loss: -5.460488] [G loss: -15.567884]\n",
      "[Epoch 24/200] [Batch 520/815] [D loss: -5.088821] [G loss: -22.850292]\n",
      "[Epoch 24/200] [Batch 525/815] [D loss: -5.835554] [G loss: -15.806685]\n",
      "[Epoch 24/200] [Batch 530/815] [D loss: -4.992175] [G loss: -21.414558]\n",
      "[Epoch 24/200] [Batch 535/815] [D loss: -5.274297] [G loss: -19.622149]\n",
      "[Epoch 24/200] [Batch 540/815] [D loss: -5.593584] [G loss: -21.059748]\n",
      "[Epoch 24/200] [Batch 545/815] [D loss: -6.078047] [G loss: -14.632183]\n",
      "[Epoch 24/200] [Batch 550/815] [D loss: -4.012177] [G loss: -27.375055]\n",
      "[Epoch 24/200] [Batch 555/815] [D loss: -5.033577] [G loss: -18.565552]\n",
      "[Epoch 24/200] [Batch 560/815] [D loss: -4.728310] [G loss: -35.594296]\n",
      "[Epoch 24/200] [Batch 565/815] [D loss: -4.517049] [G loss: -17.540606]\n",
      "[Epoch 24/200] [Batch 570/815] [D loss: -4.544619] [G loss: -21.640411]\n",
      "[Epoch 24/200] [Batch 575/815] [D loss: -5.001863] [G loss: -18.877302]\n",
      "[Epoch 24/200] [Batch 580/815] [D loss: -6.379389] [G loss: -11.972186]\n",
      "[Epoch 24/200] [Batch 585/815] [D loss: -6.138010] [G loss: -14.618898]\n",
      "[Epoch 24/200] [Batch 590/815] [D loss: -5.086478] [G loss: -28.511749]\n",
      "[Epoch 24/200] [Batch 595/815] [D loss: -5.225697] [G loss: -21.089275]\n",
      "[Epoch 24/200] [Batch 600/815] [D loss: -5.523061] [G loss: -18.724951]\n",
      "[Epoch 24/200] [Batch 605/815] [D loss: -5.322730] [G loss: -23.236179]\n",
      "[Epoch 24/200] [Batch 610/815] [D loss: -5.390518] [G loss: -17.331562]\n",
      "[Epoch 24/200] [Batch 615/815] [D loss: -4.929849] [G loss: -19.671408]\n",
      "[Epoch 24/200] [Batch 620/815] [D loss: -5.519870] [G loss: -18.988752]\n",
      "[Epoch 24/200] [Batch 625/815] [D loss: -4.704545] [G loss: -20.779980]\n",
      "[Epoch 24/200] [Batch 630/815] [D loss: -5.462862] [G loss: -14.103051]\n",
      "[Epoch 24/200] [Batch 635/815] [D loss: -7.172995] [G loss: -12.036077]\n",
      "[Epoch 24/200] [Batch 640/815] [D loss: -5.827332] [G loss: -20.882658]\n",
      "[Epoch 24/200] [Batch 645/815] [D loss: -5.587808] [G loss: -18.936676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 650/815] [D loss: -6.122011] [G loss: -13.672697]\n",
      "[Epoch 24/200] [Batch 655/815] [D loss: -4.573861] [G loss: -22.845694]\n",
      "[Epoch 24/200] [Batch 660/815] [D loss: -5.392619] [G loss: -15.626405]\n",
      "[Epoch 24/200] [Batch 665/815] [D loss: -5.233712] [G loss: -21.129736]\n",
      "[Epoch 24/200] [Batch 670/815] [D loss: -5.842145] [G loss: -12.624260]\n",
      "[Epoch 24/200] [Batch 675/815] [D loss: -5.822451] [G loss: -15.162377]\n",
      "[Epoch 24/200] [Batch 680/815] [D loss: -5.028018] [G loss: -14.488060]\n",
      "[Epoch 24/200] [Batch 685/815] [D loss: -5.695107] [G loss: -15.559119]\n",
      "[Epoch 24/200] [Batch 690/815] [D loss: -5.496065] [G loss: -16.409756]\n",
      "[Epoch 24/200] [Batch 695/815] [D loss: -5.843168] [G loss: -15.111381]\n",
      "[Epoch 24/200] [Batch 700/815] [D loss: -5.486088] [G loss: -12.363657]\n",
      "[Epoch 24/200] [Batch 705/815] [D loss: -5.332354] [G loss: -23.805101]\n",
      "[Epoch 24/200] [Batch 710/815] [D loss: -5.073395] [G loss: -16.117563]\n",
      "[Epoch 24/200] [Batch 715/815] [D loss: -6.138811] [G loss: -15.695590]\n",
      "[Epoch 24/200] [Batch 720/815] [D loss: -3.961209] [G loss: -24.875299]\n",
      "[Epoch 24/200] [Batch 725/815] [D loss: -5.604225] [G loss: -14.313533]\n",
      "[Epoch 24/200] [Batch 730/815] [D loss: -4.660635] [G loss: -24.526663]\n",
      "[Epoch 24/200] [Batch 735/815] [D loss: -5.805083] [G loss: -26.246849]\n",
      "[Epoch 24/200] [Batch 740/815] [D loss: -5.457344] [G loss: -13.843485]\n",
      "[Epoch 24/200] [Batch 745/815] [D loss: -5.232306] [G loss: -18.285063]\n",
      "[Epoch 24/200] [Batch 750/815] [D loss: -5.213461] [G loss: -22.959675]\n",
      "[Epoch 24/200] [Batch 755/815] [D loss: -5.606200] [G loss: -15.468667]\n",
      "[Epoch 24/200] [Batch 760/815] [D loss: -5.274308] [G loss: -13.044438]\n",
      "[Epoch 24/200] [Batch 765/815] [D loss: -5.182526] [G loss: -21.184196]\n",
      "[Epoch 24/200] [Batch 770/815] [D loss: -5.262037] [G loss: -14.445092]\n",
      "[Epoch 24/200] [Batch 775/815] [D loss: -4.511533] [G loss: -15.886104]\n",
      "[Epoch 24/200] [Batch 780/815] [D loss: -5.484747] [G loss: -13.374372]\n",
      "[Epoch 24/200] [Batch 785/815] [D loss: -5.557066] [G loss: -19.029160]\n",
      "[Epoch 24/200] [Batch 790/815] [D loss: -5.600834] [G loss: -13.505529]\n",
      "[Epoch 24/200] [Batch 795/815] [D loss: -5.363956] [G loss: -20.604788]\n",
      "[Epoch 24/200] [Batch 800/815] [D loss: -5.302679] [G loss: -19.715572]\n",
      "[Epoch 24/200] [Batch 805/815] [D loss: -5.250291] [G loss: -16.842302]\n",
      "[Epoch 24/200] [Batch 810/815] [D loss: -4.224345] [G loss: -25.257959]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-928096ff9c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatches_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Configure input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# ensure that the worker exits on process exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "batches_done = 0\n",
    "for epoch in range(1000):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % 5 == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, 200, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            \n",
    "            \n",
    "            if batches_done % 81500 == 0:\n",
    "                save_image(fake_imgs.data[:25], \"images100_b1_0p5_lr_0p00002n3/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "            batches_done += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.0.weight',\n",
       "              tensor([[-0.0755,  0.0834, -0.0273,  ..., -0.0811, -0.0297,  0.0153],\n",
       "                      [ 0.1134,  0.0469,  0.0029,  ..., -0.0919,  0.0523,  0.0084],\n",
       "                      [-0.0145,  0.0043, -0.1151,  ..., -0.0460, -0.0711, -0.0073],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.0349, -0.0487,  ..., -0.0206,  0.0813,  0.0843],\n",
       "                      [-0.0824,  0.0009,  0.0197,  ...,  0.0484, -0.0272, -0.0106],\n",
       "                      [-0.0122,  0.0017, -0.1745,  ..., -0.0262, -0.0026,  0.0457]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.0.bias',\n",
       "              tensor([ 0.0516, -0.0204,  0.2660,  0.1415,  0.0396,  0.0179, -0.0682,  0.1631,\n",
       "                       0.4934,  0.1693,  0.1395,  0.2470,  0.2450,  0.1272, -0.2084, -0.0913,\n",
       "                       0.1224,  0.2447,  0.0536,  0.1853,  0.1298,  0.3033,  0.1689,  0.1224,\n",
       "                      -0.7369,  0.0848,  0.4795,  0.4657,  0.1758,  0.2944,  0.3005,  0.2086,\n",
       "                       0.1513,  0.1326, -0.0116,  0.2088,  0.2038,  0.0920, -0.0878,  0.2890,\n",
       "                       0.2143,  0.0941, -0.0363,  0.2856,  0.0095,  0.1983, -0.0380,  0.3838,\n",
       "                       0.2091, -0.0583,  0.3613, -0.0076,  0.0890,  0.1445, -0.1279,  0.1720,\n",
       "                      -0.0132,  0.2259,  0.3182, -0.2056,  0.2809,  0.1528,  0.1316, -0.0795,\n",
       "                       0.4601,  0.2255,  0.1753,  0.2788,  0.0615,  0.2771,  0.1594,  0.2397,\n",
       "                       0.4542,  0.2048,  0.0791,  0.2509,  0.0133, -0.5930,  0.0571,  0.2352,\n",
       "                       0.2594,  0.1817,  0.2140,  0.0372, -0.0896,  0.1468, -0.2692, -0.0360,\n",
       "                       0.1265,  0.2880, -0.0055, -0.2754,  0.0396,  0.2861,  0.1703,  0.1682,\n",
       "                       0.3384,  0.2953,  0.1440,  0.0270,  0.0127,  0.1291,  0.2892,  0.1180,\n",
       "                       0.0956,  0.1524,  0.3043,  0.1537,  0.2629,  0.1829,  0.2003,  0.0838,\n",
       "                       0.5146,  0.2130,  0.0191,  0.0438,  0.1748, -0.0167,  0.0147,  0.0614,\n",
       "                       0.1544,  0.3038, -0.1251, -0.0880, -0.0439,  0.1784,  0.1837,  0.0367],\n",
       "                     device='cuda:0')),\n",
       "             ('model.2.weight',\n",
       "              tensor([[ 0.0226, -0.0818, -0.0457,  ..., -0.0557, -0.0673, -0.0799],\n",
       "                      [ 0.1264,  0.0188, -0.0549,  ...,  0.0271,  0.1185, -0.0174],\n",
       "                      [ 0.1312,  0.1948, -0.0516,  ..., -0.0929,  0.0594,  0.0769],\n",
       "                      ...,\n",
       "                      [ 0.0734,  0.0591, -0.0296,  ...,  0.0106,  0.1139, -0.0027],\n",
       "                      [ 0.1071, -0.1489, -0.0690,  ...,  0.1514, -0.1233, -0.1114],\n",
       "                      [-0.0101, -0.1030, -0.1148,  ...,  0.0883, -0.0055, -0.1745]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.2.bias',\n",
       "              tensor([ 0.0458, -0.0704, -0.0742,  0.0454, -0.0336,  0.0192,  0.0240, -0.0006,\n",
       "                       0.0402,  0.0398, -0.0099,  0.0425, -0.0562,  0.0171, -0.0123,  0.0696,\n",
       "                       0.0698, -0.0303, -0.0044, -0.0449, -0.0097,  0.0880, -0.0093,  0.0093,\n",
       "                      -0.0586, -0.0284,  0.0617, -0.0100, -0.0233,  0.0595,  0.0102,  0.0630,\n",
       "                       0.0049,  0.0319, -0.0455,  0.0885,  0.0329, -0.0743,  0.0538,  0.0232,\n",
       "                      -0.0237,  0.0407, -0.0458,  0.0518, -0.0101,  0.0113, -0.0425,  0.0016,\n",
       "                      -0.0496,  0.0660, -0.0265,  0.0922,  0.0528, -0.0786,  0.0507,  0.0734,\n",
       "                      -0.0793,  0.0945, -0.0456, -0.0146,  0.0571, -0.0640,  0.0659, -0.0334,\n",
       "                      -0.0778,  0.0202,  0.0493,  0.0513, -0.0618,  0.0363, -0.0618,  0.0063,\n",
       "                      -0.0272, -0.0677, -0.0194, -0.0605, -0.0803,  0.0598, -0.0308,  0.0434,\n",
       "                       0.0410,  0.0794,  0.0772, -0.0347, -0.0592, -0.0755,  0.0790,  0.0116,\n",
       "                      -0.0228, -0.0007,  0.0513,  0.0190,  0.0484, -0.0421, -0.0178,  0.0175,\n",
       "                       0.0786,  0.0569, -0.0176,  0.0415,  0.0135, -0.0045,  0.0743,  0.0396,\n",
       "                      -0.0520, -0.0864, -0.0690,  0.0269,  0.0797, -0.0074,  0.0491,  0.0605,\n",
       "                      -0.0353,  0.0241, -0.0340, -0.0153,  0.0912,  0.0628, -0.0041, -0.0029,\n",
       "                      -0.0075, -0.0701,  0.0215,  0.0137, -0.0550, -0.0045,  0.0772, -0.0692,\n",
       "                      -0.0113, -0.0620,  0.0831,  0.0862, -0.0800,  0.0136,  0.0065,  0.0282,\n",
       "                      -0.0792, -0.0708, -0.0148,  0.0606,  0.0288, -0.0784,  0.0378,  0.0111,\n",
       "                       0.0792, -0.0492,  0.0802, -0.0665, -0.0639, -0.0590,  0.0389,  0.0323,\n",
       "                       0.0768, -0.0677,  0.0554, -0.0838, -0.0690,  0.0407, -0.0469, -0.0830,\n",
       "                       0.0476, -0.0911,  0.0646, -0.0305,  0.0552, -0.0173,  0.0654, -0.0165,\n",
       "                      -0.0145,  0.0141,  0.0367, -0.0708,  0.0579, -0.0807,  0.0169, -0.0785,\n",
       "                       0.0889, -0.0184, -0.0423,  0.0608, -0.0790, -0.0299, -0.0421, -0.0630,\n",
       "                       0.0710, -0.0726,  0.0449,  0.0740,  0.0097,  0.0709,  0.0812,  0.0706,\n",
       "                      -0.0293, -0.0520, -0.0843, -0.0339, -0.0529,  0.0435,  0.0434, -0.0079,\n",
       "                       0.0291, -0.0053, -0.0588, -0.0753, -0.0796, -0.0478, -0.0232,  0.0855,\n",
       "                       0.0289,  0.0626, -0.0160, -0.0115,  0.0720, -0.0412, -0.0098, -0.0584,\n",
       "                       0.0734,  0.0111,  0.0192, -0.0081,  0.0407, -0.0622,  0.0797, -0.0579,\n",
       "                       0.0755,  0.0276, -0.0805,  0.0606,  0.0866, -0.0576, -0.0710,  0.0492,\n",
       "                      -0.0688, -0.0425,  0.0571,  0.0250, -0.0705, -0.0713,  0.0935,  0.0258,\n",
       "                       0.0579, -0.0378,  0.0389, -0.0339, -0.0560,  0.0617,  0.0055, -0.0375,\n",
       "                      -0.0525, -0.0497, -0.0276, -0.0244, -0.0518, -0.0198, -0.0677,  0.0498],\n",
       "                     device='cuda:0')),\n",
       "             ('model.3.weight',\n",
       "              tensor([ 0.4583,  1.2607,  0.7646,  1.2960,  1.4134,  0.6353,  0.7664,  1.2482,\n",
       "                       0.6621,  0.6285,  1.0020,  1.1978,  0.9286,  1.3780,  0.7911,  0.8672,\n",
       "                       1.0604,  1.1737,  1.1940,  1.3752,  0.7558,  0.9934,  0.7512,  0.9008,\n",
       "                       0.8253,  0.8240,  1.4970,  1.0063,  1.2295,  0.7510,  1.3020,  1.4482,\n",
       "                       0.9590,  1.3699,  0.9543,  1.3979,  0.8211,  1.3392,  0.8540,  1.1500,\n",
       "                       1.2916,  0.5618,  1.1282,  0.9454,  1.2657,  1.3382,  0.7745,  1.1512,\n",
       "                       0.6849,  1.1732,  0.7793,  0.9220,  1.0517,  1.4551,  1.3673,  1.0301,\n",
       "                       0.8926,  1.3300,  0.6955,  0.9888,  1.1725,  0.9241,  1.4329,  1.1216,\n",
       "                       0.9455,  0.8838,  0.8866,  1.3616,  0.9114,  1.4038,  1.2319,  1.5142,\n",
       "                       1.3992,  1.4638,  0.7771,  0.8319,  1.2448,  0.7255,  0.6808,  1.5617,\n",
       "                       1.0187,  1.5165,  1.2686,  1.0159,  1.1998,  1.3155,  1.2163,  0.8588,\n",
       "                       0.7179,  0.6861,  1.3683,  0.7632,  0.6676,  1.0124,  1.0381,  1.3727,\n",
       "                       1.0732,  0.7893,  1.4073,  1.1609,  1.3800,  0.8818,  0.9750,  1.1893,\n",
       "                       1.1772,  0.8817,  1.0348,  0.7039,  0.7303,  1.1278,  1.1811,  0.9360,\n",
       "                       1.4394,  0.5648,  1.3181,  1.1899,  0.9315,  1.2835,  0.9258,  0.8722,\n",
       "                       0.7019,  0.6849,  0.8550,  1.1432,  1.4409,  0.5496,  0.7113,  0.8930,\n",
       "                       1.3098,  0.7895,  0.7112,  1.1325,  0.7617,  0.8602,  1.1538,  1.3631,\n",
       "                       1.2437,  0.9658,  1.3763,  0.7281,  1.4074,  1.1143,  1.0004,  0.7849,\n",
       "                       1.2904,  1.2440,  1.0778,  1.2577,  0.9808,  0.5066,  1.4814,  1.3486,\n",
       "                       0.5996,  1.3564,  1.1470,  1.1381,  1.2057,  0.9470,  1.0341,  1.2796,\n",
       "                       1.3767,  0.6312,  0.8053,  0.9504,  1.2186,  0.8233,  0.7257,  1.2569,\n",
       "                       0.6360,  1.0851,  1.3198,  1.1042,  0.7667,  1.0205,  1.0232,  1.1805,\n",
       "                       1.3994,  1.2243,  0.6952,  1.2597,  0.9309,  0.9436,  0.7435,  1.2398,\n",
       "                       1.0228,  0.9933,  1.3001,  1.0797,  1.3617,  0.8079,  1.0432,  1.1143,\n",
       "                       0.8958,  1.2251,  0.9023,  0.7739,  0.8636,  0.9920,  0.6281,  1.2506,\n",
       "                       1.5369,  0.5180,  0.7352,  1.4435,  1.3439,  0.9228,  0.7353,  1.3666,\n",
       "                       0.7628,  0.9920, -0.5360,  0.5992,  0.8661,  0.8390,  0.9247,  1.3744,\n",
       "                       0.5237,  1.0980,  1.0305,  1.3595,  1.3778,  0.6370,  0.5510,  0.6234,\n",
       "                       0.9043,  0.8914,  0.8193,  0.5759,  1.1141,  0.9260,  1.4062,  0.9780,\n",
       "                       0.8116,  0.9569,  1.1024,  1.4829,  1.5760,  0.8361,  0.9638,  0.9729,\n",
       "                       0.8420,  1.3141,  1.1647,  0.7591,  1.3190,  0.9550,  1.2090,  1.1942,\n",
       "                       0.7803,  1.4855,  0.9788,  1.4939,  1.0396,  1.1741,  0.6299,  0.7521],\n",
       "                     device='cuda:0')),\n",
       "             ('model.3.bias',\n",
       "              tensor([-0.0920, -0.5246,  0.0145, -0.1033,  0.1112, -0.1458,  0.4000,  0.2041,\n",
       "                       0.2248,  0.1808,  0.1545,  0.3237,  0.1514,  0.2094,  0.3477,  0.1805,\n",
       "                       0.2320,  0.1585, -0.0114,  0.2668,  0.1647,  0.1291,  0.1304,  0.0322,\n",
       "                       0.2238,  0.5168,  0.0901,  0.0067,  0.1567,  0.1213,  0.1919, -0.1543,\n",
       "                       0.1677, -0.0499,  0.3006,  0.3203,  0.1165,  0.0334,  0.0365,  0.1212,\n",
       "                       0.2395, -0.0183,  0.2045,  0.1630,  0.0369,  0.0935,  0.0611,  0.1606,\n",
       "                       0.0295,  0.2048,  0.1198,  0.0708,  0.1118,  0.2257,  0.3083,  0.0400,\n",
       "                       0.0047,  0.1445,  0.0779,  0.2435,  0.1977,  0.2896,  0.2392,  0.4630,\n",
       "                       0.0946,  0.0279,  0.0190,  0.3265,  0.2257,  0.0450,  0.2679,  0.0926,\n",
       "                       0.2112, -0.1028,  0.0806,  0.1861,  0.1158,  0.1596,  0.0329,  0.0786,\n",
       "                       0.0252,  0.2385,  0.1392,  0.2297,  0.0836,  0.1085,  0.3328,  0.0726,\n",
       "                       0.0155,  0.2255,  0.2284,  0.0674,  0.0664,  0.2416, -0.0048,  0.2164,\n",
       "                       0.2549,  0.2300,  0.6386,  0.3314, -0.0020,  0.2378,  0.2011,  0.5319,\n",
       "                       0.0700, -0.0954,  0.1423,  0.0368,  0.0428,  0.0630, -0.0854,  0.1814,\n",
       "                      -0.1129,  0.3486,  0.1596,  0.1459, -0.0938,  0.0976,  0.3150, -0.0054,\n",
       "                       0.1449,  0.1853,  0.2287,  0.1032,  0.2170, -0.1585,  0.0735,  0.2201,\n",
       "                       0.1689,  0.2279,  0.1514, -0.0370,  0.0929,  0.0949, -0.0274,  0.1513,\n",
       "                       0.3076,  0.3055,  0.1063,  0.1418,  0.1206, -0.0021,  0.0776,  0.2063,\n",
       "                       0.0165,  0.0325, -0.0411,  0.1946,  0.0494, -0.4241,  0.3009,  0.2855,\n",
       "                       0.0434,  0.3727,  0.1390,  0.0627,  0.1056,  0.1210,  0.2453, -0.0931,\n",
       "                       0.1345, -0.1511,  0.0175,  0.1935, -0.1727,  0.1164,  0.3985,  0.3080,\n",
       "                       0.0778, -0.1282,  0.2166,  0.1422, -0.0729, -0.0195, -0.0108,  0.3618,\n",
       "                       0.3831,  0.2750,  0.2107,  0.2183,  0.2775,  0.1210,  0.0376,  0.1101,\n",
       "                       0.0957,  0.3673,  0.1109,  0.0517, -0.0021,  0.1122,  0.1111,  0.3759,\n",
       "                       0.2467, -0.0910,  0.0490,  0.2060,  0.2051,  0.1229,  0.2213, -0.0366,\n",
       "                       0.2185,  0.1676,  0.0267,  0.2696,  0.4004,  0.1687,  0.0504,  0.0007,\n",
       "                       0.1265,  0.1074, -0.0162,  0.3016,  0.2637, -0.0916,  0.2828,  0.0843,\n",
       "                       0.1942, -0.5349,  0.2134,  0.7140, -0.1453,  0.0794,  0.0879, -0.0169,\n",
       "                       0.0966,  0.1371,  0.2291,  0.1508,  0.2881,  0.3546,  0.0627,  0.2297,\n",
       "                       0.2137,  0.2298,  0.1238,  0.1742,  0.1366,  0.0237,  0.1733,  0.1317,\n",
       "                       0.0599,  0.0885,  0.2054,  0.1257,  0.3377,  0.1802,  0.1937,  0.1953,\n",
       "                       0.3351,  0.2742,  0.1659,  0.0127,  0.0900,  0.2428,  0.0001,  0.1309],\n",
       "                     device='cuda:0')),\n",
       "             ('model.3.running_mean',\n",
       "              tensor([-6.2416e-01, -1.5400e+00, -9.1282e-01, -1.1970e+00, -1.2155e+00,\n",
       "                      -1.5234e-01,  3.6823e-01, -5.8854e-01, -1.3648e-02, -9.2823e-01,\n",
       "                      -2.0649e+00, -5.5895e-01, -1.1529e+00, -1.0861e+00,  5.9932e-01,\n",
       "                      -1.2074e+00, -1.3756e+00, -1.9142e+00, -9.8849e-02, -8.5389e-01,\n",
       "                       6.2693e-02, -1.3735e+00,  3.2787e-01, -1.9906e+00, -5.7684e-01,\n",
       "                       5.6704e-01, -1.8392e-01,  3.6920e-01, -1.3385e+00, -7.4763e-01,\n",
       "                      -1.9426e+00,  4.6523e-01, -1.1525e+00,  2.6617e-02, -1.3715e-01,\n",
       "                      -2.0135e+00, -1.7219e+00,  5.3982e-01,  9.4202e-05, -1.1118e+00,\n",
       "                      -1.5815e+00, -6.3778e-01, -1.2547e+00, -1.5288e+00, -5.6622e-01,\n",
       "                      -2.1891e+00, -3.0078e-01, -1.5420e+00, -1.2299e+00, -1.8462e+00,\n",
       "                       2.9313e-01, -3.8949e-02, -1.3952e+00, -2.3407e+00, -3.4374e-01,\n",
       "                      -7.3857e-01, -1.1433e+00, -4.9318e-01, -1.1692e+00, -7.4026e-01,\n",
       "                      -1.8910e+00, -1.2546e+00, -1.1260e+00, -2.0265e-02, -1.7333e+00,\n",
       "                      -2.6905e+00, -5.0006e-01,  5.0945e-01, -2.2918e+00,  4.3317e-01,\n",
       "                      -1.0618e+00, -3.4207e-01, -3.4910e+00, -3.2305e-01, -7.8188e-01,\n",
       "                      -7.0902e-01,  1.3891e-01, -3.1925e-01, -1.6008e+00, -2.7603e-01,\n",
       "                      -3.9348e-01, -1.2434e+00, -1.1750e+00,  5.7247e-01, -2.1835e+00,\n",
       "                      -5.0293e-01, -1.8963e+00, -4.4357e-01,  6.3506e-01, -5.2943e-01,\n",
       "                       5.7376e-01, -1.3559e+00,  4.4703e-03, -1.4440e+00, -1.4060e-01,\n",
       "                       7.9435e-01, -1.2633e+00,  3.2494e-02, -1.2274e-01, -1.6664e+00,\n",
       "                      -2.3242e+00, -5.0799e-01, -9.8649e-01, -1.2559e+00, -2.3927e-01,\n",
       "                      -3.0871e-01, -1.1006e+00, -1.8047e-01,  8.6575e-01, -1.5333e+00,\n",
       "                      -6.1983e-01, -4.5734e-01, -1.3275e+00, -3.1729e-02, -2.5963e+00,\n",
       "                      -1.4110e+00, -1.1690e+00, -1.2485e+00, -4.1714e-01,  8.4472e-01,\n",
       "                       5.2903e-01, -2.7209e+00, -1.3827e+00, -1.6334e+00, -2.0056e+00,\n",
       "                      -1.8367e-02, -6.4077e-01, -1.2859e+00, -8.3441e-01,  2.6802e-01,\n",
       "                      -1.1340e+00,  1.7255e-01, -2.1575e+00, -1.1541e+00, -1.7422e+00,\n",
       "                      -5.0479e-01, -1.0336e+00,  5.5981e-01,  6.6649e-01,  3.9056e-01,\n",
       "                      -7.6565e-01, -1.1412e+00, -1.7433e-01, -2.9218e-01, -4.0868e-01,\n",
       "                       1.6083e-01, -1.6951e+00, -1.1521e+00, -8.4288e-01, -6.0608e-01,\n",
       "                      -1.3125e+00, -1.4003e+00,  9.4131e-02, -1.3916e+00, -1.1095e+00,\n",
       "                      -1.3630e+00, -6.5068e-01, -1.6089e+00, -2.5893e+00, -4.7607e-01,\n",
       "                      -1.1003e+00, -2.4522e+00, -2.0650e+00, -1.7748e+00, -3.0567e-01,\n",
       "                      -1.6625e-01, -1.6964e+00, -1.3040e+00, -3.9544e-01,  4.2508e-01,\n",
       "                      -1.7097e+00, -1.1483e+00, -8.6077e-01, -9.0635e-01, -2.2220e+00,\n",
       "                      -1.3702e+00, -2.4160e+00, -4.9252e-01, -1.0225e+00, -2.0828e+00,\n",
       "                      -1.7217e+00, -7.4000e-01, -1.6809e+00, -8.7804e-01, -1.1926e+00,\n",
       "                      -2.6375e+00,  4.4328e-01, -8.1153e-02, -1.3592e+00, -1.6176e+00,\n",
       "                       3.9349e-03, -1.2910e+00,  1.7380e-01, -1.0699e-01, -1.5868e+00,\n",
       "                       1.2922e+00,  1.5449e+00,  8.7358e-01,  1.0499e+00, -1.5293e+00,\n",
       "                      -1.5318e+00, -1.7947e-01,  2.2779e-01, -1.9166e+00, -1.0096e+00,\n",
       "                      -2.4426e+00, -1.5643e+00, -1.3757e-01, -5.1226e-01,  5.9926e-01,\n",
       "                       3.4382e-02,  1.2971e+00,  4.8193e-01, -4.2368e-01,  1.9704e-01,\n",
       "                      -2.5356e+00,  1.8008e+00, -1.9984e-01, -7.3745e-01, -5.9919e-01,\n",
       "                      -1.6438e-01,  9.8067e-01,  3.6156e-01,  3.3365e-01, -1.3999e+00,\n",
       "                      -1.9967e+00,  4.4062e-01, -3.3480e-01, -3.0088e-01, -2.4224e-01,\n",
       "                      -1.3449e+00,  6.4361e-01, -6.6105e-01, -3.7621e-01, -7.4859e-01,\n",
       "                      -3.5283e-01, -5.1110e-01, -7.3794e-01, -1.7023e+00, -1.1229e+00,\n",
       "                       1.4331e+00, -9.2938e-01,  6.2682e-01, -6.4634e-01, -1.7658e+00,\n",
       "                       1.0478e+00, -1.6296e-01, -1.5284e+00, -4.0274e-01, -1.3451e+00,\n",
       "                      -1.6373e+00, -9.3133e-01, -1.1055e+00,  9.9638e-01, -1.1646e+00,\n",
       "                      -3.3287e-03], device='cuda:0')),\n",
       "             ('model.3.running_var',\n",
       "              tensor([2.3545, 1.2184, 2.0843, 2.2472, 1.6641, 1.6895, 1.7053, 1.4816, 1.2783,\n",
       "                      1.4576, 2.1817, 1.8368, 1.5855, 2.8525, 1.8325, 1.6096, 2.7818, 4.1953,\n",
       "                      2.6566, 3.9101, 1.5044, 1.6677, 0.7845, 2.0430, 1.3762, 2.1824, 1.9651,\n",
       "                      2.7089, 2.7718, 1.8471, 2.3381, 4.3375, 1.7244, 3.4244, 1.7953, 1.9708,\n",
       "                      1.6323, 2.6304, 2.1418, 1.7088, 4.4796, 2.3151, 2.0937, 2.7473, 2.6137,\n",
       "                      1.5348, 1.4104, 1.3573, 2.1549, 1.0487, 2.6099, 1.3372, 2.1699, 2.1777,\n",
       "                      1.8536, 1.6858, 4.4514, 1.6896, 1.6342, 1.9451, 2.4892, 2.0595, 1.7460,\n",
       "                      1.8620, 1.6340, 1.7661, 2.6932, 2.3525, 1.1410, 5.4102, 1.9003, 3.0366,\n",
       "                      1.1956, 3.8072, 2.0221, 2.2859, 2.0752, 1.6465, 1.6676, 3.0669, 1.7894,\n",
       "                      2.2405, 1.3010, 2.4587, 1.7503, 1.8145, 1.6571, 1.1283, 3.0600, 1.4123,\n",
       "                      1.8619, 1.8775, 1.9105, 1.4283, 3.0755, 4.7748, 1.2126, 1.4039, 1.9000,\n",
       "                      1.7606, 1.6130, 1.1706, 1.3164, 1.3838, 1.8173, 3.0680, 1.4188, 4.0242,\n",
       "                      2.1003, 1.1151, 1.7602, 2.2790, 1.8115, 2.5346, 1.3515, 2.3627, 3.0953,\n",
       "                      2.8343, 1.4630, 3.4450, 2.3931, 0.6329, 1.5402, 0.9908, 1.0518, 2.4607,\n",
       "                      1.1656, 2.1710, 2.8288, 3.2231, 2.1552, 1.9832, 1.9465, 1.5683, 2.2453,\n",
       "                      2.8159, 2.3980, 1.6510, 3.8515, 1.7510, 1.9612, 3.5180, 1.9176, 1.4171,\n",
       "                      1.5948, 2.3731, 1.3095, 1.6401, 2.5703, 2.0328, 1.3262, 2.3572, 2.3789,\n",
       "                      3.3911, 3.6715, 2.3153, 0.9931, 1.5330, 2.0531, 2.2295, 0.8946, 2.7065,\n",
       "                      1.0747, 1.2281, 2.9197, 1.1441, 0.6519, 2.2817, 2.3997, 3.2979, 1.9204,\n",
       "                      1.9021, 2.0438, 2.6729, 1.6481, 1.6012, 1.3368, 2.1990, 1.7991, 1.6010,\n",
       "                      1.2789, 1.0520, 3.4022, 2.3472, 0.9930, 3.6841, 5.0421, 1.5624, 1.1806,\n",
       "                      1.2711, 3.3416, 1.2998, 1.1869, 1.7376, 1.2789, 1.9695, 1.3456, 3.0503,\n",
       "                      2.0852, 4.8481, 2.1736, 2.1815, 3.0391, 1.3144, 2.4559, 2.7945, 3.3193,\n",
       "                      1.7377, 1.7027, 2.4196, 2.6491, 1.8612, 1.4723, 2.6957, 3.2200, 1.7946,\n",
       "                      0.7203, 2.4458, 2.0494, 1.8935, 2.1103, 1.2713, 0.9617, 2.8072, 1.7625,\n",
       "                      4.2444, 1.0697, 1.1227, 3.8302, 2.6573, 4.9408, 2.2452, 4.0038, 2.3726,\n",
       "                      2.3409, 2.8194, 3.3566, 3.7008, 2.5105, 1.8905, 2.1331, 5.4341, 1.9948,\n",
       "                      2.6795, 1.5763, 1.3909, 2.6098, 1.3792, 1.9424, 1.4134, 2.6573, 2.1839,\n",
       "                      1.2293, 2.8679, 1.8088, 1.9258], device='cuda:0')),\n",
       "             ('model.3.num_batches_tracked', tensor(6063600, device='cuda:0')),\n",
       "             ('model.5.weight',\n",
       "              tensor([[-0.0672, -0.0503, -0.0372,  ...,  0.0336,  0.0493,  0.1184],\n",
       "                      [ 0.0034, -0.1014, -0.1444,  ..., -0.0532, -0.1117,  0.0256],\n",
       "                      [-0.1156,  0.0916, -0.0581,  ..., -0.0115, -0.0590, -0.0660],\n",
       "                      ...,\n",
       "                      [ 0.0930,  0.0997,  0.0974,  ..., -0.1128,  0.0167,  0.0980],\n",
       "                      [-0.0175, -0.0132, -0.0666,  ...,  0.0735,  0.0230,  0.0522],\n",
       "                      [-0.0335,  0.0307, -0.0181,  ...,  0.0571,  0.0451, -0.1051]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.5.bias',\n",
       "              tensor([ 0.0505,  0.0209, -0.0127, -0.0116, -0.0100,  0.0456,  0.0355, -0.0596,\n",
       "                       0.0139,  0.0166, -0.0361, -0.0112,  0.0128,  0.0234,  0.0007, -0.0228,\n",
       "                       0.0292,  0.0561,  0.0375, -0.0301,  0.0211, -0.0538, -0.0284,  0.0650,\n",
       "                      -0.0556, -0.0374,  0.0131, -0.0039, -0.0016,  0.0618, -0.0198, -0.0288,\n",
       "                      -0.0296, -0.0198, -0.0161, -0.0256, -0.0467,  0.0384,  0.0203,  0.0378,\n",
       "                      -0.0231,  0.0607,  0.0658, -0.0243,  0.0131,  0.0575,  0.0387,  0.0673,\n",
       "                       0.0556,  0.0026,  0.0084, -0.0040, -0.0537, -0.0011,  0.0332, -0.0220,\n",
       "                      -0.0160,  0.0074,  0.0542,  0.0447,  0.0326,  0.0455, -0.0136,  0.0276,\n",
       "                      -0.0172, -0.0315, -0.0008,  0.0557, -0.0119, -0.0388, -0.0365,  0.0408,\n",
       "                      -0.0197,  0.0467,  0.0424,  0.0014, -0.0161,  0.0333, -0.0475,  0.0597,\n",
       "                       0.0205,  0.0357,  0.0031, -0.0259,  0.0444, -0.0263, -0.0135, -0.0076,\n",
       "                       0.0202,  0.0537, -0.0477,  0.0537, -0.0160, -0.0014,  0.0258,  0.0288,\n",
       "                       0.0150, -0.0312, -0.0199,  0.0384,  0.0460,  0.0428,  0.0538,  0.0577,\n",
       "                       0.0400, -0.0019, -0.0077, -0.0307,  0.0669,  0.0191,  0.0005, -0.0395,\n",
       "                      -0.0265,  0.0344, -0.0087, -0.0455, -0.0339, -0.0342, -0.0026,  0.0104,\n",
       "                      -0.0475, -0.0055, -0.0336,  0.0330,  0.0289,  0.0141, -0.0319, -0.0157,\n",
       "                      -0.0321,  0.0418,  0.0492, -0.0222,  0.0247,  0.0084,  0.0405,  0.0109,\n",
       "                       0.0505,  0.0455,  0.0577, -0.0207,  0.0102,  0.0496, -0.0224,  0.0624,\n",
       "                      -0.0338,  0.0340, -0.0475,  0.0226,  0.0571, -0.0485,  0.0009,  0.0329,\n",
       "                       0.0048, -0.0355, -0.0101, -0.0384,  0.0112,  0.0174, -0.0349,  0.0590,\n",
       "                       0.0550, -0.0515,  0.0466,  0.0144,  0.0276, -0.0479, -0.0375, -0.0199,\n",
       "                       0.0195,  0.0266, -0.0400, -0.0278,  0.0514,  0.0657,  0.0535, -0.0521,\n",
       "                       0.0020,  0.0218,  0.0154, -0.0455, -0.0115,  0.0237,  0.0229, -0.0532,\n",
       "                       0.0076,  0.0009,  0.0083, -0.0070, -0.0258,  0.0005, -0.0281, -0.0472,\n",
       "                       0.0405,  0.0610,  0.0071,  0.0310,  0.0659, -0.0546, -0.0147, -0.0479,\n",
       "                       0.0548, -0.0477, -0.0583,  0.0127,  0.0116,  0.0383, -0.0019,  0.0551,\n",
       "                      -0.0391,  0.0208, -0.0526,  0.0609, -0.0643, -0.0234, -0.0252, -0.0385,\n",
       "                       0.0277, -0.0361,  0.0589,  0.0106,  0.0596, -0.0224,  0.0613,  0.0087,\n",
       "                       0.0372,  0.0258,  0.0197, -0.0166,  0.0109, -0.0484, -0.0161,  0.0168,\n",
       "                      -0.0086, -0.0101,  0.0499,  0.0692,  0.0311,  0.0051,  0.0011,  0.0140,\n",
       "                      -0.0051,  0.0235,  0.0397,  0.0391,  0.0238, -0.0029, -0.0248, -0.0313,\n",
       "                       0.0373,  0.0200,  0.0348, -0.0359,  0.0051, -0.0489, -0.0449,  0.0115,\n",
       "                      -0.0139, -0.0343,  0.0230, -0.0093, -0.0123,  0.0250, -0.0527, -0.0128,\n",
       "                      -0.0421,  0.0591,  0.0258,  0.0369,  0.0249,  0.0571, -0.0238,  0.0563,\n",
       "                      -0.0497, -0.0070, -0.0303,  0.0035,  0.0473, -0.0115,  0.0179, -0.0416,\n",
       "                       0.0476,  0.0150,  0.0300,  0.0271,  0.0292,  0.0058,  0.0341,  0.0543,\n",
       "                       0.0020,  0.0046, -0.0321, -0.0309, -0.0122,  0.0107,  0.0386, -0.0349,\n",
       "                      -0.0275, -0.0217,  0.0070,  0.0187, -0.0252, -0.0024, -0.0471,  0.0185,\n",
       "                       0.0387,  0.0154, -0.0272,  0.0353,  0.0113,  0.0090,  0.0528,  0.0303,\n",
       "                      -0.0507,  0.0072, -0.0538, -0.0255,  0.0679,  0.0532, -0.0348,  0.0048,\n",
       "                       0.0381, -0.0524, -0.0034, -0.0419,  0.0151,  0.0331,  0.0746, -0.0456,\n",
       "                      -0.0488,  0.0311, -0.0107, -0.0318,  0.0506, -0.0208,  0.0011, -0.0107,\n",
       "                       0.0071, -0.0624,  0.0223,  0.0620, -0.0092,  0.0200, -0.0180, -0.0314,\n",
       "                       0.0325, -0.0112, -0.0234, -0.0287,  0.0588, -0.0312,  0.0221,  0.0197,\n",
       "                       0.0348,  0.0310,  0.0051,  0.0062, -0.0138, -0.0373, -0.0337, -0.0252,\n",
       "                       0.0607,  0.0643,  0.0474, -0.0224,  0.0021,  0.0639, -0.0339,  0.0532,\n",
       "                       0.0258, -0.0216, -0.0397,  0.0259,  0.0237,  0.0093,  0.0506, -0.0569,\n",
       "                      -0.0329,  0.0603,  0.0253,  0.0331,  0.0072, -0.0606, -0.0017,  0.0650,\n",
       "                      -0.0365,  0.0112, -0.0007,  0.0298,  0.0250,  0.0124,  0.0198,  0.0540,\n",
       "                       0.0337,  0.0199, -0.0286,  0.0072,  0.0074, -0.0037,  0.0265,  0.0299,\n",
       "                       0.0159, -0.0145,  0.0638, -0.0532, -0.0103, -0.0073,  0.0305, -0.0208,\n",
       "                      -0.0527, -0.0594,  0.0150,  0.0189, -0.0217,  0.0178, -0.0466,  0.0140,\n",
       "                       0.0040, -0.0203,  0.0210, -0.0367, -0.0450,  0.0320,  0.0497, -0.0549,\n",
       "                       0.0491,  0.0393,  0.0457, -0.0479, -0.0351, -0.0097, -0.0474,  0.0254,\n",
       "                      -0.0242, -0.0459,  0.0634,  0.0126,  0.0333, -0.0596, -0.0421,  0.0148,\n",
       "                       0.0514, -0.0224,  0.0665, -0.0427,  0.0566,  0.0206,  0.0388, -0.0409,\n",
       "                      -0.0108, -0.0291,  0.0351,  0.0020,  0.0163, -0.0465,  0.0284,  0.0206,\n",
       "                       0.0635,  0.0505, -0.0187, -0.0433, -0.0135,  0.0529, -0.0182,  0.0217,\n",
       "                       0.0005, -0.0440,  0.0323, -0.0522,  0.0438,  0.0429, -0.0425, -0.0041,\n",
       "                       0.0105,  0.0474, -0.0498,  0.0064,  0.0654,  0.0226, -0.0332, -0.0584,\n",
       "                       0.0661, -0.0143, -0.0545,  0.0290,  0.0625,  0.0671,  0.0296, -0.0093,\n",
       "                      -0.0131,  0.0544,  0.0075, -0.0408, -0.0151,  0.0634,  0.0016,  0.0522,\n",
       "                       0.0248, -0.0348,  0.0504,  0.0528, -0.0110,  0.0406,  0.0632,  0.0403,\n",
       "                      -0.0089,  0.0247, -0.0511,  0.0243, -0.0429,  0.0011, -0.0192,  0.0463],\n",
       "                     device='cuda:0')),\n",
       "             ('model.6.weight',\n",
       "              tensor([1.7374, 1.4916, 1.7049, 1.7482, 1.3784, 1.8147, 1.6606, 1.1442, 1.6262,\n",
       "                      1.1546, 1.6465, 1.7605, 1.8603, 1.2384, 1.4509, 1.2205, 0.7920, 1.3939,\n",
       "                      1.5055, 1.4192, 1.6416, 1.4622, 1.2987, 1.6299, 1.2581, 1.4722, 1.8239,\n",
       "                      1.7218, 1.2445, 1.5911, 1.7742, 1.2058, 1.9922, 1.4658, 1.9366, 1.8047,\n",
       "                      1.4419, 1.2710, 1.5268, 1.6091, 1.1931, 1.6230, 1.1428, 1.2848, 1.1398,\n",
       "                      1.4711, 1.3008, 1.6290, 1.0790, 1.7298, 1.3337, 1.5444, 0.8346, 1.5423,\n",
       "                      1.1635, 1.1195, 1.8181, 1.5368, 1.4557, 1.0039, 1.5455, 1.2847, 1.6082,\n",
       "                      0.8449, 1.4439, 1.5488, 1.3890, 1.3915, 1.4751, 1.4804, 1.2039, 1.7470,\n",
       "                      1.3300, 0.8091, 1.4413, 1.5103, 1.7257, 1.4481, 0.8500, 0.9412, 0.7032,\n",
       "                      1.2238, 1.2626, 1.3120, 1.8412, 0.7790, 1.3696, 0.9753, 1.3440, 1.6407,\n",
       "                      1.8175, 1.5330, 1.5943, 1.0247, 1.3044, 1.5895, 1.5516, 1.2227, 1.4376,\n",
       "                      1.8283, 1.0504, 1.5443, 1.8709, 1.1615, 0.8604, 1.2987, 1.7048, 1.3423,\n",
       "                      1.8107, 1.3866, 1.3914, 1.4801, 1.5988, 1.2836, 1.1989, 1.1283, 1.5838,\n",
       "                      1.6350, 0.7596, 1.6195, 1.5925, 1.3004, 1.7232, 1.1101, 1.8051, 1.3606,\n",
       "                      1.2431, 1.7436, 0.9584, 1.3403, 1.1163, 1.4988, 1.4487, 0.9620, 1.5892,\n",
       "                      1.8328, 1.4648, 1.0491, 1.4263, 1.2701, 1.5644, 1.4062, 1.3342, 0.9396,\n",
       "                      1.8134, 1.2453, 1.2571, 1.6317, 1.4351, 1.4968, 1.6638, 1.6391, 1.2895,\n",
       "                      1.5955, 1.5099, 0.8766, 1.4763, 1.6624, 1.1813, 1.4848, 1.3634, 0.9382,\n",
       "                      1.8964, 1.0625, 1.0591, 1.2632, 1.3160, 1.2270, 1.5222, 1.4376, 1.1671,\n",
       "                      1.7437, 1.1316, 1.7532, 0.8189, 1.6340, 1.3384, 1.8331, 1.1967, 1.1145,\n",
       "                      1.4070, 1.1979, 1.6256, 1.2102, 1.1929, 1.4722, 1.8830, 1.1466, 1.7004,\n",
       "                      1.0620, 0.9009, 1.5781, 1.3217, 1.6492, 1.0092, 1.5100, 1.7234, 1.8418,\n",
       "                      1.2676, 0.7868, 1.6386, 1.6160, 1.0134, 1.2154, 1.6110, 1.6542, 1.9000,\n",
       "                      1.1307, 1.4564, 0.7344, 1.3357, 1.6209, 1.4411, 1.6754, 0.9661, 1.3473,\n",
       "                      1.6757, 1.3202, 1.6677, 1.4859, 1.1093, 1.3816, 1.6070, 1.5932, 1.5910,\n",
       "                      1.8347, 1.2869, 1.8852, 1.4660, 1.4741, 1.4686, 1.3064, 1.4430, 1.2906,\n",
       "                      1.4820, 1.7041, 1.4202, 1.1672, 1.6734, 1.5928, 1.8403, 1.3700, 1.4072,\n",
       "                      1.2809, 1.6241, 1.3881, 1.1275, 1.2954, 1.1512, 1.6642, 1.1080, 1.2368,\n",
       "                      1.1314, 1.6444, 1.1081, 1.2950, 1.4710, 1.6136, 1.2241, 1.1066, 1.5338,\n",
       "                      1.5332, 0.6641, 0.9986, 0.8066, 1.4087, 1.8947, 1.2017, 1.4566, 0.6466,\n",
       "                      1.7471, 1.3328, 1.7529, 0.9475, 1.1597, 1.5438, 1.2204, 1.2443, 1.0265,\n",
       "                      1.2165, 1.4336, 1.2656, 1.4393, 1.4115, 1.0311, 1.3435, 1.3961, 1.7397,\n",
       "                      1.7516, 1.6849, 1.7668, 1.0663, 1.0416, 1.1602, 1.3646, 1.3643, 1.5170,\n",
       "                      1.2499, 1.3342, 1.7090, 1.3425, 1.8315, 1.6146, 1.3929, 1.8117, 1.5591,\n",
       "                      1.4580, 1.0013, 0.8514, 1.4948, 1.4804, 1.3750, 1.4818, 1.9015, 1.1322,\n",
       "                      1.2130, 1.9915, 1.5446, 1.1669, 1.1174, 1.8146, 1.4113, 1.1833, 1.2072,\n",
       "                      1.5761, 1.7732, 1.7547, 1.1945, 1.5093, 1.5342, 1.3077, 1.3304, 0.9991,\n",
       "                      1.6232, 1.0633, 1.0838, 1.8437, 1.6446, 1.5795, 0.8141, 1.5477, 1.8000,\n",
       "                      0.7596, 1.7181, 1.3135, 1.7874, 1.6780, 1.6529, 1.4457, 1.1268, 1.8308,\n",
       "                      1.8031, 1.6385, 1.3467, 1.2019, 1.8507, 1.3548, 0.9443, 1.4909, 1.1448,\n",
       "                      1.8583, 1.4457, 1.5502, 1.2775, 1.6440, 1.3546, 1.2992, 1.6329, 0.8442,\n",
       "                      1.2461, 1.5302, 0.9077, 1.5336, 1.1879, 1.3909, 1.3983, 1.6957, 1.6475,\n",
       "                      1.4333, 1.3662, 1.6393, 0.7593, 1.4258, 1.3383, 1.3996, 1.2560, 1.7702,\n",
       "                      1.3236, 1.5807, 1.7242, 1.6151, 1.2474, 1.6155, 1.5889, 1.2031, 1.7059,\n",
       "                      1.7943, 1.7529, 1.4603, 1.7457, 1.2308, 1.6137, 1.2174, 1.5749, 1.4976,\n",
       "                      1.7390, 1.7337, 1.1081, 1.5158, 1.2543, 1.4626, 1.3571, 1.5462, 1.6037,\n",
       "                      0.8558, 1.3543, 1.8407, 1.8536, 1.4825, 1.2128, 0.8975, 1.3384, 1.3925,\n",
       "                      1.0817, 1.6675, 1.5534, 1.7660, 1.1845, 1.3504, 1.6557, 1.7539, 1.2544,\n",
       "                      1.7202, 1.3403, 1.2272, 1.2150, 1.3754, 1.1888, 1.8601, 1.0634, 1.7873,\n",
       "                      0.8839, 1.5764, 1.3052, 1.2501, 1.1742, 1.5938, 1.2428, 1.1378, 1.8424,\n",
       "                      0.8879, 1.4373, 1.3239, 0.7571, 1.0998, 1.3544, 1.4895, 1.6302, 1.7299,\n",
       "                      1.6010, 1.5543, 1.4113, 1.0022, 1.5738, 1.7329, 1.7849, 1.4405, 1.6296,\n",
       "                      1.5318, 1.4363, 1.1454, 1.7848, 1.7974, 0.9199, 1.6464, 1.7904, 1.2375,\n",
       "                      1.0889, 1.8487, 0.8884, 1.6247, 1.4100, 1.6515, 1.6484, 1.1498, 1.3726,\n",
       "                      1.1856, 1.4280, 1.0870, 1.8684, 1.4204, 1.5540, 1.4871, 1.4507, 1.2075,\n",
       "                      1.1231, 1.4982, 1.8042, 1.1529, 1.8638, 1.3638, 1.5070, 1.7533, 1.7215,\n",
       "                      1.0803, 1.2660, 1.5142, 1.0073, 1.3708, 1.6761, 1.4579, 1.8011],\n",
       "                     device='cuda:0')),\n",
       "             ('model.6.bias',\n",
       "              tensor([ 0.2649,  0.1345,  0.3335,  0.0898,  0.1045,  0.0308,  0.2365, -0.0065,\n",
       "                       0.1332,  0.1187,  0.1727,  0.2065,  0.0517,  0.2411,  0.2561,  0.1003,\n",
       "                       0.0052,  0.2349,  0.2468,  0.0707,  0.0568,  0.0387,  0.1534,  0.2675,\n",
       "                      -0.0707,  0.1469,  0.1493,  0.0711,  0.2813,  0.0496,  0.2151,  0.1505,\n",
       "                       0.0664,  0.0877,  0.2593,  0.1144,  0.3751,  0.1213, -0.0391,  0.0374,\n",
       "                       0.1826,  0.1807, -0.0294,  0.0764,  0.1334, -0.0004,  0.1506,  0.2111,\n",
       "                       0.0505,  0.1393,  0.3124,  0.0940,  0.0407,  0.3114,  0.0771,  0.0812,\n",
       "                       0.2357,  0.0675,  0.0851,  0.0620,  0.2065,  0.0114,  0.2997,  0.0921,\n",
       "                       0.0544,  0.0351,  0.0855,  0.1088,  0.0509,  0.1867, -0.0820,  0.1747,\n",
       "                       0.1299,  0.0516,  0.2118,  0.2080,  0.2415,  0.2525, -0.1193,  0.1791,\n",
       "                       0.0272,  0.0598,  0.2137,  0.1714,  0.0326, -0.0392,  0.1397,  0.0326,\n",
       "                       0.1822,  0.0700,  0.3428,  0.1487,  0.2129,  0.1466,  0.0751,  0.1415,\n",
       "                       0.0823,  0.1398,  0.1484,  0.1905,  0.0958,  0.1017,  0.1893,  0.2965,\n",
       "                       0.1121,  0.1497,  0.2746,  0.1326,  0.1295,  0.1861,  0.1807,  0.2837,\n",
       "                       0.2847,  0.1911,  0.0915,  0.1699,  0.1982, -0.0188, -0.0211,  0.1934,\n",
       "                       0.1001,  0.1578,  0.1821,  0.0736,  0.1968,  0.3036,  0.1113,  0.2396,\n",
       "                       0.1257,  0.1975,  0.1058,  0.2584,  0.2632,  0.1560,  0.2707,  0.1893,\n",
       "                       0.3731,  0.0448,  0.1981,  0.0966,  0.1496,  0.1378,  0.1132,  0.1222,\n",
       "                       0.1940,  0.0900,  0.1780,  0.2385,  0.1979, -0.0111,  0.0891,  0.2460,\n",
       "                       0.2184,  0.0742,  0.1643, -0.0661,  0.1512,  0.0568,  0.1523,  0.0371,\n",
       "                       0.1040,  0.0098,  0.2287,  0.1512,  0.0905,  0.1122,  0.1044,  0.3280,\n",
       "                       0.1726,  0.0437, -0.0277,  0.1301,  0.2462,  0.1470,  0.0310,  0.0196,\n",
       "                      -0.0281,  0.2882,  0.1231,  0.1514,  0.0581,  0.1685,  0.0724, -0.0735,\n",
       "                       0.0609,  0.1817,  0.0847,  0.0549,  0.2460, -0.0714,  0.1468,  0.2664,\n",
       "                       0.0857,  0.1188,  0.2121,  0.2635,  0.3618,  0.1631,  0.1906,  0.1064,\n",
       "                       0.1330,  0.1666,  0.0541,  0.0475,  0.0892, -0.0524,  0.0769,  0.0317,\n",
       "                       0.0537, -0.0999,  0.0181,  0.1922, -0.5303,  0.0564,  0.0670,  0.1358,\n",
       "                       0.1788,  0.1378,  0.1847,  0.0815,  0.0649,  0.2215,  0.2015,  0.1145,\n",
       "                       0.1243,  0.2888, -0.0120,  0.2025,  0.1812,  0.1958,  0.1843,  0.3719,\n",
       "                       0.1859,  0.2416,  0.1699,  0.1428,  0.1153,  0.0755,  0.1995,  0.2404,\n",
       "                       0.2644,  0.2205,  0.0085,  0.2450,  0.2554,  0.0665,  0.1557,  0.0124,\n",
       "                       0.0598,  0.1423,  0.2363, -0.1062,  0.1320,  0.1643,  0.1073,  0.2666,\n",
       "                       0.4334, -0.0365,  0.1331,  0.2520,  0.2346, -0.0291,  0.0440,  0.0478,\n",
       "                       0.0473,  0.2361,  0.1248,  0.2121,  0.2307,  0.0472,  0.1924,  0.0849,\n",
       "                       0.0486,  0.0515,  0.0822,  0.1395,  0.1524,  0.1097,  0.2530,  0.0639,\n",
       "                       0.2249,  0.2814,  0.0783,  0.1452,  0.1340,  0.1979,  0.0939,  0.3411,\n",
       "                       0.1573,  0.2395,  0.0793,  0.2630, -0.0069,  0.2392,  0.0273,  0.1044,\n",
       "                       0.0928,  0.1938,  0.0895, -0.0366,  0.0583,  0.1312,  0.1091,  0.0392,\n",
       "                       0.1599,  0.1403,  0.0528,  0.1434, -0.0343,  0.2807,  0.2184,  0.2092,\n",
       "                       0.1232,  0.4120,  0.0781,  0.2405,  0.3043,  0.1833, -0.0560,  0.0466,\n",
       "                       0.1001,  0.1637,  0.0657,  0.0142,  0.4293,  0.2682,  0.2244,  0.2818,\n",
       "                       0.2813,  0.1134,  0.2645,  0.0682,  0.1327,  0.0717,  0.1810,  0.0698,\n",
       "                       0.1199,  0.1246,  0.1994,  0.0158,  0.0990, -0.0330,  0.1165,  0.2294,\n",
       "                       0.1358,  0.1783,  0.2927,  0.1309,  0.2307, -0.0885,  0.2068,  0.2269,\n",
       "                       0.1326,  0.3200,  0.1649,  0.2214,  0.1892,  0.0258,  0.2154,  0.2412,\n",
       "                       0.2560,  0.1841,  0.3492,  0.3297,  0.1914,  0.2261,  0.1940,  0.1707,\n",
       "                       0.1197,  0.0769, -0.2673,  0.0422,  0.3258,  0.2048,  0.1433,  0.0940,\n",
       "                       0.0954,  0.2345,  0.0916,  0.1700, -0.0467, -0.0343,  0.2079,  0.0755,\n",
       "                       0.1785,  0.1840,  0.0165, -0.0483,  0.0459,  0.1112,  0.0596,  0.1044,\n",
       "                       0.2942,  0.2553,  0.2156,  0.0810,  0.1166,  0.0420,  0.2439,  0.3663,\n",
       "                       0.0499,  0.3357,  0.0462,  0.1862, -0.0018,  0.1241,  0.5316,  0.0379,\n",
       "                       0.1718,  0.0904, -0.0234,  0.0117,  0.0964,  0.0247, -0.0054,  0.1236,\n",
       "                       0.1277,  0.1365,  0.1333,  0.1500,  0.0537,  0.1221,  0.1138,  0.1191,\n",
       "                       0.0883,  0.2156,  0.2015,  0.0991,  0.2554,  0.1415,  0.2139,  0.0762,\n",
       "                       0.2384,  0.2519,  0.0970, -0.0038,  0.1696,  0.1359,  0.3898,  0.1074,\n",
       "                       0.1501,  0.0645,  0.1276,  0.1194,  0.1185,  0.1552,  0.1357,  0.1417,\n",
       "                       0.1504,  0.1678,  0.0120,  0.1758,  0.0124,  0.0268,  0.1465,  0.0672,\n",
       "                       0.0891,  0.2133,  0.1913,  0.3145,  0.3983,  0.0820,  0.1113,  0.1174,\n",
       "                       0.1805,  0.1737,  0.2342, -0.0602, -0.0153,  0.0799,  0.1505,  0.0887,\n",
       "                       0.1621, -0.0131,  0.0139,  0.1471,  0.2511,  0.0589,  0.3869,  0.1556,\n",
       "                       0.1044,  0.1383,  0.1277,  0.3165,  0.0716,  0.1912,  0.1737,  0.1406,\n",
       "                       0.1290, -0.1022,  0.1119,  0.0430,  0.0961,  0.0147, -0.1083,  0.3385,\n",
       "                       0.0445,  0.3480,  0.1592,  0.2122,  0.1870,  0.2734,  0.1695,  0.2068,\n",
       "                       0.1828,  0.3247,  0.0594,  0.0073,  0.2421,  0.3301,  0.0103,  0.2371],\n",
       "                     device='cuda:0')),\n",
       "             ('model.6.running_mean',\n",
       "              tensor([ 2.3790, -0.0318, -0.2101, -1.4251,  1.7602, -0.0287,  0.9288, -3.3650,\n",
       "                       1.3573, -2.2887, -1.5106, -2.5442, -1.8490, -2.6308,  0.8589, -1.1930,\n",
       "                       1.3564,  0.8962, -0.2544, -3.6827, -0.7466, -0.3766,  0.2866,  0.9605,\n",
       "                       0.1373,  3.2867,  0.0233, -1.8891, -1.5775, -0.1717, -2.1036,  1.3624,\n",
       "                      -2.7969, -1.2223,  0.0320, -1.1190, -2.9013, -3.5262, -2.2240, -0.4516,\n",
       "                      -1.8716,  1.1759, -2.6215, -3.4174,  2.4899,  1.1523, -0.9460, -3.0588,\n",
       "                      -1.3117,  0.0890, -0.4828,  1.7498, -0.7228, -2.3679,  1.3301,  1.7060,\n",
       "                       0.9569, -2.7237, -0.2200,  0.1797, -2.4594, -1.6081,  0.1831,  2.7539,\n",
       "                      -2.0534,  4.0103, -0.9180, -1.3938, -0.5364, -2.1981,  1.8090, -1.1779,\n",
       "                      -2.1134,  1.3973, -1.3884, -2.3956, -0.1896, -3.1743,  2.6815,  4.5229,\n",
       "                       2.8615, -0.2955, -0.6181,  2.8549, -1.9363,  0.9584, -1.9379,  1.8633,\n",
       "                       2.6857,  1.7162, -0.6913, -2.4057,  2.0931, -1.4402, -0.0019,  3.5852,\n",
       "                      -1.2208,  3.1758,  0.4146, -0.2311,  3.2021, -0.6624, -2.4979, -2.2278,\n",
       "                       1.6648, -2.8161, -2.2886, -2.0897, -3.0407,  1.3516, -2.6121,  3.7240,\n",
       "                      -3.1547,  3.6422,  1.1811, -0.2608,  0.1969,  0.1335,  1.7424, -0.2687,\n",
       "                      -3.1084,  2.3939, -0.2741,  2.6189, -0.2982, -1.5854, -2.9636, -0.7315,\n",
       "                      -0.2340, -2.6396, -1.0282, -3.0156, -0.6236,  3.4472,  0.5916, -1.4359,\n",
       "                      -0.1146, -1.2874, -0.9474, -0.9662, -0.4004, -0.5024,  2.7066,  0.9013,\n",
       "                       2.1515,  2.2499, -2.7340, -1.9079, -2.5712, -2.1280, -3.6721, -0.4408,\n",
       "                      -0.8301, -1.1642,  1.3697, -3.1022, -1.6350, -0.4459, -0.9856,  0.2873,\n",
       "                      -1.8157,  2.9232, -1.3813,  3.3347, -1.4967,  0.2639, -3.2620,  2.2030,\n",
       "                      -0.3225,  0.7473,  0.3598, -1.7396,  0.7703, -0.8302,  2.9259, -0.9114,\n",
       "                      -1.0735,  0.7860,  1.1140,  0.0707,  2.2517, -1.1974,  1.6339, -1.4516,\n",
       "                      -0.4713,  0.9889, -4.1401, -0.1157,  2.1633,  1.7318,  1.0937,  2.6876,\n",
       "                       2.8129, -0.9619,  3.5883,  1.5268,  3.5406, -0.8144,  0.9891,  2.4282,\n",
       "                       0.9737, -0.7575, -2.3012,  2.9127, -1.8224, -1.4886, -1.6205, -0.1453,\n",
       "                      -3.4617,  3.0771,  2.3958, -1.9740, -2.1848,  2.8011,  3.2082, -0.6091,\n",
       "                       1.9215,  0.7802,  2.5640,  1.5058,  0.3125, -2.3820, -1.4797,  0.0946,\n",
       "                      -1.0833, -0.3448, -2.2219, -0.2910, -1.9582,  2.2401,  4.3520,  1.2427,\n",
       "                      -0.9733, -1.4761, -3.1632, -0.5524, -0.4296, -2.8243, -0.3789, -1.7133,\n",
       "                      -0.9719,  2.8211,  2.6742,  0.3414, -0.9920, -2.3755,  1.1320, -3.7198,\n",
       "                      -1.7217,  1.0055,  1.3695,  1.9144, -2.1790,  0.9147, -3.4870, -0.2635,\n",
       "                      -0.9606, -0.3449,  1.9156, -3.4713, -0.5604, -3.5257,  4.4743, -2.9531,\n",
       "                       1.1483, -1.7924,  0.3380,  3.3689, -2.7299,  0.9523,  1.8645,  1.0614,\n",
       "                       0.5954, -1.0194, -2.1116, -3.2240,  4.2531, -1.6062,  2.9430,  1.4738,\n",
       "                       0.9921, -1.2509, -2.4055, -1.9698,  4.0535, -1.2802, -2.2039, -1.9504,\n",
       "                       0.6272,  2.6469,  0.2799, -1.0752,  2.9365,  2.1041, -1.4038,  0.9382,\n",
       "                      -2.5735, -1.3770,  2.4588,  0.7689, -1.2987, -2.1218,  1.0284, -0.1580,\n",
       "                      -3.0888, -0.2037, -1.3887, -0.0693,  1.9860, -1.9846, -1.7476, -1.6744,\n",
       "                       0.7350, -2.5044, -0.0333,  2.8317, -2.4403, -1.5583, -0.3922, -1.2209,\n",
       "                      -2.3414,  1.0156, -1.1808, -2.9416, -2.9808, -2.1083, -0.6387,  0.3788,\n",
       "                      -2.9245, -0.8602,  0.6203, -1.7510, -0.6593, -2.9050, -2.4951, -2.2565,\n",
       "                      -0.7371, -3.5586,  0.6223, -1.8727, -1.8424, -3.6627,  1.3647, -1.8446,\n",
       "                       2.7894, -1.4916,  1.4574, -2.0125, -1.9045, -0.0700, -2.1802, -1.3146,\n",
       "                       0.6548,  0.6714,  0.8627,  2.4432,  0.4787,  1.0637, -0.0968,  1.1513,\n",
       "                      -3.0711,  2.6843, -3.0300, -1.5996, -0.4836,  4.4560, -2.4867, -1.0847,\n",
       "                       1.4591, -1.0282, -1.5578,  2.2097,  2.2462, -1.0267, -0.1496, -1.2455,\n",
       "                      -0.1122, -0.6954, -2.0282, -0.8037, -1.4497, -0.8556, -2.3285, -0.4666,\n",
       "                      -2.9806, -1.1782, -3.0453, -1.1583,  1.0720, -3.3458, -2.9155, -2.9102,\n",
       "                      -3.2861, -3.2484,  1.1271, -1.1639, -3.7890, -1.7143, -3.0823, -3.0678,\n",
       "                      -1.1175,  3.1328,  1.5084, -3.1368, -1.4594,  1.0860,  3.7779, -2.0606,\n",
       "                      -3.6233,  2.4193, -3.1145,  1.0967, -3.2231,  0.5568,  0.7488,  0.1192,\n",
       "                      -0.4683, -2.8790, -1.0664,  3.2086, -1.5883, -1.5100, -2.6876,  0.2616,\n",
       "                      -1.1391,  2.3154,  0.0733,  2.9835, -0.5802, -3.2539, -1.5203, -2.3895,\n",
       "                      -2.3807, -1.9494,  1.6722, -0.3852, -1.8199,  1.1623, -1.5098,  1.4366,\n",
       "                      -2.0449,  0.8224, -4.5916, -1.3075, -1.8533, -1.0361, -1.0457,  3.7264,\n",
       "                      -0.2102, -1.1688, -1.7691, -0.5555,  1.0089,  3.4596, -0.0285, -3.7634,\n",
       "                      -1.4339, -0.5567,  0.1443,  2.6755,  1.2918, -0.5974, -1.1920,  0.2333,\n",
       "                      -2.0092, -1.7471,  0.3582, -0.8545, -0.1617,  0.4298,  1.1563, -2.0256,\n",
       "                      -2.7390,  0.8462, -0.2795, -0.8374,  1.9752, -1.4315,  2.4177, -0.0698,\n",
       "                      -2.6768, -0.5353, -2.5987,  0.7851, -1.7747,  2.9084,  2.0953, -0.3011,\n",
       "                       0.4581, -2.3485,  1.0299,  1.3804, -0.9314, -0.9803, -2.2057,  2.0966,\n",
       "                       3.4344, -1.7122, -2.0123,  0.1241,  0.8278, -2.1950, -1.9937,  0.1938,\n",
       "                       1.0661,  1.0680,  0.8779,  0.8275, -0.4232,  0.5721, -0.5365, -0.8386],\n",
       "                     device='cuda:0')),\n",
       "             ('model.6.running_var',\n",
       "              tensor([ 0.8739,  1.8727,  2.5764,  1.7947,  5.4870,  1.6718,  2.3688,  1.4775,\n",
       "                       2.3016,  2.2980,  1.2158,  3.2582,  1.3743,  1.7270,  1.6969,  4.2647,\n",
       "                       4.5851,  0.8646,  1.3610,  1.2241,  3.5014,  1.2217,  1.0803,  1.0801,\n",
       "                       3.1620,  1.2335,  1.0140,  1.1685,  1.6745,  1.5241,  1.6614,  2.4330,\n",
       "                       1.0459,  1.1732,  1.0847,  1.3564,  0.7829,  2.4458,  7.2507,  1.0606,\n",
       "                       0.9993,  3.1872,  5.9523,  1.3862,  0.7689,  5.9159,  1.2189,  0.7021,\n",
       "                       3.0286,  1.2902,  1.7614,  1.7941,  4.0383,  2.3887,  6.9781,  2.8531,\n",
       "                       4.0719,  1.3807,  1.3979,  4.0009,  1.8978,  1.2431,  2.4571,  3.2597,\n",
       "                       1.5319,  1.3187,  2.2398,  4.2119,  1.5874,  0.9930,  2.6347,  2.0267,\n",
       "                       1.5052,  5.7001,  2.1880,  1.0318,  1.4557,  0.7320,  1.4883,  0.8462,\n",
       "                       4.5811,  1.3884,  1.8018,  2.9090,  4.6468,  5.7687,  1.2326,  1.2333,\n",
       "                       2.4816,  1.3253,  2.7206,  3.6913,  1.7779,  1.2720,  1.2398,  2.6581,\n",
       "                       1.3598,  2.6652,  4.5596,  1.7008,  1.9420,  2.4172,  3.0936,  1.0454,\n",
       "                       3.9700,  1.3958,  1.2508,  1.4196,  1.7447,  1.0003,  1.3142,  1.4993,\n",
       "                       1.4165,  1.4223,  2.2202,  2.1899,  1.1519,  1.1119,  6.4412,  1.3827,\n",
       "                       2.7635,  1.9535,  3.8762,  2.0974,  2.0197,  1.6799,  2.6207,  1.1638,\n",
       "                       2.2550,  1.6104,  3.4309,  1.1785,  1.3551,  1.6077,  1.2987,  1.2311,\n",
       "                       0.9405,  2.1468,  1.5822,  2.7728,  2.2491,  1.8740,  2.6435,  2.5577,\n",
       "                       2.0614,  2.4022,  1.2767,  1.8453,  0.9831,  1.5854,  1.3181,  1.2322,\n",
       "                       1.8028,  2.2358,  1.6495,  3.5367,  1.9520,  1.8439,  1.9678,  2.8324,\n",
       "                       2.3783,  1.9029,  1.5175,  3.3569,  1.1923,  1.5337,  1.5607,  2.5369,\n",
       "                       1.6165,  6.4034,  2.0213,  1.3467,  1.1915,  1.0583,  4.8453,  3.8161,\n",
       "                       1.6282,  1.4588,  2.4225,  1.8220,  5.5625,  2.3026,  1.3385,  1.3773,\n",
       "                       1.4302,  2.1599,  1.4573,  2.1064,  2.2136,  3.6016,  1.8481,  3.8224,\n",
       "                       2.9962,  2.0705,  2.8893,  0.7837,  1.9504,  2.8364,  1.5695,  3.4454,\n",
       "                       1.5252,  0.9337,  2.1804,  1.6326,  1.5001,  1.2981,  2.8054,  1.3440,\n",
       "                       1.7927,  7.4810,  4.0074,  4.7584,  0.9765,  1.8365,  2.2286,  1.1277,\n",
       "                       3.6941,  1.8744,  2.4493,  1.1228,  2.5651,  0.8078,  2.1574,  2.1803,\n",
       "                       1.4097,  1.4105,  0.9540,  2.0980,  1.2554,  2.9352,  0.9293,  1.9310,\n",
       "                       3.6390,  1.2054,  1.1540,  1.4236,  2.7971,  1.4294,  2.0399,  4.3738,\n",
       "                       1.0867,  3.4940,  5.3065,  1.6874,  0.9464,  1.9715,  3.4578,  1.8695,\n",
       "                       2.9981,  2.6676,  1.8230,  2.4682,  1.4613,  1.7379,  2.1554,  2.8913,\n",
       "                       1.8098,  2.5436,  1.8360,  1.2301,  2.1337,  1.3938,  4.6577,  0.9809,\n",
       "                       1.1801,  2.4790,  1.7085,  3.5563,  1.8869,  3.1891,  2.0544,  1.9482,\n",
       "                       1.2948,  0.9619,  1.0594,  7.6411,  1.4973,  1.5937,  2.6423,  1.1508,\n",
       "                       1.3111,  2.3356,  1.5873,  2.5426,  1.0976,  1.8584,  1.3098,  1.1162,\n",
       "                       1.4655,  1.3541,  1.6267,  1.6492,  4.6833,  2.4248,  1.3877,  3.6334,\n",
       "                       1.0454,  1.1542,  6.7576,  1.2151,  1.8905,  1.0278,  1.5238,  1.7274,\n",
       "                       1.0405,  1.4627,  1.3425,  2.0402,  2.8203,  1.1906,  1.0589,  2.3403,\n",
       "                       1.5752,  1.1031,  3.3723,  1.7658,  1.3041,  3.5877,  1.5107,  1.5603,\n",
       "                       1.4101,  3.3252,  1.5577,  2.1733,  1.3513,  1.4325,  1.7064,  1.1069,\n",
       "                       1.2354,  1.4754,  1.5453,  2.5882,  1.0488,  1.2903,  1.0498,  2.0847,\n",
       "                       3.3810,  0.7409,  2.9429,  1.1874,  1.6635,  1.1771,  4.7135,  2.2680,\n",
       "                       3.0255,  0.9719,  3.3322,  3.1013,  2.1766,  1.7402,  3.2117,  1.1910,\n",
       "                       1.5325,  1.6234,  2.2953,  1.9511,  0.9952,  4.3777,  4.7425,  1.5932,\n",
       "                       1.7521,  1.9890,  1.0593,  1.6435,  1.2305,  1.7853,  2.0149,  1.6559,\n",
       "                       3.1082,  1.9513,  0.5574,  2.3965,  1.2263,  0.9492,  1.3459,  5.4780,\n",
       "                       1.5015,  1.0209,  1.6709,  4.7412,  1.7036,  3.9589,  0.9638,  1.7891,\n",
       "                       2.5084,  1.4378,  1.0101,  1.4621,  1.5842,  1.4553,  0.9509,  1.4430,\n",
       "                       1.1412,  1.9991,  1.0795,  0.5771,  1.2192,  0.9578,  1.0215,  2.7470,\n",
       "                       2.5049,  1.0556,  4.0698,  1.9424,  1.7236,  1.9552,  1.3991,  1.2154,\n",
       "                       1.4044,  2.5703,  2.4355,  2.0562,  2.3148,  1.8492,  3.4527,  1.7817,\n",
       "                       2.2759,  1.0505,  0.8173,  1.9134,  2.8046,  1.2120,  1.7804,  3.2784,\n",
       "                       4.3852,  5.4035,  1.0832,  3.5595,  5.5965,  1.4922,  3.3656,  3.8548,\n",
       "                       2.9231,  1.8081,  1.3475,  2.5357,  2.4942,  1.2948,  3.7222,  1.4618,\n",
       "                       0.9019,  3.4691,  2.2562,  3.1069,  1.8827,  0.9960,  3.3848,  1.4243,\n",
       "                       0.9010,  4.9395,  1.8815,  1.8830,  1.4020,  3.2059,  1.0313,  1.0854,\n",
       "                       1.4030,  1.3545,  1.7334,  1.4194,  1.3510,  2.2536,  2.5451,  2.3820,\n",
       "                       1.6562,  1.1826,  2.4770,  2.4575,  2.9501,  1.4691,  1.9622,  1.2746,\n",
       "                       1.3483, 10.7563,  1.3996,  1.2229,  3.2207,  3.0246,  1.3182,  1.1119,\n",
       "                       2.9128,  1.6925,  1.4176,  3.0814,  2.9056,  2.7646,  1.8183,  1.1201,\n",
       "                       1.9503,  1.1053,  1.9036,  2.4850,  1.6872,  1.1260,  2.1568,  2.1020,\n",
       "                       3.3495,  1.7979,  3.1422,  1.0766,  1.5445,  1.2435,  1.0194,  1.8189,\n",
       "                       1.9955,  0.7990,  2.7318,  3.9547,  1.5605,  2.0607,  1.0912,  1.7097],\n",
       "                     device='cuda:0')),\n",
       "             ('model.6.num_batches_tracked', tensor(6063600, device='cuda:0')),\n",
       "             ('model.8.weight',\n",
       "              tensor([[ 0.1612,  0.1179, -0.0309,  ...,  0.0926,  0.1337, -0.0170],\n",
       "                      [-0.1194, -0.0054, -0.0337,  ...,  0.0106,  0.1453,  0.0396],\n",
       "                      [-0.0683, -0.0788,  0.0912,  ...,  0.0877,  0.0370, -0.0119],\n",
       "                      ...,\n",
       "                      [ 0.0810, -0.0665,  0.0855,  ..., -0.0032,  0.0378, -0.0792],\n",
       "                      [ 0.0488,  0.0675, -0.0160,  ..., -0.0026,  0.0223,  0.1353],\n",
       "                      [-0.0021, -0.0033,  0.0685,  ...,  0.2148,  0.0054,  0.0291]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.8.bias',\n",
       "              tensor([-0.0121,  0.0269,  0.0227,  ...,  0.0400,  0.0392,  0.0241], device='cuda:0')),\n",
       "             ('model.9.weight',\n",
       "              tensor([4.0371, 3.3561, 3.7972,  ..., 2.7879, 3.4266, 3.2912], device='cuda:0')),\n",
       "             ('model.9.bias',\n",
       "              tensor([ 0.2653, -0.1125, -0.1586,  ..., -0.4422, -0.3241, -0.0017], device='cuda:0')),\n",
       "             ('model.9.running_mean',\n",
       "              tensor([ 6.8429,  8.2549,  2.8831,  ..., -0.1412,  3.0716,  5.8089], device='cuda:0')),\n",
       "             ('model.9.running_var',\n",
       "              tensor([3.3067, 2.6591, 2.9695,  ..., 2.0346, 2.3558, 1.8689], device='cuda:0')),\n",
       "             ('model.9.num_batches_tracked', tensor(6063600, device='cuda:0')),\n",
       "             ('model.11.weight',\n",
       "              tensor([[-0.0056, -0.0250, -0.0226,  ..., -0.0550, -0.0344, -0.0361],\n",
       "                      [-0.0106, -0.0362, -0.0149,  ...,  0.0107, -0.0183, -0.0017],\n",
       "                      [-0.0063, -0.0404, -0.0194,  ..., -0.0343, -0.0644,  0.0179],\n",
       "                      ...,\n",
       "                      [-0.0178, -0.0310, -0.0095,  ...,  0.0154, -0.0041, -0.0346],\n",
       "                      [-0.0269, -0.0399,  0.0001,  ..., -0.0108, -0.0245, -0.0259],\n",
       "                      [-0.0159, -0.0376, -0.0095,  ..., -0.0306, -0.0283,  0.0048]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.11.bias',\n",
       "              tensor([0.0700, 0.1058, 0.0608,  ..., 0.1054, 0.0790, 0.0528], device='cuda:0'))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved models @\n",
      "4999\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"/home/jgmeyer2/vangan/gans/models\",exist_ok=True)\n",
    "PATH = \"/home/jgmeyer2/vangan/gans/models/g5k.model\"\n",
    "modelid=\"5k\"\n",
    "\n",
    "\n",
    "state_g = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': generator.state_dict(),\n",
    "    'optimizer': optimizer_G.state_dict()\n",
    "    }\n",
    "torch.save(state_g, PATH+\"g\"+modelid+\".model\")\n",
    "\n",
    "state_d = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': discriminator.state_dict(),\n",
    "    'optimizer': optimizer_D.state_dict()\n",
    "    }\n",
    "torch.save(state_d, PATH+\"d\"+modelid+\".model\")\n",
    "print(\"saved models @\")\n",
    "print(epoch)\n",
    "\n",
    "\n",
    "#def save_model(net, optim, ckpt_fname):\n",
    "#    state_dict = net.module.state_dict()\n",
    "#    for key in state_dict.keys():\n",
    "#        state_dict[key] = state_dict[key].cpu()\n",
    "#        torch.save({\n",
    "#            'epoch': epoch,                                                                                                                                                                                     \n",
    "#            'state_dict': state_dict,                                                                                                                                                                                \n",
    "#            'optimizer': optim},                                                                                                                                                                                     \n",
    "#            ckpt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(state['state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "model.load_state_dict(state['state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "state = torch.load(filepath)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
