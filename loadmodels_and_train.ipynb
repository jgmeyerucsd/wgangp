{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 250, 250)\n"
     ]
    }
   ],
   "source": [
    "n_epochs=100 #number of epochs of training\n",
    "batch_size=1000 #size of the batches\n",
    "lr=0.0002 #adam: learning rate\n",
    "b1=0.5  #\"adam: decay of first order momentum of gradient\")\n",
    "b2=0.999 #adam: decay of first order momentum of gradient\")\n",
    "n_cpu=8\n",
    "latent_dim=100\n",
    "img_size=250\n",
    "channels=1\n",
    "n_critic=5\n",
    "clip_value=0.01\n",
    "sample_interval=1000\n",
    "img_shape = (channels, img_size, img_size)\n",
    "crop_size = 400\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from tensorboard_logger import configure, log_value\n",
    "import tensorboard\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "#import utils import Logger\n",
    "\n",
    "# torchvision stuff\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "# torch stuff\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transforms_=None):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.files = sorted(glob.glob('%s/*.*' % folder_path))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    \n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(cuda)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(100, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "    \n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models and Load Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# If cuda, use cuda\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    \n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b2, b2))\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_g = torch.load(\"/home/jgmeyer2/vangan/gans/models/g250px_jpegs_bw.model\")\n",
    "state_d = torch.load(\"/home/jgmeyer2/vangan/gans/models/d250px_jpegs_bw.model\")\n",
    "\n",
    "\n",
    "generator.load_state_dict(state_g['state_dict'])\n",
    "optimizer_G.load_state_dict(state_g['optimizer'])\n",
    "\n",
    "discriminator.load_state_dict(state_d['state_dict'])\n",
    "optimizer_D.load_state_dict(state_d['optimizer'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INitialize logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure(\"runs/bw250n2\",flush_secs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(dataloader, batch_size, n_epochs):\n",
    "    start = time.time()\n",
    "    batches_done=0\n",
    "    for epoch in range(n_epochs):\n",
    "        batchtimes=[float()]\n",
    "        for i, imgs in enumerate(dataloader):\n",
    "            ## monitor time\n",
    "\n",
    "            # Configure input\n",
    "            real_imgs = Variable(imgs.type(Tensor))\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            # Sample noise as generator input\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z)\n",
    "            # Real images\n",
    "            real_validity = discriminator(real_imgs)\n",
    "            # Fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            # Gradient penalty\n",
    "            gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "            # Adversarial loss\n",
    "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            optimizer_G.zero_grad()\n",
    "            # Train the generator every n_critic steps\n",
    "            if i % n_critic == 0:\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "                # Generate a batch of images\n",
    "                fake_imgs = generator(z)\n",
    "                # Loss measures generator's ability to fool the discriminator\n",
    "                # Train on fake images\n",
    "                fake_validity = discriminator(fake_imgs)\n",
    "                g_loss = -torch.mean(fake_validity)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "                #logger.log(d_loss, g_loss, epoch, batches_done, num_batches)\n",
    "                if batches_done % sample_interval/10 ==0:\n",
    "                    log_value('g_loss', g_loss, batches_done)\n",
    "                    log_value('d_loss', d_loss, batches_done)\n",
    "\n",
    "                if batches_done % sample_interval/10 == 0:\n",
    "                    save_image(fake_imgs.data[:25], \"molpics250px_bw/%d_b.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "                end = time.time()\n",
    "                batchtime = (end - start)/5\n",
    "\n",
    "                print(\n",
    "                    \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [batch time: %f]\"\n",
    "                    % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item(), batchtime)\n",
    "                )\n",
    "                batchtimes.append(batchtime/batch_size)\n",
    "                start = time.time()\n",
    "                batches_done += n_critic\n",
    "        print(\"average time per picture = \" +str(np.mean(batchtimes)))\n",
    "        print(\"minutes per 100,000 pictures = \"+str((np.mean(batchtimes)*100000)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10000] [Batch 0/100] [D loss: 2.353823] [G loss: 272.677124] [batch time: 0.542465]\n",
      "[Epoch 0/10000] [Batch 5/100] [D loss: 1.987182] [G loss: 289.494385] [batch time: 0.301251]\n",
      "[Epoch 0/10000] [Batch 10/100] [D loss: 1.581028] [G loss: 305.757019] [batch time: 0.302904]\n",
      "[Epoch 0/10000] [Batch 15/100] [D loss: 1.327439] [G loss: 321.162811] [batch time: 0.296978]\n",
      "[Epoch 0/10000] [Batch 20/100] [D loss: 1.391119] [G loss: 335.550140] [batch time: 0.297094]\n",
      "[Epoch 0/10000] [Batch 25/100] [D loss: 1.299007] [G loss: 348.966766] [batch time: 0.301552]\n",
      "[Epoch 0/10000] [Batch 30/100] [D loss: 1.251305] [G loss: 361.027222] [batch time: 0.297408]\n",
      "[Epoch 0/10000] [Batch 35/100] [D loss: 1.613397] [G loss: 371.269165] [batch time: 0.302569]\n",
      "[Epoch 0/10000] [Batch 40/100] [D loss: 2.605494] [G loss: 379.260498] [batch time: 0.301731]\n",
      "[Epoch 0/10000] [Batch 45/100] [D loss: 3.365986] [G loss: 384.848602] [batch time: 0.307398]\n",
      "[Epoch 0/10000] [Batch 50/100] [D loss: 3.647167] [G loss: 387.501251] [batch time: 0.307233]\n",
      "[Epoch 0/10000] [Batch 55/100] [D loss: 4.033956] [G loss: 387.111969] [batch time: 0.298897]\n",
      "[Epoch 0/10000] [Batch 60/100] [D loss: 4.394892] [G loss: 383.788208] [batch time: 0.300212]\n",
      "[Epoch 0/10000] [Batch 65/100] [D loss: 4.865631] [G loss: 377.574097] [batch time: 0.298589]\n",
      "[Epoch 0/10000] [Batch 70/100] [D loss: 5.079910] [G loss: 368.339569] [batch time: 0.301750]\n",
      "[Epoch 0/10000] [Batch 75/100] [D loss: 5.150745] [G loss: 356.260986] [batch time: 0.305266]\n",
      "[Epoch 0/10000] [Batch 80/100] [D loss: 4.838259] [G loss: 341.193573] [batch time: 0.301071]\n",
      "[Epoch 0/10000] [Batch 85/100] [D loss: 4.351648] [G loss: 323.310638] [batch time: 0.295722]\n",
      "[Epoch 0/10000] [Batch 90/100] [D loss: 3.902344] [G loss: 302.463013] [batch time: 0.292581]\n",
      "[Epoch 0/10000] [Batch 95/100] [D loss: 3.134422] [G loss: 279.097992] [batch time: 0.287835]\n",
      "average time per picture = 0.00029716700599307104\n",
      "minutes per 100,000 pictures = 0.49527834332178505\n",
      "[Epoch 1/10000] [Batch 0/100] [D loss: 2.400208] [G loss: 253.303818] [batch time: 0.514084]\n",
      "[Epoch 1/10000] [Batch 5/100] [D loss: 1.432779] [G loss: 225.356064] [batch time: 0.304087]\n",
      "[Epoch 1/10000] [Batch 10/100] [D loss: 0.619469] [G loss: 195.268341] [batch time: 0.315030]\n",
      "[Epoch 1/10000] [Batch 15/100] [D loss: -0.356379] [G loss: 163.547607] [batch time: 0.306381]\n",
      "[Epoch 1/10000] [Batch 20/100] [D loss: -1.170498] [G loss: 130.312805] [batch time: 0.302747]\n",
      "[Epoch 1/10000] [Batch 25/100] [D loss: -1.754029] [G loss: 95.983627] [batch time: 0.300438]\n",
      "[Epoch 1/10000] [Batch 30/100] [D loss: -2.363777] [G loss: 60.931892] [batch time: 0.300409]\n",
      "[Epoch 1/10000] [Batch 35/100] [D loss: -2.801479] [G loss: 25.490345] [batch time: 0.301736]\n",
      "[Epoch 1/10000] [Batch 40/100] [D loss: -2.854500] [G loss: -10.339741] [batch time: 0.303518]\n",
      "[Epoch 1/10000] [Batch 45/100] [D loss: -2.910717] [G loss: -46.050827] [batch time: 0.302760]\n",
      "[Epoch 1/10000] [Batch 50/100] [D loss: -2.672352] [G loss: -81.603493] [batch time: 0.303247]\n",
      "[Epoch 1/10000] [Batch 55/100] [D loss: -2.316059] [G loss: -116.616562] [batch time: 0.302145]\n",
      "[Epoch 1/10000] [Batch 60/100] [D loss: -1.985565] [G loss: -150.880447] [batch time: 0.304977]\n",
      "[Epoch 1/10000] [Batch 65/100] [D loss: -1.315301] [G loss: -184.424728] [batch time: 0.304499]\n",
      "[Epoch 1/10000] [Batch 70/100] [D loss: -0.490483] [G loss: -216.833160] [batch time: 0.303496]\n",
      "[Epoch 1/10000] [Batch 75/100] [D loss: 0.272643] [G loss: -247.728546] [batch time: 0.302007]\n",
      "[Epoch 1/10000] [Batch 80/100] [D loss: 1.275899] [G loss: -277.165894] [batch time: 0.302404]\n",
      "[Epoch 1/10000] [Batch 85/100] [D loss: 2.497710] [G loss: -304.722626] [batch time: 0.303274]\n",
      "[Epoch 1/10000] [Batch 90/100] [D loss: 3.752137] [G loss: -330.105225] [batch time: 0.291807]\n",
      "[Epoch 1/10000] [Batch 95/100] [D loss: 4.927547] [G loss: -353.025085] [batch time: 0.292457]\n",
      "average time per picture = 0.00029816682906377883\n",
      "minutes per 100,000 pictures = 0.496944715106298\n",
      "[Epoch 2/10000] [Batch 0/100] [D loss: 6.036004] [G loss: -373.139435] [batch time: 0.455210]\n",
      "[Epoch 2/10000] [Batch 5/100] [D loss: 7.143885] [G loss: -390.394958] [batch time: 0.338528]\n",
      "[Epoch 2/10000] [Batch 10/100] [D loss: 8.222340] [G loss: -404.585114] [batch time: 0.301131]\n",
      "[Epoch 2/10000] [Batch 15/100] [D loss: 9.019585] [G loss: -415.297363] [batch time: 0.303914]\n",
      "[Epoch 2/10000] [Batch 20/100] [D loss: 9.450930] [G loss: -422.557617] [batch time: 0.301080]\n",
      "[Epoch 2/10000] [Batch 25/100] [D loss: 9.835171] [G loss: -426.272949] [batch time: 0.302062]\n",
      "[Epoch 2/10000] [Batch 30/100] [D loss: 9.887217] [G loss: -426.355438] [batch time: 0.302956]\n",
      "[Epoch 2/10000] [Batch 35/100] [D loss: 9.659828] [G loss: -422.918854] [batch time: 0.302640]\n",
      "[Epoch 2/10000] [Batch 40/100] [D loss: 9.216374] [G loss: -415.824280] [batch time: 0.304755]\n",
      "[Epoch 2/10000] [Batch 45/100] [D loss: 8.333207] [G loss: -405.344513] [batch time: 0.304774]\n",
      "[Epoch 2/10000] [Batch 50/100] [D loss: 7.459072] [G loss: -391.712463] [batch time: 0.302539]\n",
      "[Epoch 2/10000] [Batch 55/100] [D loss: 6.447074] [G loss: -374.826660] [batch time: 0.301619]\n",
      "[Epoch 2/10000] [Batch 60/100] [D loss: 5.178028] [G loss: -355.080505] [batch time: 0.305540]\n",
      "[Epoch 2/10000] [Batch 65/100] [D loss: 3.898172] [G loss: -332.772827] [batch time: 0.304292]\n",
      "[Epoch 2/10000] [Batch 70/100] [D loss: 2.777653] [G loss: -308.192505] [batch time: 0.305094]\n",
      "[Epoch 2/10000] [Batch 75/100] [D loss: 1.618283] [G loss: -281.577667] [batch time: 0.303728]\n",
      "[Epoch 2/10000] [Batch 80/100] [D loss: 0.658681] [G loss: -253.302429] [batch time: 0.302852]\n",
      "[Epoch 2/10000] [Batch 85/100] [D loss: -0.165624] [G loss: -223.680542] [batch time: 0.299767]\n",
      "[Epoch 2/10000] [Batch 90/100] [D loss: -0.913807] [G loss: -192.898514] [batch time: 0.291198]\n",
      "[Epoch 2/10000] [Batch 95/100] [D loss: -1.393433] [G loss: -161.329636] [batch time: 0.291285]\n",
      "average time per picture = 0.00029642676398867655\n",
      "minutes per 100,000 pictures = 0.4940446066477942\n",
      "[Epoch 3/10000] [Batch 0/100] [D loss: -1.802922] [G loss: -129.119812] [batch time: 0.526970]\n",
      "[Epoch 3/10000] [Batch 5/100] [D loss: -2.120957] [G loss: -96.440758] [batch time: 0.312726]\n",
      "[Epoch 3/10000] [Batch 10/100] [D loss: -2.311073] [G loss: -63.439747] [batch time: 0.301996]\n",
      "[Epoch 3/10000] [Batch 15/100] [D loss: -2.555958] [G loss: -30.082111] [batch time: 0.301523]\n",
      "[Epoch 3/10000] [Batch 20/100] [D loss: -2.741116] [G loss: 3.551073] [batch time: 0.302461]\n",
      "[Epoch 3/10000] [Batch 25/100] [D loss: -2.961321] [G loss: 37.415184] [batch time: 0.300354]\n",
      "[Epoch 3/10000] [Batch 30/100] [D loss: -3.175099] [G loss: 71.557945] [batch time: 0.301468]\n",
      "[Epoch 3/10000] [Batch 35/100] [D loss: -3.195029] [G loss: 105.710022] [batch time: 0.303943]\n",
      "[Epoch 3/10000] [Batch 40/100] [D loss: -3.109987] [G loss: 139.773376] [batch time: 0.304156]\n",
      "[Epoch 3/10000] [Batch 45/100] [D loss: -2.795986] [G loss: 173.475220] [batch time: 0.300967]\n",
      "[Epoch 3/10000] [Batch 50/100] [D loss: -2.277806] [G loss: 206.558701] [batch time: 0.302519]\n",
      "[Epoch 3/10000] [Batch 55/100] [D loss: -1.461483] [G loss: 238.609436] [batch time: 0.303591]\n",
      "[Epoch 3/10000] [Batch 60/100] [D loss: -0.615017] [G loss: 269.383270] [batch time: 0.306175]\n",
      "[Epoch 3/10000] [Batch 65/100] [D loss: 0.636242] [G loss: 298.251862] [batch time: 0.303972]\n",
      "[Epoch 3/10000] [Batch 70/100] [D loss: 1.930816] [G loss: 325.099579] [batch time: 0.304839]\n",
      "[Epoch 3/10000] [Batch 75/100] [D loss: 3.490557] [G loss: 349.282410] [batch time: 0.300122]\n",
      "[Epoch 3/10000] [Batch 80/100] [D loss: 4.544451] [G loss: 371.021851] [batch time: 0.302677]\n",
      "[Epoch 3/10000] [Batch 85/100] [D loss: 5.920286] [G loss: 389.505188] [batch time: 0.301437]\n",
      "[Epoch 3/10000] [Batch 90/100] [D loss: 7.049242] [G loss: 404.816589] [batch time: 0.294022]\n",
      "[Epoch 3/10000] [Batch 95/100] [D loss: 7.902310] [G loss: 416.371216] [batch time: 0.291711]\n",
      "average time per picture = 0.00029845859890892395\n",
      "minutes per 100,000 pictures = 0.4974309981815399\n",
      "[Epoch 4/10000] [Batch 0/100] [D loss: 8.652312] [G loss: 424.417816] [batch time: 0.467529]\n",
      "[Epoch 4/10000] [Batch 5/100] [D loss: 8.952291] [G loss: 428.653534] [batch time: 0.339086]\n",
      "[Epoch 4/10000] [Batch 10/100] [D loss: 8.818480] [G loss: 429.236877] [batch time: 0.299361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10000] [Batch 15/100] [D loss: 8.032801] [G loss: 426.383636] [batch time: 0.300741]\n",
      "[Epoch 4/10000] [Batch 20/100] [D loss: 7.607787] [G loss: 419.692322] [batch time: 0.302361]\n",
      "[Epoch 4/10000] [Batch 25/100] [D loss: 6.726378] [G loss: 409.705505] [batch time: 0.309457]\n",
      "[Epoch 4/10000] [Batch 30/100] [D loss: 5.724051] [G loss: 396.693024] [batch time: 0.309523]\n",
      "[Epoch 4/10000] [Batch 35/100] [D loss: 4.527613] [G loss: 380.902954] [batch time: 0.314141]\n",
      "[Epoch 4/10000] [Batch 40/100] [D loss: 3.598086] [G loss: 362.556519] [batch time: 0.315589]\n",
      "[Epoch 4/10000] [Batch 45/100] [D loss: 2.609808] [G loss: 342.056122] [batch time: 0.316434]\n",
      "[Epoch 4/10000] [Batch 50/100] [D loss: 1.685929] [G loss: 319.790771] [batch time: 0.302858]\n",
      "[Epoch 4/10000] [Batch 55/100] [D loss: 1.091435] [G loss: 295.912781] [batch time: 0.303462]\n",
      "[Epoch 4/10000] [Batch 60/100] [D loss: 0.639137] [G loss: 271.073212] [batch time: 0.298985]\n",
      "[Epoch 4/10000] [Batch 65/100] [D loss: 0.446929] [G loss: 245.271439] [batch time: 0.302657]\n",
      "[Epoch 4/10000] [Batch 70/100] [D loss: 0.363343] [G loss: 219.032059] [batch time: 0.307109]\n",
      "[Epoch 4/10000] [Batch 75/100] [D loss: 0.419853] [G loss: 192.485504] [batch time: 0.309254]\n",
      "[Epoch 4/10000] [Batch 80/100] [D loss: 0.601446] [G loss: 165.823318] [batch time: 0.307448]\n",
      "[Epoch 4/10000] [Batch 85/100] [D loss: 0.831395] [G loss: 139.273239] [batch time: 0.302394]\n",
      "[Epoch 4/10000] [Batch 90/100] [D loss: 1.095123] [G loss: 112.972343] [batch time: 0.306081]\n",
      "[Epoch 4/10000] [Batch 95/100] [D loss: 1.560353] [G loss: 86.769722] [batch time: 0.299971]\n",
      "average time per picture = 0.00030068760599408835\n",
      "minutes per 100,000 pictures = 0.5011460099901472\n",
      "[Epoch 5/10000] [Batch 0/100] [D loss: 2.012930] [G loss: 61.136688] [batch time: 0.457722]\n",
      "[Epoch 5/10000] [Batch 5/100] [D loss: 2.471828] [G loss: 35.996326] [batch time: 0.343704]\n",
      "[Epoch 5/10000] [Batch 10/100] [D loss: 3.045971] [G loss: 11.379261] [batch time: 0.302577]\n",
      "[Epoch 5/10000] [Batch 15/100] [D loss: 3.709280] [G loss: -12.332385] [batch time: 0.302830]\n",
      "[Epoch 5/10000] [Batch 20/100] [D loss: 4.337439] [G loss: -35.114799] [batch time: 0.299872]\n",
      "[Epoch 5/10000] [Batch 25/100] [D loss: 5.003673] [G loss: -56.777332] [batch time: 0.303859]\n",
      "[Epoch 5/10000] [Batch 30/100] [D loss: 5.820051] [G loss: -77.217628] [batch time: 0.304958]\n",
      "[Epoch 5/10000] [Batch 35/100] [D loss: 6.376163] [G loss: -95.901901] [batch time: 0.301132]\n",
      "[Epoch 5/10000] [Batch 40/100] [D loss: 7.044107] [G loss: -113.016396] [batch time: 0.303062]\n",
      "[Epoch 5/10000] [Batch 45/100] [D loss: 7.397818] [G loss: -128.060883] [batch time: 0.304563]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./zinc100k250pxJPEGbw/\"\n",
    "n_epochs=10000\n",
    "batch_size = 1000\n",
    "transforms_ = [ transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "dataloader = DataLoader(ImageDataset(folder_path, transforms_=transforms_),\n",
    "                        batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "train(dataloader, batch_size, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved models @\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"/home/jgmeyer2/vangan/gans/models\",exist_ok=True)\n",
    "PATH = \"/home/jgmeyer2/vangan/gans/models/\"\n",
    "modelid=\"250px_jpegs_bw\"\n",
    "epoch=100\n",
    "\n",
    "state_g = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': generator.state_dict(),\n",
    "    'optimizer': optimizer_G.state_dict()\n",
    "    }\n",
    "torch.save(state_g, PATH+\"g\"+modelid+\".model\")\n",
    "\n",
    "state_d = {\n",
    "    'epoch': epoch,\n",
    "    'state_dict': discriminator.state_dict(),\n",
    "    'optimizer': optimizer_D.state_dict()\n",
    "    }\n",
    "torch.save(state_d, PATH+\"d\"+modelid+\".model\")\n",
    "print(\"saved models @\")\n",
    "print(epoch)\n",
    "\n",
    "\n",
    "#def save_model(net, optim, ckpt_fname):\n",
    "#    state_dict = net.module.state_dict()\n",
    "#    for key in state_dict.keys():\n",
    "#        state_dict[key] = state_dict[key].cpu()\n",
    "#        torch.save({\n",
    "#            'epoch': epoch,                                                                                                                                                                                     \n",
    "#            'state_dict': state_dict,                                                                                                                                                                                \n",
    "#            'optimizer': optim},                                                                                                                                                                                     \n",
    "#            ckpt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard\n",
    "!python -m tensorboard.main --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vangan",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
