{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jgmeyer2/anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    keras-2.2.2                |                0           6 KB\n",
      "    keras-base-2.2.2           |           py36_0         445 KB\n",
      "    keras-preprocessing-1.0.2  |           py36_1          46 KB\n",
      "    keras-applications-1.0.4   |           py36_1          47 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         544 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    _tflow_1100_select:  0.0.3-mkl                \n",
      "    absl-py:             0.4.0-py36h28b3542_0     \n",
      "    astor:               0.7.1-py36_0             \n",
      "    gast:                0.2.0-py36_0             \n",
      "    grpcio:              1.12.1-py36hdbcaa40_0    \n",
      "    keras:               2.2.2-0                  \n",
      "    keras-applications:  1.0.4-py36_1             \n",
      "    keras-base:          2.2.2-py36_0             \n",
      "    keras-preprocessing: 1.0.2-py36_1             \n",
      "    libprotobuf:         3.6.0-hdbcaa40_0         \n",
      "    markdown:            2.6.11-py36_0            \n",
      "    protobuf:            3.6.0-py36hf484d3e_0     \n",
      "    tensorboard:         1.10.0-py36hf484d3e_0    \n",
      "    tensorflow:          1.10.0-mkl_py36hdb377fd_0\n",
      "    tensorflow-base:     1.10.0-mkl_py36h3c3e929_0\n",
      "    termcolor:           1.1.0-py36_1             \n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "keras-2.2.2          | 6 KB      | ##################################### | 100% \n",
      "keras-base-2.2.2     | 445 KB    | ##################################### | 100% \n",
      "keras-preprocessing- | 46 KB     | ##################################### | 100% \n",
      "keras-applications-1 | 47 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are tring to use the old GPU back-end. It was removed from Theano. Use device=cuda* now. See https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc7f354ba4c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"InlineBackend.figure_format = 'retina'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using Theano backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtheano_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrng_mrg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMRG_RandomStreams\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mRandomStreams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/theano/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchange_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/theano/configdefaults.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m      \"letters, only lower case even if NVIDIA uses capital letters.\"),\n\u001b[1;32m    136\u001b[0m     \u001b[0mDeviceParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_override\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     in_c_key=False)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m AddConfigVar(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/theano/configparser.py\u001b[0m in \u001b[0;36mAddConfigVar\u001b[0;34m(name, doc, configparam, root, in_c_key)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# This allow to filter wrong value from the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mconfigparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;31m# We do not want to evaluate now the default value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/theano/configparser.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, cls, type_, delete_key)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mval_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# print \"RVAL\", self.val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/theano/configparser.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, cls, val)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# print \"SETTING PARAM\", self.fullname,(cls), val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/theano/configdefaults.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0;34m'You are tring to use the old GPU back-end. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0;34m'It was removed from Theano. Use device=cuda* now. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0;34m'See https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are tring to use the old GPU back-end. It was removed from Theano. Use device=cuda* now. See https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29 for more information."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.callbacks import *\n",
    "from keras.utils.generic_utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 777\n",
    "\n",
    "RUN = 'F'\n",
    "OUT_DIR = 'out/' + RUN\n",
    "TENSORBOARD_DIR = '/tensorboard/wgans/' + RUN\n",
    "\n",
    "# GPU # \n",
    "GPU = \"1\"\n",
    "\n",
    "# latent vector size\n",
    "Z_SIZE = 100\n",
    "\n",
    "# number of iterations D is trained for per each G iteration\n",
    "D_ITERS = 5\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "ITERATIONS = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use specific GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basically return mean(y_pred),\n",
    "# but with ability to inverse it for minimization (when y_true == -1)\n",
    "def wasserstein(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_D():\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    input_image = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "    x = Conv2D(\n",
    "        32, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_1',\n",
    "        kernel_initializer=weight_init)(input_image)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        64, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_2',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        128, (3, 3),\n",
    "        padding='same',\n",
    "        name='conv_3',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        256, (3, 3),\n",
    "        padding='same',\n",
    "        name='coonv_4',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "    x = MaxPool2D(pool_size=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    output_is_fake = Dense(\n",
    "        1, activation='linear', name='output_is_fake')(features)\n",
    "\n",
    "    output_class = Dense(\n",
    "        10, activation='softmax', name='output_class')(features)\n",
    "\n",
    "    return Model(\n",
    "        inputs=[input_image], outputs=[output_is_fake, output_class], name='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_G(Z_SIZE=Z_SIZE):\n",
    "    DICT_LEN = 10\n",
    "    EMBEDDING_LEN = Z_SIZE\n",
    "\n",
    "    # weights are initlaized from normal distribution with below params\n",
    "    weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "\n",
    "    # class#\n",
    "    input_class = Input(shape=(1, ), dtype='int32', name='input_class')\n",
    "    # encode class# to the same size as Z to use hadamard multiplication later on\n",
    "    e = Embedding(\n",
    "        DICT_LEN, EMBEDDING_LEN,\n",
    "        embeddings_initializer='glorot_uniform')(input_class)\n",
    "    embedded_class = Flatten(name='embedded_class')(e)\n",
    "\n",
    "    # latent var\n",
    "    input_z = Input(shape=(Z_SIZE, ), name='input_z')\n",
    "\n",
    "    # hadamard product\n",
    "    h = multiply([input_z, embedded_class], name='h')\n",
    "\n",
    "    # cnn part\n",
    "    x = Dense(1024)(h)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Dense(128 * 7 * 7)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same', kernel_initializer=weight_init)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    x = Conv2D(\n",
    "        1, (2, 2),\n",
    "        padding='same',\n",
    "        activation='tanh',\n",
    "        name='output_generated_image',\n",
    "        kernel_initializer=weight_init)(x)\n",
    "\n",
    "    return Model(inputs=[input_z, input_class], outputs=x, name='G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = create_D()\n",
    "\n",
    "# # remember D dropout rates\n",
    "# for l in D.layers:\n",
    "#     if l.name.startswith('dropout'):\n",
    "#         l._rate = l.rate\n",
    "\n",
    "D.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein, 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_z = Input(shape=(Z_SIZE, ), name='input_z_')\n",
    "input_class = Input(shape=(1, ),name='input_class_', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = create_G()\n",
    "\n",
    "# create combined D(G) model\n",
    "output_is_fake, output_class = D(G(inputs=[input_z, input_class]))\n",
    "DG = Model(inputs=[input_z, input_class], outputs=[output_is_fake, output_class])\n",
    "DG.get_layer('D').trainable = False # freeze D in generator training faze\n",
    "\n",
    "DG.compile(\n",
    "    optimizer=RMSprop(lr=0.00005),\n",
    "    loss=[wasserstein, 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load mnist data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# use all available 70k samples\n",
    "X_train = np.concatenate((X_train, X_test))\n",
    "y_train = np.concatenate((y_train, y_test))\n",
    "\n",
    "# convert to -1..1 range, reshape to (sample_i, 28, 28, 1)\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save 10x10 sample of generated images\n",
    "samples_zz = np.random.normal(0., 1., (100, Z_SIZE))\n",
    "def generate_samples(n=0, save=True):\n",
    "\n",
    "    generated_classes = np.array(list(range(0, 10)) * 10)\n",
    "    generated_images = G.predict([samples_zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "    rr = []\n",
    "    for c in range(10):\n",
    "        rr.append(\n",
    "            np.concatenate(generated_images[c * 10:(1 + c) * 10]).reshape(\n",
    "                280, 28))\n",
    "    img = np.hstack(rr)\n",
    "\n",
    "    if save:\n",
    "        plt.imsave(OUT_DIR + '/samples_%07d.png' % n, img, cmap=plt.cm.gray)\n",
    "\n",
    "    return img\n",
    "\n",
    "# write tensorboard summaries\n",
    "sw = tf.summary.FileWriter(TENSORBOARD_DIR)\n",
    "def update_tb_summary(step, sample_images=True, save_image_files=True):\n",
    "\n",
    "    s = tf.Summary()\n",
    "\n",
    "    # losses as is\n",
    "    for names, vals in zip((('D_real_is_fake', 'D_real_class'),\n",
    "                            ('D_fake_is_fake', 'D_fake_class'), ('DG_is_fake',\n",
    "                                                                 'DG_class')),\n",
    "                           (D_true_losses, D_fake_losses, DG_losses)):\n",
    "\n",
    "        v = s.value.add()\n",
    "        v.simple_value = vals[-1][1]\n",
    "        v.tag = names[0]\n",
    "\n",
    "        v = s.value.add()\n",
    "        v.simple_value = vals[-1][2]\n",
    "        v.tag = names[1]\n",
    "\n",
    "    # D loss: -1*D_true_is_fake - D_fake_is_fake\n",
    "    v = s.value.add()\n",
    "    v.simple_value = -D_true_losses[-1][1] - D_fake_losses[-1][1]\n",
    "    v.tag = 'D loss (-1*D_real_is_fake - D_fake_is_fake)'\n",
    "\n",
    "    # generated image\n",
    "    if sample_images:\n",
    "        img = generate_samples(step, save=save_image_files)\n",
    "        s.MergeFromString(tf.Session().run(\n",
    "            tf.summary.image('samples_%07d' % step,\n",
    "                             img.reshape([1, *img.shape, 1]))))\n",
    "\n",
    "    sw.add_summary(s, step)\n",
    "    sw.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fake = 1\n",
    "# real = -1\n",
    "\n",
    "progress_bar = Progbar(target=ITERATIONS)\n",
    "\n",
    "DG_losses = []\n",
    "D_true_losses = []\n",
    "D_fake_losses = []\n",
    "\n",
    "for it in range(ITERATIONS):\n",
    "\n",
    "    if len(D_true_losses) > 0:\n",
    "        progress_bar.update(\n",
    "            it,\n",
    "            values=[\n",
    "                    ('D_real_is_fake', np.mean(D_true_losses[-5:], axis=0)[1]),\n",
    "                    ('D_real_class', np.mean(D_true_losses[-5:], axis=0)[2]),\n",
    "                    ('D_fake_is_fake', np.mean(D_fake_losses[-5:], axis=0)[1]),\n",
    "                    ('D_fake_class', np.mean(D_fake_losses[-5:], axis=0)[2]),\n",
    "                    ('D(G)_is_fake', np.mean(DG_losses[-5:],axis=0)[1]),\n",
    "                    ('D(G)_class', np.mean(DG_losses[-5:],axis=0)[2])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        progress_bar.update(it)\n",
    "\n",
    "    # 1: train D on real+generated images\n",
    "\n",
    "    if (it % 1000) < 25 or it % 500 == 0: # 25 times in 1000, every 500th\n",
    "        d_iters = 100\n",
    "    else:\n",
    "        d_iters = D_ITERS\n",
    "\n",
    "    for d_it in range(d_iters):\n",
    "\n",
    "        # unfreeze D\n",
    "        D.trainable = True\n",
    "        for l in D.layers: l.trainable = True\n",
    "            \n",
    "        # # restore D dropout rates\n",
    "        # for l in D.layers:\n",
    "        #     if l.name.startswith('dropout'):\n",
    "        #         l.rate = l._rate\n",
    "\n",
    "        # clip D weights\n",
    "\n",
    "        for l in D.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        # 1.1: maximize D output on reals === minimize -1*(D(real))\n",
    "\n",
    "        # draw random samples from real images\n",
    "        index = np.random.choice(len(X_train), BATCH_SIZE, replace=False)\n",
    "        real_images = X_train[index]\n",
    "        real_images_classes = y_train[index]\n",
    "\n",
    "        D_loss = D.train_on_batch(real_images, [-np.ones(BATCH_SIZE), real_images_classes])\n",
    "        D_true_losses.append(D_loss)\n",
    "\n",
    "        # 1.2: minimize D output on fakes \n",
    "\n",
    "        zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE))\n",
    "        generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "        generated_images = G.predict([zz, generated_classes.reshape(-1, 1)])\n",
    "\n",
    "        D_loss = D.train_on_batch(generated_images, [np.ones(BATCH_SIZE), generated_classes])\n",
    "        D_fake_losses.append(D_loss)\n",
    "\n",
    "    # 2: train D(G) (D is frozen)\n",
    "    # minimize D output while supplying it with fakes, telling it that they are reals (-1)\n",
    "\n",
    "    # freeze D\n",
    "    D.trainable = False\n",
    "    for l in D.layers: l.trainable = False\n",
    "        \n",
    "    # # disable D dropout layers\n",
    "    # for l in D.layers:\n",
    "    #     if l.name.startswith('dropout'):\n",
    "    #         l.rate = 0.\n",
    "\n",
    "    zz = np.random.normal(0., 1., (BATCH_SIZE, Z_SIZE)) \n",
    "    generated_classes = np.random.randint(0, 10, BATCH_SIZE)\n",
    "\n",
    "    DG_loss = DG.train_on_batch(\n",
    "        [zz, generated_classes.reshape((-1, 1))],\n",
    "        [-np.ones(BATCH_SIZE), generated_classes])\n",
    "\n",
    "    DG_losses.append(DG_loss)\n",
    "\n",
    "    if it % 10 == 0:\n",
    "        update_tb_summary(it, sample_images=(it % 10 == 0), save_image_files=True)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/6ecf449b32eb263e7d9a7f6e9aed5dc2"
  },
  "gist": {
   "data": {
    "description": "Wasserstein ACGAN in Keras",
    "public": true
   },
   "id": "6ecf449b32eb263e7d9a7f6e9aed5dc2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
